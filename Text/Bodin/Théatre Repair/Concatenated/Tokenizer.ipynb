{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54bf6974-56fe-490b-9b06-61bd6634a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize,wordpunct_tokenize\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures, TrigramCollocationFinder, TrigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d91501f-4ea8-4a51-80e4-5b2c3d87f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/lucas-jerusalimiec/Documents/OCR Text/Notebooks\")\n",
    "from tokenizer_func  import (wordcleaner, write_words_to_file, dictionary_to_file, convert_tuple_bigrams,\n",
    "convert_tuple_trigrams)\n",
    "\n",
    "from extra_token_func import print_first_n_items, remove_keys_from_nested_dict\n",
    "\n",
    "from additional_token_func import convert_strings_to_counts\n",
    "\n",
    "from dict_write import write_dict_to_files_with_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d557ac9-168b-4b35-ac00-28687dd85cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tokenized/\n",
      "Text files in the spellchecked directory: ['final/Théatre_corrected.txt']\n"
     ]
    }
   ],
   "source": [
    "text_loc = Path(\"./final\")\n",
    "text_files = glob.glob(f\"{text_loc}/*.txt\")\n",
    "output_folder = './tokenized/'\n",
    "tokenized_folder = Path(output_folder)\n",
    "tokenized_folder.mkdir(exist_ok=True)\n",
    "print(output_folder)\n",
    "print(\"Text files in the spellchecked directory:\", text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa6226b-1236-4eb7-b4b3-7b8c79c0a6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ie', 'fc', 'del', 'o', 'dé', 'dela', 'ay', 'w', 'iij', 'enl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open stopwords CSV file and list the contents\n",
    "with open('./stop_words.csv', 'r') as f:\n",
    "    stopwords = f.read().strip().split(\",\")\n",
    "stopwords[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b085009a-d824-4bf2-aedc-fd567abf2dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw texts: ['Théatre_corrected']\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = {}\n",
    "for txt in text_files:\n",
    "    with open(txt, 'r') as f:\n",
    "        content = f.read()\n",
    "        file_name = txt.split('\\\\')[-1]\n",
    "        #key = file_name.split('.')[0]\n",
    "        key = os.path.splitext(os.path.basename(file_name))[0]\n",
    "        tokenized_texts[key] = content\n",
    "print(\"Raw texts:\", list(tokenized_texts.keys()))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f8cc71e-5849-4195-8b5c-585cc06d2916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved content for 'Théatre_corrected' to ./tokenized/Théatre_corrected.txt\n"
     ]
    }
   ],
   "source": [
    "unigrams = {}\n",
    "\n",
    "for key, value in tokenized_texts.items():\n",
    "    unigram_list = wordpunct_tokenize(value)\n",
    "    cleanwords = [wordcleaner(w) for w in unigram_list]\n",
    "    unigrams[key] = cleanwords\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    filename = f\"./tokenized/{key}.txt\"\n",
    "    write_words_to_file(value, filename, words_per_line=20)\n",
    "    print(f\"Saved content for '{key}' to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d044c3f8-9aab-4362-8b85-a3709e228a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram texts:\n",
      "Théatre_corrected\n"
     ]
    }
   ],
   "source": [
    "print(\"Unigram texts:\")\n",
    "for key in unigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51492bb5-b662-4e41-bf0d-35e2bd3e3e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Counts:\n",
      "Théatre_corrected\n",
      "First 25 items in Théatre_corrected:\n",
      ": 74568\n",
      "de: 8277\n",
      "la: 5498\n",
      "que: 5297\n",
      "l: 4758\n",
      "les: 4233\n",
      "le: 3630\n",
      "en: 3486\n",
      "qu: 3209\n",
      "à: 3171\n",
      "qui: 2883\n",
      "il: 2809\n",
      "d: 2702\n",
      "des: 2657\n",
      "ne: 2377\n",
      "par: 2172\n",
      "a: 2167\n",
      "plus: 1824\n",
      "eft: 1778\n",
      "s: 1705\n",
      "n: 1700\n",
      "ce: 1583\n",
      "du: 1572\n",
      "fe: 1466\n",
      "au: 1431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count up the tokens using a Counter() object\n",
    "unigram_counts = {}\n",
    "for key, value in unigrams.items():\n",
    "    unigram_counts_dict = Counter(value)\n",
    "    unigram_counts[key] = unigram_counts_dict\n",
    "\n",
    "print(\"Unigram Counts:\")\n",
    "for key in unigram_counts:\n",
    "    print(key)\n",
    "\n",
    "print_first_n_items(unigram_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1300638a-16da-4c7f-8e9c-1de304b45009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 30 items in Théatre_corrected:\n",
      "plus: 1824\n",
      "comme: 910\n",
      "corps: 688\n",
      "autre: 672\n",
      "autres: 665\n",
      "peut: 625\n",
      "foit: 552\n",
      "toutes: 546\n",
      "nature: 545\n",
      "tout: 535\n",
      "deux: 501\n",
      "mefme: 496\n",
      "laquelle: 495\n",
      "grand: 469\n",
      "fois: 435\n",
      "terre: 432\n",
      "tant: 428\n",
      "ni: 425\n",
      "puis: 385\n",
      "pourquoy: 383\n",
      "fans: 376\n",
      "eau: 367\n",
      "ame: 364\n",
      "leurs: 350\n",
      "auec: 349\n",
      "fes: 345\n",
      "ainfi: 344\n",
      "elles: 334\n",
      "tous: 330\n",
      "rien: 325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove specified keys from the dictionary\n",
    "stripped_unigrams = remove_keys_from_nested_dict(unigram_counts, stopwords)\n",
    "\n",
    "print_first_n_items(stripped_unigrams, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2d63ded-ea90-4894-af13-c8373b235afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Théatre_corrected_unigram_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(stripped_unigrams, output_folder, 'unigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d6661b6-baf5-47d8-a58b-49bfedc0a32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams:\n",
      "Théatre_corrected\n"
     ]
    }
   ],
   "source": [
    "bigrams = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    #unigram_list = [word for word in value]\n",
    "    bigrams_list = list(nltk.bigrams(unigram_list))\n",
    "    bigrams[key] = bigrams_list\n",
    "\n",
    "print(\"Bigrams:\")\n",
    "for key in bigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24b278bb-d5b9-436c-8a31-3d626532ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Counts:\n",
      "Théatre_corrected\n",
      "First 30 items in Théatre_corrected:\n",
      "toutes fois: 165\n",
      "plus grand: 159\n",
      "où vient: 87\n",
      "peut faire: 79\n",
      "plus moins: 78\n",
      "beaucoup plus: 62\n",
      "tous autres: 60\n",
      "tant plus: 60\n",
      "corps naturel: 59\n",
      "voilà pourquoy: 55\n",
      "plus grande: 49\n",
      "long temps: 48\n",
      "autre chofe: 45\n",
      "tout ainfi: 43\n",
      "autres animaux: 42\n",
      "peut entendre: 41\n",
      "toutes fortes: 41\n",
      "foit plus: 39\n",
      "fois plus: 39\n",
      "plus petit: 37\n",
      "toutes choses: 36\n",
      "vns autres: 36\n",
      "là où: 36\n",
      "toutes chofes: 34\n",
      "combien fortes: 34\n",
      "puis apres: 34\n",
      "quelque chofe: 33\n",
      "autre chose: 32\n",
      "fes parties: 31\n",
      "non plus: 30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bigram_counts = {}\n",
    "\n",
    "for key, value in bigrams.items():\n",
    "    string_bigrams = convert_tuple_bigrams(value)\n",
    "    bigramCount = convert_strings_to_counts(string_bigrams)\n",
    "    bigram_counts[key] = bigramCount\n",
    "\n",
    "print(\"Bigram Counts:\")\n",
    "for key in bigram_counts:\n",
    "    print(key)\n",
    "\n",
    "print_first_n_items(bigram_counts, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c4eb003-3c3c-4d9e-b5e9-1979bd1a3fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Théatre_corrected_bigram_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(bigram_counts, output_folder, 'bigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfe978cd-c9e2-46c6-9c37-fbb524fbbd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigrams:\n",
      "Théatre_corrected\n"
     ]
    }
   ],
   "source": [
    "trigrams = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    #unigram_list = [word for word in value]\n",
    "    trigrams_list = list(nltk.trigrams(unigram_list))\n",
    "    trigrams[key] = trigrams_list\n",
    "\n",
    "print(\"Trigrams:\")\n",
    "for key in bigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b2a5667-7557-49d9-9904-184526684891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram Counts:\n",
      "Théatre_corrected\n",
      "First 30 items in Théatre_corrected:\n",
      "comment peut faire: 18\n",
      "plus grand partie: 16\n",
      "auec plus grand: 12\n",
      "tout enfemble fois: 12\n",
      "plus grand plus: 11\n",
      "plus vray femblable: 11\n",
      "fois plus grand: 10\n",
      "tout ensemble fois: 9\n",
      "là peut entendre: 9\n",
      "tous autres animaux: 9\n",
      "differentes vnes autres: 8\n",
      "long temps fans: 8\n",
      "deux fois plus: 8\n",
      "rien foit plus: 7\n",
      "foit plus propre: 7\n",
      "plus longue durée: 7\n",
      "long temps apres: 7\n",
      "fois plus grande: 7\n",
      "mille cinq cents: 7\n",
      "plus grand nombre: 6\n",
      "tres bon tres: 6\n",
      "quel ineonuenient auroit: 6\n",
      "pourquoy non pource: 6\n",
      "fur tous autres: 6\n",
      "vaut autant dire: 6\n",
      "ainfi certes efcript: 6\n",
      "tue où vient: 6\n",
      "vingt quatre heures: 6\n",
      "plus haut ciel: 5\n",
      "ineonuenient auroit difions: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trigram_counts = {}\n",
    "\n",
    "for key, value in trigrams.items():\n",
    "    string_trigrams = convert_tuple_trigrams(value)\n",
    "    trigramCount = convert_strings_to_counts(string_trigrams)\n",
    "    trigram_counts[key] = trigramCount\n",
    "\n",
    "print(\"Trigram Counts:\")\n",
    "for key in trigram_counts:\n",
    "    print(key)\n",
    "    \n",
    "print_first_n_items(trigram_counts, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d36ad6c4-4f5b-4d15-b463-25318d4095b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Théatre_corrected_trigram_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(trigram_counts, output_folder, 'trigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58fd2be9-d9ed-4c35-b058-5a1f944e992a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collocations:\n",
      "Théatre_corrected\n",
      "Collocation Counts:\n",
      "Théatre_corrected\n",
      "où vient 87\n",
      "voilà pourquoy 55\n",
      "long temps 48\n",
      "grand peine 27\n",
      "ceftuy cy 25\n",
      "auons defia 24\n",
      "quelques vns 24\n",
      "entendement agent 23\n",
      "longue durée 22\n",
      "cinq cens 22\n",
      "neant moins 19\n",
      "hors mis 19\n",
      "vray femblable 19\n",
      "pierres metaux 16\n",
      "dont aduient 16\n",
      "argent vif 16\n",
      "seroit autant 14\n",
      "quatriesme livre 14\n",
      "orient occident 13\n",
      "chaleur naturelle 12\n",
      "nombre infiny 12\n",
      "cause efficiente 11\n",
      "differentes vnes 11\n",
      "anges demons 11\n",
      "mille cinq 11\n",
      "faut douter 10\n",
      "auons monftré 10\n",
      "bon gré 10\n",
      "loy diuine 10\n",
      "cinq cents 10\n",
      "\n",
      "Saved Théatre_corrected_collocation_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "colloc_dict = {}\n",
    "colloc_counts = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    bigram_finder = BigramCollocationFinder.from_words(unigram_list)\n",
    "    bigram_finder.apply_freq_filter(3)  # Make sure all collocations have occurred at least 5 times\n",
    "    collocations = bigram_finder.nbest(BigramAssocMeasures.pmi, 500)\n",
    "    colloc_dict[key] = collocations\n",
    "    \n",
    "    # Initialize Counter for colloc_counts\n",
    "    bigram_count_dict = Counter()\n",
    "\n",
    "    # Count the occurrences of each bigram in the text\n",
    "    bigram_finder = BigramCollocationFinder.from_words(unigram_list)\n",
    "    bigram_freqs = bigram_finder.ngram_fd.items()\n",
    "    \n",
    "    # Filter bigram counts based on collocations\n",
    "    for bigram, count in bigram_freqs:\n",
    "        if bigram in collocations:\n",
    "            bigram_count_dict[bigram] = count\n",
    "\n",
    "    colloc_counts[key] = bigram_count_dict\n",
    "\n",
    "print(\"Collocations:\")\n",
    "for key, value in colloc_dict.items():\n",
    "    print(key)\n",
    "    # for w1, w2 in value:\n",
    "    #     print(' ', w1, w2)\n",
    "\n",
    "print(\"Collocation Counts:\")\n",
    "for key in colloc_counts:\n",
    "    print(key)\n",
    "    # Print first n items, assuming print_first_n_items function is defined elsewhere\n",
    "    for item, count in colloc_counts[key].most_common(30):\n",
    "        bigram = \" \".join(item)\n",
    "        print(f\"{bigram} {count}\")\n",
    "    print()\n",
    "\n",
    "dictionary_to_file(colloc_counts, output_folder, 'collocation_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4f5f4c8-a3e2-4e10-9a2f-b3369eced597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram Collocations:\n",
      "Théatre_corrected\n",
      "Trigram Collocation Counts:\n",
      "Théatre_corrected\n",
      "comment peut faire 18\n",
      "plus grand partie 16\n",
      "auec plus grand 12\n",
      "tout enfemble fois 12\n",
      "plus grand plus 11\n",
      "plus vray femblable 11\n",
      "fois plus grand 10\n",
      "tout ensemble fois 9\n",
      "là peut entendre 9\n",
      "tous autres animaux 9\n",
      "differentes vnes autres 8\n",
      "long temps fans 8\n",
      "deux fois plus 8\n",
      "rien foit plus 7\n",
      "foit plus propre 7\n",
      "plus longue durée 7\n",
      "long temps apres 7\n",
      "fois plus grande 7\n",
      "mille cinq cents 7\n",
      "plus grand nombre 6\n",
      "tres bon tres 6\n",
      "quel ineonuenient auroit 6\n",
      "pourquoy non pource 6\n",
      "fur tous autres 6\n",
      "vaut autant dire 6\n",
      "ainfi certes efcript 6\n",
      "tue où vient 6\n",
      "vingt quatre heures 6\n",
      "plus haut ciel 5\n",
      "ineonuenient auroit difions 5\n",
      "\n",
      "Saved Théatre_corrected_trigram_collocation_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "trigram_colloc_dict = {}\n",
    "trigram_colloc_counts = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    trigram_finder = TrigramCollocationFinder.from_words(unigram_list)\n",
    "    trigram_finder.apply_freq_filter(3)  # Ensure all collocations have occurred at least 5 times\n",
    "    collocations = trigram_finder.nbest(TrigramAssocMeasures.pmi, 500)\n",
    "    trigram_colloc_dict[key] = collocations\n",
    "    \n",
    "    # Initialize Counter for trigram_colloc_counts\n",
    "    trigram_count_dict = Counter()\n",
    "\n",
    "    # Count the occurrences of each trigram in the text\n",
    "    trigram_freqs = trigram_finder.ngram_fd.items()\n",
    "    \n",
    "    # Filter trigram counts based on collocations\n",
    "    for trigram, count in trigram_freqs:\n",
    "        if trigram in collocations:\n",
    "            trigram_count_dict[trigram] = count\n",
    "\n",
    "    trigram_colloc_counts[key] = trigram_count_dict\n",
    "\n",
    "print(\"Trigram Collocations:\")\n",
    "for key, value in trigram_colloc_dict.items():\n",
    "    print(key)\n",
    "    #for w1, w2, w3 in value:\n",
    "    #    print(' ', w1, w2, w3)\n",
    "\n",
    "print(\"Trigram Collocation Counts:\")\n",
    "for key in trigram_colloc_counts:\n",
    "    print(key)\n",
    "    # Print first n items, assuming print_first_n_items function is defined elsewhere\n",
    "    for item, count in trigram_colloc_counts[key].most_common(30):\n",
    "        trigram = \" \".join(item)\n",
    "        print(f\"{trigram} {count}\")\n",
    "    print()\n",
    "\n",
    "dictionary_to_file(trigram_colloc_counts, output_folder, 'trigram_collocation_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b890221-5827-4d01-a9ab-9726fde00e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underscore Dictionary:\n",
      "Théatre_corrected\n",
      "Théatre_corrected_underscore_bigrams.txt in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "underscore_dict = {}\n",
    "for key, value in unigrams.items():\n",
    "\n",
    "    tokenized_words = unigrams.get(key)\n",
    "    collocations = colloc_dict.get(key)\n",
    "    \n",
    "    colloc_words = []\n",
    "    \n",
    "    # Iterate through the words making new versions combining collocations\n",
    "    i = 0\n",
    "    while i < len(tokenized_words) - 1:\n",
    "        # If we find a collocation, add and advance by two words\n",
    "        if (tokenized_words[i], tokenized_words[i + 1]) in collocations:\n",
    "            colloc_words.append('_'.join((tokenized_words[i], tokenized_words[i + 1])))\n",
    "            i += 2\n",
    "        # Otherwise, advance by one word\n",
    "        else:\n",
    "            colloc_words.append(tokenized_words[i])\n",
    "            i += 1\n",
    "\n",
    "    # Add the last word (if any)\n",
    "    if i == len(tokenized_words) - 1:\n",
    "        colloc_words.append(tokenized_words[i])\n",
    "    underscore_dict[key] = colloc_words\n",
    "\n",
    "print(\"Underscore Dictionary:\")\n",
    "for key in underscore_dict:\n",
    "    print(key)\n",
    "\n",
    "write_dict_to_files_with_suffix(underscore_dict, output_folder, 'underscore_bigrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f0b3b4c-c6df-4bdf-84c2-fb152e0b68e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram underscore Dictionary:\n",
      "Théatre_corrected\n",
      "Théatre_corrected_underscore_trigrams.txt in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "trigram_underscore_dict = {}\n",
    "\n",
    "for key, tokenized_words in unigrams.items():\n",
    "    collocations = trigram_colloc_dict.get(key, [])\n",
    "    colloc_words = []\n",
    "    i = 0\n",
    "    while i < len(tokenized_words) - 2:\n",
    "        # If we find a trigram collocation, add and advance by three words\n",
    "        trigram = (tokenized_words[i], tokenized_words[i + 1], tokenized_words[i + 2])\n",
    "        if trigram in collocations:\n",
    "            colloc_words.append('_'.join(trigram))\n",
    "            i += 3\n",
    "        else:\n",
    "            colloc_words.append(tokenized_words[i])\n",
    "            i += 1\n",
    "    # Add the last words (if any)\n",
    "    while i < len(tokenized_words):\n",
    "        colloc_words.append(tokenized_words[i])\n",
    "        i += 1\n",
    "    trigram_underscore_dict[key] = colloc_words\n",
    "\n",
    "print(\"Trigram underscore Dictionary:\")\n",
    "for key in trigram_underscore_dict:\n",
    "    print(key)\n",
    "\n",
    "write_dict_to_files_with_suffix(trigram_underscore_dict, output_folder, 'underscore_trigrams')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
