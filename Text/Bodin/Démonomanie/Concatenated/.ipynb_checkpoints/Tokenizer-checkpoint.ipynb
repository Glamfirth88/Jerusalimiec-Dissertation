{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54bf6974-56fe-490b-9b06-61bd6634a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize,wordpunct_tokenize\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d91501f-4ea8-4a51-80e4-5b2c3d87f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/lucas-jerusalimiec/Documents/OCR Text/Notebooks\")\n",
    "from tokenizer_func  import (wordcleaner, write_words_to_file, dictionary_to_file, convert_tuple_bigrams,\n",
    "convert_tuple_trigrams)\n",
    "\n",
    "from extra_token_func import print_first_n_items, remove_keys_from_nested_dict\n",
    "\n",
    "from additional_token_func import convert_strings_to_counts\n",
    "\n",
    "from dict_write import write_dict_to_files_with_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d557ac9-168b-4b35-ac00-28687dd85cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tokenized/\n",
      "Text files in the spellchecked directory: ['final/Démonomanie_corrected.txt']\n"
     ]
    }
   ],
   "source": [
    "text_loc = Path(\"./final\")\n",
    "text_files = glob.glob(f\"{text_loc}/*.txt\")\n",
    "output_folder = './tokenized/'\n",
    "tokenized_folder = Path(output_folder)\n",
    "tokenized_folder.mkdir(exist_ok=True)\n",
    "print(output_folder)\n",
    "print(\"Text files in the spellchecked directory:\", text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b085009a-d824-4bf2-aedc-fd567abf2dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw texts: ['Démonomanie_corrected']\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = {}\n",
    "for txt in text_files:\n",
    "    with open(txt, 'r') as f:\n",
    "        content = f.read()\n",
    "        file_name = txt.split('\\\\')[-1]\n",
    "        #key = file_name.split('.')[0]\n",
    "        key = os.path.splitext(os.path.basename(file_name))[0]\n",
    "        tokenized_texts[key] = content\n",
    "print(\"Raw texts:\", list(tokenized_texts.keys()))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f8cc71e-5849-4195-8b5c-585cc06d2916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved content for 'Démonomanie_corrected' to ./tokenized/Démonomanie_corrected.txt\n"
     ]
    }
   ],
   "source": [
    "unigrams = {}\n",
    "\n",
    "for key, value in tokenized_texts.items():\n",
    "    unigram_list = wordpunct_tokenize(value)\n",
    "    cleanwords = [wordcleaner(w) for w in unigram_list]\n",
    "    unigrams[key] = cleanwords\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    filename = f\"./tokenized/{key}.txt\"\n",
    "    write_words_to_file(value, filename, words_per_line=20)\n",
    "    print(f\"Saved content for '{key}' to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d044c3f8-9aab-4362-8b85-a3709e228a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram texts:\n",
      "Démonomanie_corrected\n"
     ]
    }
   ],
   "source": [
    "print(\"Unigram texts:\")\n",
    "for key in unigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51492bb5-b662-4e41-bf0d-35e2bd3e3e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Counts:\n",
      "Démonomanie_corrected\n"
     ]
    }
   ],
   "source": [
    "# Count up the tokens using a Counter() object\n",
    "unigram_counts = {}\n",
    "for key, value in unigrams.items():\n",
    "    unigram_counts_dict = Counter(value)\n",
    "    unigram_counts[key] = unigram_counts_dict\n",
    "\n",
    "print(\"Unigram Counts:\")\n",
    "for key in unigram_counts:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47725d22-cfe1-4bae-80a7-1dd079591dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in Démonomanie_corrected:\n",
      ": 38302\n",
      "de: 3488\n",
      "que: 1938\n",
      "qu: 1742\n",
      "les: 1664\n",
      "la: 1661\n",
      "en: 1648\n",
      "il: 1593\n",
      "qui: 1576\n",
      "à: 1298\n",
      "l: 1296\n",
      "d: 1287\n",
      "le: 1218\n",
      "des: 1115\n",
      "eft: 927\n",
      "pour: 740\n",
      "ne: 740\n",
      "par: 679\n",
      "dieu: 676\n",
      "on: 668\n",
      "ce: 665\n",
      "c: 665\n",
      "n: 661\n",
      "vn: 655\n",
      "a: 652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_first_n_items(unigram_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fa6226b-1236-4eb7-b4b3-7b8c79c0a6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fe', 'auoit', 'fa', 'eftoit', 'eftre', 'auoir', '', 'x', 'v', 'ee']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open stopwords CSV file and list the contents\n",
    "with open('./stop_words.csv', 'r') as f:\n",
    "    stopwords = f.read().strip().split(\",\")\n",
    "stopwords[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1300638a-16da-4c7f-8e9c-1de304b45009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in Démonomanie_corrected:\n",
      "dieu: 676\n",
      "comme: 480\n",
      "sors: 437\n",
      "plus: 426\n",
      "bien: 330\n",
      "sor: 244\n",
      "dia: 235\n",
      "autres: 231\n",
      "in: 229\n",
      "faire: 229\n",
      "di: 214\n",
      "livre: 195\n",
      "peut: 194\n",
      "point: 192\n",
      "tous: 182\n",
      "dela: 180\n",
      "faut: 173\n",
      "dit: 172\n",
      "sathan: 168\n",
      "tout: 166\n",
      "quand: 162\n",
      "mort: 161\n",
      "dire: 154\n",
      "sans: 146\n",
      "re: 146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove specified keys from the dictionary\n",
    "stripped_unigrams = remove_keys_from_nested_dict(unigram_counts, stopwords)\n",
    "\n",
    "print_first_n_items(stripped_unigrams, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2d63ded-ea90-4894-af13-c8373b235afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Démonomanie_corrected_unigram_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(stripped_unigrams, output_folder, 'unigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d6661b6-baf5-47d8-a58b-49bfedc0a32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams:\n",
      "Démonomanie_corrected\n"
     ]
    }
   ],
   "source": [
    "bigrams = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    bigrams_list = list(nltk.bigrams(unigram_list))\n",
    "    bigrams[key] = bigrams_list\n",
    "\n",
    "print(\"Bigrams:\")\n",
    "for key in bigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24b278bb-d5b9-436c-8a31-3d626532ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Counts:\n",
      "Démonomanie_corrected\n"
     ]
    }
   ],
   "source": [
    "bigram_text = {}\n",
    "bigram_counts = {}\n",
    "\n",
    "for key, value in bigrams.items():\n",
    "    string_bigrams = convert_tuple_bigrams(value)\n",
    "    bigramCount = convert_strings_to_counts(string_bigrams)\n",
    "    bigram_text[key] = string_bigrams\n",
    "    bigram_counts[key] = bigramCount\n",
    "\n",
    "print(\"Bigram Counts:\")\n",
    "for key in bigram_counts:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abf68090-62ec-4069-a472-7b7dbe6e7c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in Démonomanie_corrected:\n",
      "livre second: 45\n",
      "livre premier: 41\n",
      "loy dieu: 37\n",
      "malins efprits: 28\n",
      "livre qvatriesme: 27\n",
      "cas pareil: 26\n",
      "malings efprits: 21\n",
      "plus grand: 20\n",
      "quelque chofe: 19\n",
      "livre troisiesme: 19\n",
      "comme dit: 18\n",
      "celte cause: 17\n",
      "comme di: 17\n",
      "faire mou: 17\n",
      "cy deflus: 17\n",
      "bien fort: 16\n",
      "comme dict: 16\n",
      "faut donc: 16\n",
      "an mil: 16\n",
      "encores plus: 15\n",
      "livre troisieme: 15\n",
      "quele dia: 14\n",
      "autres choses: 14\n",
      "grand nombre: 13\n",
      "thomas aquin: 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_first_n_items(bigram_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c4eb003-3c3c-4d9e-b5e9-1979bd1a3fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Démonomanie_corrected_bigram_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(bigram_counts, output_folder, 'bigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfe978cd-c9e2-46c6-9c37-fbb524fbbd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigrams:\n",
      "Démonomanie_corrected\n"
     ]
    }
   ],
   "source": [
    "trigrams = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    trigrams_list = list(nltk.trigrams(unigram_list))\n",
    "    trigrams[key] = trigrams_list\n",
    "\n",
    "print(\"Trigrams:\")\n",
    "for key in bigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b2a5667-7557-49d9-9904-184526684891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram Counts:\n",
      "Démonomanie_corrected\n"
     ]
    }
   ],
   "source": [
    "trigram_text = {}\n",
    "trigram_counts = {}\n",
    "\n",
    "for key, value in trigrams.items():\n",
    "    string_trigrams = convert_tuple_trigrams(value)\n",
    "    trigramCount = convert_strings_to_counts(string_trigrams)\n",
    "    trigram_text[key] = string_bigrams\n",
    "    trigram_counts[key] = trigramCount\n",
    "\n",
    "print(\"Trigram Counts:\")\n",
    "for key in trigram_counts:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43910dd4-8a43-4800-8068-8f582f5a0bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in Démonomanie_corrected:\n",
      "mil cinq cens: 10\n",
      "an mil cinq: 9\n",
      "comme cas pareil: 7\n",
      "dirons cy apres: 5\n",
      "plus forte raifon: 5\n",
      "paruenir quelque chofe: 4\n",
      "prince dela mirande: 4\n",
      "ferons mefme iugement: 4\n",
      "comme dirons lieu: 4\n",
      "dela loy dieu: 4\n",
      "ie mettray point: 4\n",
      "faut bien garder: 4\n",
      "comme auons di: 4\n",
      "liure dela cité: 4\n",
      "dela cité dieu: 4\n",
      "monftré cy deflus: 4\n",
      "deux trois heures: 3\n",
      "plus deteftas sors: 3\n",
      "queie mettray point: 3\n",
      "fai bien fouuent: 3\n",
      "dict cy deflus: 3\n",
      "comme quand di: 3\n",
      "difons maintenant moyens: 3\n",
      "plus forte raison: 3\n",
      "contre cours na: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_first_n_items(trigram_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d36ad6c4-4f5b-4d15-b463-25318d4095b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Démonomanie_corrected_trigram_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(trigram_counts, output_folder, 'trigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7121f0e2-df9e-4b21-b929-144d4279227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collocations:\n",
      "Démonomanie_corrected\n"
     ]
    }
   ],
   "source": [
    "colloc_dict = {}\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    bigram_finder = BigramCollocationFinder.from_words(unigram_list)\n",
    "    bigram_finder.apply_freq_filter(5)   # make sure all collocations have occured at least 5 times\n",
    "    collocations = bigram_finder.nbest(BigramAssocMeasures.pmi, 500)\n",
    "    colloc_dict[key] = collocations\n",
    "\n",
    "print(\"Collocations:\")\n",
    "for key, value in colloc_dict.items():\n",
    "    print(key)\n",
    "    #for w1, w2 in value:\n",
    "        #print(' ', w1, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9613500d-ed13-4efa-a107-32c8ce7ef52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collocation Counts:\n",
      "Démonomanie_corrected\n"
     ]
    }
   ],
   "source": [
    "colloc_text = {}\n",
    "colloc_counts = {}\n",
    "\n",
    "for key, value in colloc_dict.items():\n",
    "    string_bigrams = convert_tuple_bigrams(value)\n",
    "    bigramCount = convert_strings_to_counts(string_bigrams)\n",
    "    colloc_counts[key] = string_bigrams\n",
    "    colloc_counts[key] = bigramCount\n",
    "\n",
    "print(\"Collocation Counts:\")\n",
    "for key in colloc_counts:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1814b84-b707-4058-9a98-0debd4f90c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in Démonomanie_corrected:\n",
      "images cire: 1\n",
      "thomas aquin: 1\n",
      "paul grilland: 1\n",
      "parties honteuses: 1\n",
      "genre humain: 1\n",
      "fonges vifions: 1\n",
      "adioufter foy: 1\n",
      "prince mirande: 1\n",
      "demeurent accord: 1\n",
      "grecs latins: 1\n",
      "ville laon: 1\n",
      "ferons mefme: 1\n",
      "mal caduc: 1\n",
      "causes nalles: 1\n",
      "bons mauuais: 1\n",
      "cas pareil: 1\n",
      "figure humaine: 1\n",
      "long temps: 1\n",
      "quel quesfois: 1\n",
      "cens cinquante: 1\n",
      "quei ay: 1\n",
      "difons donc: 1\n",
      "li ure: 1\n",
      "mil cinq: 1\n",
      "moyens diaboliques: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_first_n_items(colloc_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1956da3-dab0-4e63-ac2e-a98f2d1874d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Démonomanie_corrected_collocation_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(colloc_counts, output_folder, 'collocation_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7e2f4d1-a0cd-4382-ac98-0458ffe95edd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underscore Dictionary:\n",
      "Démonomanie_corrected\n"
     ]
    }
   ],
   "source": [
    "underscore_dict = {}\n",
    "for key, value in unigrams.items():\n",
    "\n",
    "    tokenized_words = unigrams.get(key)\n",
    "    collocations = colloc_dict.get(key)\n",
    "    \n",
    "    colloc_words = []\n",
    "    \n",
    "    # Iterate through the words making new versions combining collocations\n",
    "    i = 0\n",
    "    while i < len(tokenized_words) - 1:\n",
    "        # If we find a collocation, add and advance by two words\n",
    "        if (tokenized_words[i], tokenized_words[i + 1]) in collocations:\n",
    "            colloc_words.append('_'.join((tokenized_words[i], tokenized_words[i + 1])))\n",
    "            i += 2\n",
    "        # Otherwise, advance by one word\n",
    "        else:\n",
    "            colloc_words.append(tokenized_words[i])\n",
    "            i += 1\n",
    "\n",
    "    # Add the last word (if any)\n",
    "    if i == len(tokenized_words) - 1:\n",
    "        colloc_words.append(tokenized_words[i])\n",
    "    underscore_dict[key] = colloc_words\n",
    "\n",
    "print(\"Underscore Dictionary:\")\n",
    "for key in underscore_dict:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b482ee5a-560f-46e2-8c2a-13162fb7ccaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démonomanie_corrected_underscore_bigrams.txt in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "write_dict_to_files_with_suffix(underscore_dict, output_folder, 'underscore_bigrams')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
