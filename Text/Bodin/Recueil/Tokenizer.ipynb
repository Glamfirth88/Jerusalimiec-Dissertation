{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54bf6974-56fe-490b-9b06-61bd6634a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize,wordpunct_tokenize\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures, TrigramCollocationFinder, TrigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d91501f-4ea8-4a51-80e4-5b2c3d87f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/lucas-jerusalimiec/Documents/OCR Text/Notebooks\")\n",
    "from tokenizer_func  import (wordcleaner, write_words_to_file, dictionary_to_file, convert_tuple_bigrams,\n",
    "convert_tuple_trigrams)\n",
    "\n",
    "from extra_token_func import print_first_n_items, remove_keys_from_nested_dict\n",
    "\n",
    "from additional_token_func import convert_strings_to_counts\n",
    "\n",
    "from dict_write import write_dict_to_files_with_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d557ac9-168b-4b35-ac00-28687dd85cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tokenized/\n",
      "Text files in the spellchecked directory: ['final/Recueil_corrected.txt']\n"
     ]
    }
   ],
   "source": [
    "text_loc = Path(\"./final\")\n",
    "text_files = glob.glob(f\"{text_loc}/*.txt\")\n",
    "output_folder = './tokenized/'\n",
    "tokenized_folder = Path(output_folder)\n",
    "tokenized_folder.mkdir(exist_ok=True)\n",
    "print(output_folder)\n",
    "print(\"Text files in the spellchecked directory:\", text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa6226b-1236-4eb7-b4b3-7b8c79c0a6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['or', 'q', 'f', 'r', 'p', 'ie', 'fc', 'del', 'o', 'dé']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open stopwords CSV file and list the contents\n",
    "with open('./stop_words.csv', 'r') as f:\n",
    "    stopwords = f.read().strip().split(\",\")\n",
    "stopwords[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b085009a-d824-4bf2-aedc-fd567abf2dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw texts: ['Recueil_corrected']\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = {}\n",
    "for txt in text_files:\n",
    "    with open(txt, 'r') as f:\n",
    "        content = f.read()\n",
    "        file_name = txt.split('\\\\')[-1]\n",
    "        #key = file_name.split('.')[0]\n",
    "        key = os.path.splitext(os.path.basename(file_name))[0]\n",
    "        tokenized_texts[key] = content\n",
    "print(\"Raw texts:\", list(tokenized_texts.keys()))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f8cc71e-5849-4195-8b5c-585cc06d2916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved content for 'Recueil_corrected' to ./tokenized/Recueil_corrected.txt\n"
     ]
    }
   ],
   "source": [
    "unigrams = {}\n",
    "\n",
    "for key, value in tokenized_texts.items():\n",
    "    unigram_list = wordpunct_tokenize(value)\n",
    "    cleanwords = [wordcleaner(w) for w in unigram_list]\n",
    "    unigrams[key] = cleanwords\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    filename = f\"./tokenized/{key}.txt\"\n",
    "    write_words_to_file(value, filename, words_per_line=20)\n",
    "    print(f\"Saved content for '{key}' to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d044c3f8-9aab-4362-8b85-a3709e228a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram texts:\n",
      "Recueil_corrected\n"
     ]
    }
   ],
   "source": [
    "print(\"Unigram texts:\")\n",
    "for key in unigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51492bb5-b662-4e41-bf0d-35e2bd3e3e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Counts:\n",
      "Recueil_corrected\n",
      "First 25 items in Recueil_corrected:\n",
      ": 6756\n",
      "de: 918\n",
      "le: 443\n",
      "que: 331\n",
      "la: 329\n",
      "à: 319\n",
      "qu: 308\n",
      "les: 296\n",
      "l: 252\n",
      "en: 242\n",
      "des: 219\n",
      "il: 216\n",
      "pour: 190\n",
      "qui: 189\n",
      "du: 187\n",
      "d: 176\n",
      "roy: 174\n",
      "par: 155\n",
      "ce: 154\n",
      "a: 140\n",
      "au: 136\n",
      "e: 127\n",
      "estats: 119\n",
      "s: 111\n",
      "ne: 103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count up the tokens using a Counter() object\n",
    "unigram_counts = {}\n",
    "for key, value in unigrams.items():\n",
    "    unigram_counts_dict = Counter(value)\n",
    "    unigram_counts[key] = unigram_counts_dict\n",
    "\n",
    "print(\"Unigram Counts:\")\n",
    "for key in unigram_counts:\n",
    "    print(key)\n",
    "\n",
    "print_first_n_items(unigram_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1300638a-16da-4c7f-8e9c-1de304b45009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in Recueil_corrected:\n",
      "roy: 174\n",
      "estats: 119\n",
      "deputez: 93\n",
      "estat: 84\n",
      "tiers: 76\n",
      "faire: 66\n",
      "france: 65\n",
      "fait: 60\n",
      "ledit: 47\n",
      "re: 47\n",
      "autres: 46\n",
      "fur: 46\n",
      "apres: 44\n",
      "iour: 39\n",
      "dudit: 39\n",
      "plus: 36\n",
      "trois: 34\n",
      "tous: 34\n",
      "bien: 33\n",
      "leurs: 32\n",
      "comme: 32\n",
      "president: 32\n",
      "dit: 32\n",
      "bodin: 31\n",
      "assemblee: 31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove specified keys from the dictionary\n",
    "stripped_unigrams = remove_keys_from_nested_dict(unigram_counts, stopwords)\n",
    "\n",
    "print_first_n_items(stripped_unigrams, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2d63ded-ea90-4894-af13-c8373b235afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Recueil_corrected_unigram_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(stripped_unigrams, output_folder, 'unigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d6661b6-baf5-47d8-a58b-49bfedc0a32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams:\n",
      "Recueil_corrected\n"
     ]
    }
   ],
   "source": [
    "bigrams = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    #unigram_list = [word for word in value]\n",
    "    bigrams_list = list(nltk.bigrams(unigram_list))\n",
    "    bigrams[key] = bigrams_list\n",
    "\n",
    "print(\"Bigrams:\")\n",
    "for key in bigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24b278bb-d5b9-436c-8a31-3d626532ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Counts:\n",
      "Recueil_corrected\n",
      "First 25 items in Recueil_corrected:\n",
      "tiers estat: 52\n",
      "dudit mois: 11\n",
      "roy nauarre: 11\n",
      "iour mesme: 10\n",
      "trois estats: 9\n",
      "ledit bodin: 9\n",
      "dudit moys: 7\n",
      "tous deputez: 7\n",
      "royne mere: 6\n",
      "roy feroit: 6\n",
      "quelques autres: 6\n",
      "autres estats: 6\n",
      "deux millions: 6\n",
      "bonne part: 6\n",
      "ledit sieur: 6\n",
      "trois ordres: 5\n",
      "ceiour mesme: 5\n",
      "dutiers estat: 5\n",
      "bodin deputé: 5\n",
      "deputé vermandois: 5\n",
      "cayer general: 5\n",
      "assemblee tiers: 5\n",
      "leurs cayers: 5\n",
      "quelques vns: 5\n",
      "quelques deputez: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bigram_counts = {}\n",
    "\n",
    "for key, value in bigrams.items():\n",
    "    string_bigrams = convert_tuple_bigrams(value)\n",
    "    bigramCount = convert_strings_to_counts(string_bigrams)\n",
    "    bigram_counts[key] = bigramCount\n",
    "\n",
    "print(\"Bigram Counts:\")\n",
    "for key in bigram_counts:\n",
    "    print(key)\n",
    "\n",
    "print_first_n_items(bigram_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c4eb003-3c3c-4d9e-b5e9-1979bd1a3fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Recueil_corrected_bigram_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(bigram_counts, output_folder, 'bigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfe978cd-c9e2-46c6-9c37-fbb524fbbd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigrams:\n",
      "Recueil_corrected\n"
     ]
    }
   ],
   "source": [
    "trigrams = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    #unigram_list = [word for word in value]\n",
    "    trigrams_list = list(nltk.trigrams(unigram_list))\n",
    "    trigrams[key] = trigrams_list\n",
    "\n",
    "print(\"Trigrams:\")\n",
    "for key in bigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b2a5667-7557-49d9-9904-184526684891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram Counts:\n",
      "Recueil_corrected\n",
      "First 25 items in Recueil_corrected:\n",
      "president tiers estat: 4\n",
      "iour dudit mois: 4\n",
      "tiers estat af: 3\n",
      "roy feroit fupplie: 3\n",
      "deputez trois ordres: 2\n",
      "bodin deputé vermandois: 2\n",
      "fes fuiets religion: 2\n",
      "assemblee tiers estat: 2\n",
      "ledit tiers estat: 2\n",
      "arrest deniers tail: 2\n",
      "deniers tail taillon: 2\n",
      "prendre bonne part: 2\n",
      "fuy uant auis: 2\n",
      "troy xv millions: 2\n",
      "ledit bodin deputé: 2\n",
      "prises bonne part: 2\n",
      "feruice roy repos: 2\n",
      "dudit mois trois: 2\n",
      "deputez autres estats: 2\n",
      "deputez trois estats: 2\n",
      "heure apres midy: 2\n",
      "decifió defdits cayers: 2\n",
      "consentir alienatió domaine: 2\n",
      "feurier mil cinq: 2\n",
      "ledit sieur marefchal: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trigram_counts = {}\n",
    "\n",
    "for key, value in trigrams.items():\n",
    "    string_trigrams = convert_tuple_trigrams(value)\n",
    "    trigramCount = convert_strings_to_counts(string_trigrams)\n",
    "    trigram_counts[key] = trigramCount\n",
    "\n",
    "print(\"Trigram Counts:\")\n",
    "for key in trigram_counts:\n",
    "    print(key)\n",
    "    \n",
    "print_first_n_items(trigram_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d36ad6c4-4f5b-4d15-b463-25318d4095b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Recueil_corrected_trigram_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(trigram_counts, output_folder, 'trigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7121f0e2-df9e-4b21-b929-144d4279227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collocations:\n",
      "Recueil_corrected\n"
     ]
    }
   ],
   "source": [
    "colloc_dict = {}\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    #unigram_list = [word for word in value]\n",
    "    bigram_finder = BigramCollocationFinder.from_words(unigram_list)\n",
    "    bigram_finder.apply_freq_filter(5)   # make sure all collocations have occured at least 5 times\n",
    "    collocations = bigram_finder.nbest(BigramAssocMeasures.pmi, 500)\n",
    "    colloc_dict[key] = collocations\n",
    "\n",
    "print(\"Collocations:\")\n",
    "for key, value in colloc_dict.items():\n",
    "    print(key)\n",
    "    #for w1, w2 in value:\n",
    "        #print(' ', w1, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9613500d-ed13-4efa-a107-32c8ce7ef52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collocation Counts:\n",
      "Recueil_corrected\n",
      "First 25 items in Recueil_corrected:\n",
      "royne mere: 1\n",
      "deputé vermandois: 1\n",
      "ceiour mesme: 1\n",
      "bonne part: 1\n",
      "dudit moys: 1\n",
      "cayer general: 1\n",
      "deux millions: 1\n",
      "trois ordres: 1\n",
      "dudit mois: 1\n",
      "quelques vns: 1\n",
      "dutiers estat: 1\n",
      "iour mesme: 1\n",
      "ledit sieur: 1\n",
      "leurs cayers: 1\n",
      "bodin deputé: 1\n",
      "tiers estat: 1\n",
      "ledit bodin: 1\n",
      "quelques autres: 1\n",
      "roy nauarre: 1\n",
      "trois estats: 1\n",
      "tous deputez: 1\n",
      "assemblee tiers: 1\n",
      "roy feroit: 1\n",
      "autres estats: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "colloc_counts = {}\n",
    "\n",
    "for key, value in colloc_dict.items():\n",
    "    string_bigrams = convert_tuple_bigrams(value)\n",
    "    bigramCount = convert_strings_to_counts(string_bigrams)\n",
    "    colloc_counts[key] = string_bigrams\n",
    "    colloc_counts[key] = bigramCount\n",
    "\n",
    "print(\"Collocation Counts:\")\n",
    "for key in colloc_counts:\n",
    "    print(key)\n",
    "print_first_n_items(colloc_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1956da3-dab0-4e63-ac2e-a98f2d1874d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Recueil_corrected_collocation_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(colloc_counts, output_folder, 'collocation_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34b96f32-cba0-421c-b290-640bf7e458cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in Recueil_corrected:\n",
      "deniers tail taillon: 1\n",
      "arrest deniers tail: 1\n",
      "fuy uant auis: 1\n",
      "troy xv millions: 1\n",
      "feurier mil cinq: 1\n",
      "consentir alienatió domaine: 1\n",
      "heure apres midy: 1\n",
      "decifió defdits cayers: 1\n",
      "prises bonne part: 1\n",
      "prendre bonne part: 1\n",
      "ledit sieur marefchal: 1\n",
      "fes fuiets religion: 1\n",
      "bodin deputé vermandois: 1\n",
      "roy feroit fupplie: 1\n",
      "iour dudit mois: 1\n",
      "feruice roy repos: 1\n",
      "dudit mois trois: 1\n",
      "ledit bodin deputé: 1\n",
      "deputez trois ordres: 1\n",
      "tiers estat af: 1\n",
      "president tiers estat: 1\n",
      "assemblee tiers estat: 1\n",
      "ledit tiers estat: 1\n",
      "deputez trois estats: 1\n",
      "deputez autres estats: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trigram_measures_dict = {}\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    #unigram_list = [word for word in value]\n",
    "    trigram_finder = TrigramCollocationFinder.from_words(unigram_list)\n",
    "    trigram_finder.apply_freq_filter(2)   # make sure all collocations have occured at least 5 times\n",
    "    collocations = trigram_finder.nbest(TrigramAssocMeasures.pmi, 25)\n",
    "    trigram_measures_dict[key] = collocations\n",
    "\n",
    "trigram_colloc_counts = {}\n",
    "\n",
    "for key, value in trigram_measures_dict.items():\n",
    "    string_trigrams = convert_tuple_trigrams(value)\n",
    "    trigramCount = convert_strings_to_counts(string_trigrams)\n",
    "    trigram_colloc_counts[key] = string_trigrams\n",
    "    trigram_colloc_counts[key] = trigramCount\n",
    "\n",
    "print_first_n_items(trigram_colloc_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3721ffd2-e594-4585-a534-70cc81354e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Recueil_corrected_trigram_collocation_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(trigram_colloc_counts, output_folder, 'trigram_collocation_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7e2f4d1-a0cd-4382-ac98-0458ffe95edd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underscore Dictionary:\n",
      "Recueil_corrected\n"
     ]
    }
   ],
   "source": [
    "underscore_dict = {}\n",
    "for key, value in unigrams.items():\n",
    "\n",
    "    tokenized_words = unigrams.get(key)\n",
    "    collocations = colloc_dict.get(key)\n",
    "    \n",
    "    colloc_words = []\n",
    "    \n",
    "    # Iterate through the words making new versions combining collocations\n",
    "    i = 0\n",
    "    while i < len(tokenized_words) - 1:\n",
    "        # If we find a collocation, add and advance by two words\n",
    "        if (tokenized_words[i], tokenized_words[i + 1]) in collocations:\n",
    "            colloc_words.append('_'.join((tokenized_words[i], tokenized_words[i + 1])))\n",
    "            i += 2\n",
    "        # Otherwise, advance by one word\n",
    "        else:\n",
    "            colloc_words.append(tokenized_words[i])\n",
    "            i += 1\n",
    "\n",
    "    # Add the last word (if any)\n",
    "    if i == len(tokenized_words) - 1:\n",
    "        colloc_words.append(tokenized_words[i])\n",
    "    underscore_dict[key] = colloc_words\n",
    "\n",
    "print(\"Underscore Dictionary:\")\n",
    "for key in underscore_dict:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b482ee5a-560f-46e2-8c2a-13162fb7ccaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recueil_corrected_underscore_bigrams.txt in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "write_dict_to_files_with_suffix(underscore_dict, output_folder, 'underscore_bigrams')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
