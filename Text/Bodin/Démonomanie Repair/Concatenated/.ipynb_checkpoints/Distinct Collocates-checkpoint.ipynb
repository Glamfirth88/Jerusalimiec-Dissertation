{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f552b717-4764-4e79-b88f-765ac588cf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Current Working Directory\n",
      "1. tokenized\n",
      "2. concordances\n",
      "3. final\n",
      "4. .ipynb_checkpoints\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select a subfolder by number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select .txt files to establish global word counts\n",
      "1. Démonomanie Repair_corrected_underscore_bigrams.txt\n",
      "2. Démonomanie Repair_corrected.txt\n",
      "Enter the numbers of the text files you want to select, separated by spaces (e.g., '1 3 5'): \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 1 2\n",
      "Enter words to find their collocate concordances (separated by spaces):  malade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a subdirectory for the stopwords csv file:\n",
      "0. Current Working Directory\n",
      "2. tokenized\n",
      "3. concordances\n",
      "4. final\n",
      "5. .ipynb_checkpoints\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. spellcheck_data.csv\n",
      "2. stop_words.csv\n",
      "Enter the numbers of the text files you want to select, separated by spaces (e.g., '1 3 5'): \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 2\n",
      "Enter the value of alpha (default is 0.10):  0.95\n",
      "Exclude target term 'malade' from concordance (yes/no)?  no\n",
      "Enter the window size for concordance for 'malade':  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Démonomanie Repair_corrected_underscore_bigrams.txt\n",
      "2. Démonomanie Repair_corrected.txt\n",
      "Enter the numbers of the text files you want to use for KWIC and counts, separated by spaces (e.g., '1 3 5'): \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance for the token \"malade\" has been saved to concordances/malade_MDC.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import csv\n",
    "from scipy.stats import fisher_exact\n",
    "\n",
    "# Function to list subfolders in the current directory\n",
    "def list_subfolders():\n",
    "    return [f.name for f in os.scandir() if f.is_dir()]\n",
    "\n",
    "# Function to prompt the user to select a subfolder\n",
    "def prompt_subfolder(subfolders):\n",
    "    print(\"0. Current Working Directory\")\n",
    "    for index, folder in enumerate(subfolders, start=1):\n",
    "        print(f\"{index}. {folder}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Select a subfolder by number: \"))\n",
    "            if 0 <= choice <= len(subfolders):\n",
    "                return None if choice == 0 else subfolders[choice - 1]\n",
    "            else:\n",
    "                print(\"Invalid selection. Please try again.\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a number.\")\n",
    "\n",
    "# Function to find text files in a subfolder\n",
    "def find_text_files(subfolder):\n",
    "    text_files = [f for f in os.listdir(subfolder) if f.endswith('.txt')]\n",
    "    return text_files\n",
    "\n",
    "# Function to find CSV files in a subfolder\n",
    "def find_csv_files(subfolder):\n",
    "    csv_files = [f for f in os.listdir(subfolder) if f.endswith('.csv')]\n",
    "    return csv_files\n",
    "\n",
    "# Function to prompt the user to select multiple text files\n",
    "def prompt_text_files(text_files):\n",
    "    selected_files = []\n",
    "    for index, file in enumerate(text_files, start=1):\n",
    "        print(f\"{index}. {file}\")\n",
    "    print(\"Enter the numbers of the text files you want to select, separated by spaces (e.g., '1 3 5'): \")\n",
    "    while True:\n",
    "        try:\n",
    "            choices = list(map(int, input().split()))\n",
    "            if all(1 <= choice <= len(text_files) for choice in choices):\n",
    "                selected_files = [text_files[choice - 1] for choice in choices]\n",
    "                return selected_files\n",
    "            else:\n",
    "                print(\"Invalid selection. Please try again.\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter numbers separated by spaces.\")\n",
    "\n",
    "# Function to process the selected text files and combine them into a single corpus\n",
    "def process_text_files(file_paths):\n",
    "    combined_text = \"\"\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as f:\n",
    "            file_contents = f.read().lower()\n",
    "            combined_text += file_contents + \" \"\n",
    "    tokens = nltk.wordpunct_tokenize(combined_text)\n",
    "    text = nltk.Text(tokens)\n",
    "    return text\n",
    "\n",
    "# Function to prompt the user to select a subset of text files for KWIC and counts\n",
    "def prompt_subset_files(text_files):\n",
    "    selected_files = []\n",
    "    for index, file in enumerate(text_files, start=1):\n",
    "        print(f\"{index}. {file}\")\n",
    "    print(\"Enter the numbers of the text files you want to use for KWIC and counts, separated by spaces (e.g., '1 3 5'): \")\n",
    "    while True:\n",
    "        try:\n",
    "            choices = list(map(int, input().split()))\n",
    "            if all(1 <= choice <= len(text_files) for choice in choices):\n",
    "                selected_files = [text_files[choice - 1] for choice in choices]\n",
    "                return selected_files\n",
    "            else:\n",
    "                print(\"Invalid selection. Please try again.\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter numbers separated by spaces.\")\n",
    "\n",
    "# Function to process the subset of text files for KWIC and counts\n",
    "def process_subset_files(file_paths):\n",
    "    combined_text = \"\"\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as f:\n",
    "            file_contents = f.read().lower()\n",
    "            combined_text += file_contents + \" \"\n",
    "    tokens = nltk.wordpunct_tokenize(combined_text)\n",
    "    return tokens\n",
    "\n",
    "def get_kwic(sometargetterm, somelistofwords, window=10, excl_target=True):\n",
    "    kwics = []\n",
    "    for n, w in enumerate(somelistofwords):\n",
    "        if w == sometargetterm:\n",
    "            start = max(0, n - window)\n",
    "            end = min(n + window + 1, len(somelistofwords))\n",
    "            if excl_target:\n",
    "                k = somelistofwords[start:n] + somelistofwords[n + 1:end]\n",
    "            else:\n",
    "                k = somelistofwords[start:end]\n",
    "            kwics.append(k)\n",
    "    return kwics\n",
    "\n",
    "def add_to_count_dict(word, count_dict):\n",
    "    if word in count_dict:\n",
    "        count_dict[word] += 1\n",
    "    else:\n",
    "        count_dict[word] = 1\n",
    "\n",
    "def get_fishers(someword, somecountdict, someratedict, alternative='greater'):\n",
    "    r = someratedict[someword]\n",
    "    wc = sum(somecountdict.values())\n",
    "    a = somecountdict[someword]\n",
    "    b = wc - a\n",
    "    c = round(r * wc)\n",
    "    d = wc - c\n",
    "    p = fisher_exact([[a, b], [c, d]], alternative=alternative)[1]\n",
    "    return p\n",
    "\n",
    "def search_concordance(text_data, tokens):\n",
    "    alpha = input(\"Enter the value of alpha (default is 0.10): \").strip()\n",
    "    alpha = float(alpha) if alpha else 0.10\n",
    "    for token in tokens:\n",
    "        # Create the directory if it does not exist\n",
    "        directory = 'concordances'\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        # Create a filename for each token\n",
    "        filename = f\"{token}_MDC.csv\"\n",
    "        file_path = os.path.join(directory, filename)\n",
    "\n",
    "        excl_target = input(f\"Exclude target term '{token}' from concordance (yes/no)? \").strip().lower() == 'yes'\n",
    "        window = int(input(f\"Enter the window size for concordance for '{token}': \").strip())\n",
    "\n",
    "        with open(file_path, 'w', newline='') as csvfile:\n",
    "            fieldnames = ['Collocate', 'Count', 'Frequency', 'obs/exp', 'p-value']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "\n",
    "            words = text_data.tokens\n",
    "            subset_files = prompt_subset_files(text_files)\n",
    "            subset_tokens = process_subset_files([os.path.join(subfolder_path, file) for file in subset_files])\n",
    "            kwics = get_kwic(token, subset_tokens, window, excl_target)\n",
    "            counts = {}\n",
    "            for k in kwics:\n",
    "                for w in k:\n",
    "                    add_to_count_dict(w, counts)\n",
    "            total_wc = sum(counts.values())\n",
    "            rates = {word: count / total_wc for word, count in counts.items()}\n",
    "            for word, count in sorted(counts.items(), key=lambda item: item[1], reverse=True):\n",
    "                if word not in stops:\n",
    "                    p_value = get_fishers(word, counts, rates)\n",
    "                    if p_value < alpha:\n",
    "                        frequency = count / total_wc\n",
    "                        exp = rates[word] * total_wc\n",
    "                        obs_exp = count / exp\n",
    "                        writer.writerow({'Collocate': word, 'Count': count, 'Frequency': frequency, 'obs/exp': obs_exp, 'p-value': p_value})\n",
    "\n",
    "        print(f'Concordance for the token \"{token}\" has been saved to {file_path}')\n",
    "\n",
    "def choose_subdirectory(subdirectories):\n",
    "    print(\"Select a subdirectory for the stopwords csv file:\")\n",
    "    print(\"0. Current Working Directory\")\n",
    "    for i, subdir in enumerate(subdirectories, start=1):\n",
    "        print(f\"{i + 1}. {subdir}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter your choice: \"))\n",
    "            if 0 <= choice <= len(subdirectories):\n",
    "                return None if choice == 0 else subdirectories[choice - 1]\n",
    "            else:\n",
    "                print(\"Invalid selection. Please try again.\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a number.\")\n",
    "\n",
    "def read_stopwords(filepath):\n",
    "    with open(filepath, 'r', encoding='latin-1') as file:\n",
    "        reader = csv.reader(file)\n",
    "        stopwords = []\n",
    "        for row in reader:\n",
    "            for word in row:\n",
    "                stopwords.extend(word.split(','))\n",
    "        return [word.strip() for word in stopwords]\n",
    "\n",
    "subfolders = list_subfolders()\n",
    "if subfolders:\n",
    "    selected_subfolder = prompt_subfolder(subfolders)\n",
    "    subfolder_path = os.getcwd() if selected_subfolder is None else os.path.join(os.getcwd(), selected_subfolder)\n",
    "    text_files = find_text_files(subfolder_path)\n",
    "    if text_files:\n",
    "        print('Select .txt files to establish global word counts')\n",
    "        selected_files = prompt_text_files(text_files)\n",
    "        full_file_paths = [os.path.join(subfolder_path, file) for file in selected_files]\n",
    "        text_data = process_text_files(full_file_paths)\n",
    "    else:\n",
    "        print(f\"No text files found in '{selected_subfolder}'.\")\n",
    "else:\n",
    "    print(\"No subfolders found in the current directory.\")\n",
    "\n",
    "# Example usage\n",
    "user_input = input(\"Enter words to find their collocate concordances (separated by spaces): \").lower()\n",
    "tokens = [word.strip() for word in user_input.split(' ')]  # Split the input into a list of tokens\n",
    "\n",
    "stopwords_subfolders = list_subfolders()\n",
    "if stopwords_subfolders:\n",
    "    selected_stopwords_subfolder = choose_subdirectory(stopwords_subfolders)\n",
    "    stopwords_subfolder_path = os.getcwd() if selected_stopwords_subfolder is None else os.path.join(os.getcwd(), selected_stopwords_subfolder)\n",
    "    stopwords_files = find_csv_files(stopwords_subfolder_path)\n",
    "    if stopwords_files:\n",
    "        chosen_stopwords_file = prompt_text_files(stopwords_files)[0]  # Select the first file from the list\n",
    "        chosen_csv_file_path = os.path.join(stopwords_subfolder_path, chosen_stopwords_file)\n",
    "        stops = read_stopwords(chosen_csv_file_path)\n",
    "        search_concordance(text_data, tokens)\n",
    "    else:\n",
    "            print(f\"No stopwords files found in '{selected_stopwords_subfolder}'.\")\n",
    "else:\n",
    "    print(\"No subfolders found in the current directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
