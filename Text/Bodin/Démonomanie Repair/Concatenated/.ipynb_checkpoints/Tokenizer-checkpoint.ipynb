{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54bf6974-56fe-490b-9b06-61bd6634a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize,wordpunct_tokenize\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures, TrigramCollocationFinder, TrigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d91501f-4ea8-4a51-80e4-5b2c3d87f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/lucas-jerusalimiec/Documents/OCR Text/Notebooks\")\n",
    "from tokenizer_func  import (wordcleaner, write_words_to_file, dictionary_to_file, convert_tuple_bigrams,\n",
    "convert_tuple_trigrams)\n",
    "\n",
    "from extra_token_func import print_first_n_items, remove_keys_from_nested_dict\n",
    "\n",
    "from additional_token_func import convert_strings_to_counts\n",
    "\n",
    "from dict_write import write_dict_to_files_with_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d557ac9-168b-4b35-ac00-28687dd85cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tokenized/\n",
      "Text files in the spellchecked directory: ['final/Démonomanie Repair_corrected.txt']\n"
     ]
    }
   ],
   "source": [
    "text_loc = Path(\"./final\")\n",
    "text_files = glob.glob(f\"{text_loc}/*.txt\")\n",
    "output_folder = './tokenized/'\n",
    "tokenized_folder = Path(output_folder)\n",
    "tokenized_folder.mkdir(exist_ok=True)\n",
    "print(output_folder)\n",
    "print(\"Text files in the spellchecked directory:\", text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b085009a-d824-4bf2-aedc-fd567abf2dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw texts: ['Démonomanie Repair_corrected']\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = {}\n",
    "for txt in text_files:\n",
    "    with open(txt, 'r') as f:\n",
    "        content = f.read()\n",
    "        file_name = txt.split('\\\\')[-1]\n",
    "        #key = file_name.split('.')[0]\n",
    "        key = os.path.splitext(os.path.basename(file_name))[0]\n",
    "        tokenized_texts[key] = content\n",
    "print(\"Raw texts:\", list(tokenized_texts.keys()))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f8cc71e-5849-4195-8b5c-585cc06d2916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved content for 'Démonomanie Repair_corrected' to ./tokenized/Démonomanie Repair_corrected.txt\n"
     ]
    }
   ],
   "source": [
    "unigrams = {}\n",
    "\n",
    "for key, value in tokenized_texts.items():\n",
    "    unigram_list = wordpunct_tokenize(value)\n",
    "    cleanwords = [wordcleaner(w) for w in unigram_list]\n",
    "    unigrams[key] = cleanwords\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    filename = f\"./tokenized/{key}.txt\"\n",
    "    write_words_to_file(value, filename, words_per_line=20)\n",
    "    print(f\"Saved content for '{key}' to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d044c3f8-9aab-4362-8b85-a3709e228a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram texts:\n",
      "Démonomanie Repair_corrected\n"
     ]
    }
   ],
   "source": [
    "print(\"Unigram texts:\")\n",
    "for key in unigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51492bb5-b662-4e41-bf0d-35e2bd3e3e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Counts:\n",
      "Démonomanie Repair_corrected\n"
     ]
    }
   ],
   "source": [
    "# Count up the tokens using a Counter() object\n",
    "unigram_counts = {}\n",
    "for key, value in unigrams.items():\n",
    "    unigram_counts_dict = Counter(value)\n",
    "    unigram_counts[key] = unigram_counts_dict\n",
    "\n",
    "print(\"Unigram Counts:\")\n",
    "for key in unigram_counts:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47725d22-cfe1-4bae-80a7-1dd079591dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in Démonomanie Repair_corrected:\n",
      ": 40772\n",
      "de: 3351\n",
      "que: 1896\n",
      "la: 1678\n",
      "qu: 1667\n",
      "les: 1641\n",
      "en: 1564\n",
      "il: 1543\n",
      "qui: 1511\n",
      "à: 1281\n",
      "d: 1278\n",
      "l: 1260\n",
      "le: 1233\n",
      "des: 1102\n",
      "eft: 897\n",
      "a: 752\n",
      "pour: 731\n",
      "ne: 729\n",
      "c: 725\n",
      "n: 665\n",
      "ce: 651\n",
      "par: 649\n",
      "on: 641\n",
      "dieu: 640\n",
      "vn: 616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_first_n_items(unigram_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fa6226b-1236-4eb7-b4b3-7b8c79c0a6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['auoit', 'fa', 'eftoit', 'eftre', 'auoir', '', 'x', 'v', 'ee', 'p']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open stopwords CSV file and list the contents\n",
    "with open('./stop_words.csv', 'r') as f:\n",
    "    stopwords = f.read().strip().split(\",\")\n",
    "stopwords[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1300638a-16da-4c7f-8e9c-1de304b45009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in Démonomanie Repair_corrected:\n",
      "dieu: 640\n",
      "comme: 462\n",
      "plus: 412\n",
      "sorciers: 355\n",
      "bien: 298\n",
      "livre: 261\n",
      "faire: 232\n",
      "autres: 221\n",
      "diable: 210\n",
      "di: 207\n",
      "peut: 191\n",
      "in: 189\n",
      "tous: 177\n",
      "dit: 175\n",
      "point: 174\n",
      "fur: 167\n",
      "dela: 164\n",
      "faut: 162\n",
      "mort: 162\n",
      "sathan: 160\n",
      "quand: 158\n",
      "dire: 149\n",
      "tout: 146\n",
      "re: 144\n",
      "apres: 143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove specified keys from the dictionary\n",
    "stripped_unigrams = remove_keys_from_nested_dict(unigram_counts, stopwords)\n",
    "\n",
    "print_first_n_items(stripped_unigrams, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2d63ded-ea90-4894-af13-c8373b235afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Démonomanie Repair_corrected_unigram_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(stripped_unigrams, output_folder, 'unigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d6661b6-baf5-47d8-a58b-49bfedc0a32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams:\n",
      "Démonomanie Repair_corrected\n"
     ]
    }
   ],
   "source": [
    "bigrams = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    bigrams_list = list(nltk.bigrams(unigram_list))\n",
    "    bigrams[key] = bigrams_list\n",
    "\n",
    "print(\"Bigrams:\")\n",
    "for key in bigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24b278bb-d5b9-436c-8a31-3d626532ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Counts:\n",
      "Démonomanie Repair_corrected\n"
     ]
    }
   ],
   "source": [
    "bigram_counts = {}\n",
    "\n",
    "for key, value in bigrams.items():\n",
    "    string_bigrams = convert_tuple_bigrams(value)\n",
    "    bigramCount = convert_strings_to_counts(string_bigrams)\n",
    "    bigram_counts[key] = bigramCount\n",
    "\n",
    "print(\"Bigram Counts:\")\n",
    "for key in bigram_counts:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abf68090-62ec-4069-a472-7b7dbe6e7c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in Démonomanie Repair_corrected:\n",
      "livre second: 45\n",
      "livre premier: 41\n",
      "loy dieu: 35\n",
      "malins esprits: 28\n",
      "quelque chose: 24\n",
      "cas pareil: 24\n",
      "livre qvatriesme: 23\n",
      "comme dit: 21\n",
      "comme di: 20\n",
      "plus grand: 19\n",
      "livre troisiesme: 19\n",
      "malings esprits: 17\n",
      "cy dessus: 17\n",
      "bien fort: 16\n",
      "peut faire: 15\n",
      "cy apres: 14\n",
      "dieu comme: 14\n",
      "comme dict: 14\n",
      "mil cinq: 14\n",
      "encores plus: 13\n",
      "faut donc: 13\n",
      "autres choses: 13\n",
      "faire mourir: 13\n",
      "cinq cens: 13\n",
      "livre troisieme: 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_first_n_items(bigram_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c4eb003-3c3c-4d9e-b5e9-1979bd1a3fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Démonomanie Repair_corrected_bigram_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(bigram_counts, output_folder, 'bigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfe978cd-c9e2-46c6-9c37-fbb524fbbd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigrams:\n",
      "Démonomanie Repair_corrected\n"
     ]
    }
   ],
   "source": [
    "trigrams = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    trigrams_list = list(nltk.trigrams(unigram_list))\n",
    "    trigrams[key] = trigrams_list\n",
    "\n",
    "print(\"Trigrams:\")\n",
    "for key in bigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b2a5667-7557-49d9-9904-184526684891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram Counts:\n",
      "Démonomanie Repair_corrected\n"
     ]
    }
   ],
   "source": [
    "trigram_counts = {}\n",
    "\n",
    "for key, value in trigrams.items():\n",
    "    string_trigrams = convert_tuple_trigrams(value)\n",
    "    trigramCount = convert_strings_to_counts(string_trigrams)\n",
    "    trigram_counts[key] = trigramCount\n",
    "\n",
    "print(\"Trigram Counts:\")\n",
    "for key in trigram_counts:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43910dd4-8a43-4800-8068-8f582f5a0bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in Démonomanie Repair_corrected:\n",
      "mil cinq cens: 12\n",
      "an mil cinq: 8\n",
      "dirons cy apres: 7\n",
      "plus forte raifon: 6\n",
      "dela loy dieu: 6\n",
      "comme cas pareil: 6\n",
      "prince dela mirande: 5\n",
      "paruenir quelque chose: 5\n",
      "livre morbo facro: 5\n",
      "deux iours apres: 4\n",
      "plus grands sorciers: 4\n",
      "ie mettray point: 4\n",
      "monftré cy dessus: 4\n",
      "bruflee toute viue: 4\n",
      "cinq cens cinquante: 4\n",
      "ceste ville laon: 4\n",
      "tefmoing fans reproche: 4\n",
      "deux trois heures: 3\n",
      "quel esprit dieu: 3\n",
      "plus deteftables sorciers: 3\n",
      "comme auons dict: 3\n",
      "fait bien noter: 3\n",
      "comme dirons cy: 3\n",
      "dela ville laon: 3\n",
      "defendu parlaloy dieu: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_first_n_items(trigram_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d36ad6c4-4f5b-4d15-b463-25318d4095b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Démonomanie Repair_corrected_trigram_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(trigram_counts, output_folder, 'trigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7121f0e2-df9e-4b21-b929-144d4279227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collocations:\n",
      "Démonomanie Repair_corrected\n"
     ]
    }
   ],
   "source": [
    "colloc_dict = {}\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    bigram_finder = BigramCollocationFinder.from_words(unigram_list)\n",
    "    bigram_finder.apply_freq_filter(5)   # make sure all collocations have occured at least 5 times\n",
    "    collocations = bigram_finder.nbest(BigramAssocMeasures.pmi, 500)\n",
    "    colloc_dict[key] = collocations\n",
    "\n",
    "print(\"Collocations:\")\n",
    "for key, value in colloc_dict.items():\n",
    "    print(key)\n",
    "    #for w1, w2 in value:\n",
    "        #print(' ', w1, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9613500d-ed13-4efa-a107-32c8ce7ef52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collocation Counts:\n",
      "Démonomanie Repair_corrected\n"
     ]
    }
   ],
   "source": [
    "colloc_counts = {}\n",
    "\n",
    "for key, value in colloc_dict.items():\n",
    "    string_bigrams = convert_tuple_bigrams(value)\n",
    "    bigramCount = convert_strings_to_counts(string_bigrams)\n",
    "    colloc_counts[key] = string_bigrams\n",
    "    colloc_counts[key] = bigramCount\n",
    "\n",
    "print(\"Collocation Counts:\")\n",
    "for key in colloc_counts:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1814b84-b707-4058-9a98-0debd4f90c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in Démonomanie Repair_corrected:\n",
      "morbo facro: 1\n",
      "iefus chrift: 1\n",
      "paul grilland: 1\n",
      "thomas aquin: 1\n",
      "images cire: 1\n",
      "dia ble: 1\n",
      "genre humain: 1\n",
      "prefomptions violentes: 1\n",
      "grecs latins: 1\n",
      "demeurent accord: 1\n",
      "ville laon: 1\n",
      "caufes naturelles: 1\n",
      "ef prit: 1\n",
      "mal caduc: 1\n",
      "bons mauuais: 1\n",
      "cas pareil: 1\n",
      "figure humaine: 1\n",
      "cy deffus: 1\n",
      "mil cinq: 1\n",
      "long temps: 1\n",
      "aage douze: 1\n",
      "quei ay: 1\n",
      "cens cinquante: 1\n",
      "cinq cens: 1\n",
      "mefme autheur: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_first_n_items(colloc_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1956da3-dab0-4e63-ac2e-a98f2d1874d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Démonomanie Repair_corrected_collocation_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(colloc_counts, output_folder, 'collocation_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34b96f32-cba0-421c-b290-640bf7e458cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in Démonomanie Repair_corrected:\n",
      "naturam adit pana: 1\n",
      "bouuin bailly chafteau: 1\n",
      "felin ye nies: 1\n",
      "pres villiers cofterets: 1\n",
      "cognoift veué œil: 1\n",
      "vol oy feaux: 1\n",
      "pana non attraxerit: 1\n",
      "adam martin procureur: 1\n",
      "adit pana non: 1\n",
      "frappé maladie foudaine: 1\n",
      "aueugle pendu paris: 1\n",
      "bruflées toutes viues: 1\n",
      "vingt quatre heures: 1\n",
      "iln befoin efcrire: 1\n",
      "confirmatif dela fentence: 1\n",
      "maladies venues fortileges: 1\n",
      "maiftre adam martin: 1\n",
      "procureur roy ribemont: 1\n",
      "diminuer nombre mefchans: 1\n",
      "iour feurier mil: 1\n",
      "feurier mil cinq: 1\n",
      "ennemys genre humain: 1\n",
      "és crimes atroces: 1\n",
      "creé ciel laterre: 1\n",
      "magdeleine dela croix: 1\n",
      "\n",
      "Saved Démonomanie Repair_corrected_trigram_collocation_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "trigram_measures_dict = {}\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    trigram_finder = TrigramCollocationFinder.from_words(unigram_list)\n",
    "    trigram_finder.apply_freq_filter(2)   # make sure all collocations have occured at least 5 times\n",
    "    collocations = trigram_finder.nbest(TrigramAssocMeasures.pmi, 25)\n",
    "    trigram_measures_dict[key] = collocations\n",
    "\n",
    "trigram_colloc_counts = {}\n",
    "\n",
    "for key, value in trigram_measures_dict.items():\n",
    "    string_trigrams = convert_tuple_trigrams(value)\n",
    "    trigramCount = convert_strings_to_counts(string_trigrams)\n",
    "    trigram_colloc_counts[key] = string_trigrams\n",
    "    trigram_colloc_counts[key] = trigramCount\n",
    "\n",
    "print_first_n_items(trigram_colloc_counts, 25)\n",
    "\n",
    "dictionary_to_file(trigram_colloc_counts, output_folder, 'trigram_collocation_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7e2f4d1-a0cd-4382-ac98-0458ffe95edd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underscore Dictionary:\n",
      "Démonomanie Repair_corrected\n"
     ]
    }
   ],
   "source": [
    "underscore_dict = {}\n",
    "for key, value in unigrams.items():\n",
    "\n",
    "    tokenized_words = unigrams.get(key)\n",
    "    collocations = colloc_dict.get(key)\n",
    "    \n",
    "    colloc_words = []\n",
    "    \n",
    "    # Iterate through the words making new versions combining collocations\n",
    "    i = 0\n",
    "    while i < len(tokenized_words) - 1:\n",
    "        # If we find a collocation, add and advance by two words\n",
    "        if (tokenized_words[i], tokenized_words[i + 1]) in collocations:\n",
    "            colloc_words.append('_'.join((tokenized_words[i], tokenized_words[i + 1])))\n",
    "            i += 2\n",
    "        # Otherwise, advance by one word\n",
    "        else:\n",
    "            colloc_words.append(tokenized_words[i])\n",
    "            i += 1\n",
    "\n",
    "    # Add the last word (if any)\n",
    "    if i == len(tokenized_words) - 1:\n",
    "        colloc_words.append(tokenized_words[i])\n",
    "    underscore_dict[key] = colloc_words\n",
    "\n",
    "print(\"Underscore Dictionary:\")\n",
    "for key in underscore_dict:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b482ee5a-560f-46e2-8c2a-13162fb7ccaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démonomanie Repair_corrected_underscore_bigrams.txt in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "write_dict_to_files_with_suffix(underscore_dict, output_folder, 'underscore_bigrams')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
