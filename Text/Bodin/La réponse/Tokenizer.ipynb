{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54bf6974-56fe-490b-9b06-61bd6634a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize,wordpunct_tokenize\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures, TrigramCollocationFinder, TrigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d91501f-4ea8-4a51-80e4-5b2c3d87f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/lucas-jerusalimiec/Documents/OCR Text/Notebooks\")\n",
    "from tokenizer_func  import (wordcleaner, write_words_to_file, dictionary_to_file, convert_tuple_bigrams,\n",
    "convert_tuple_trigrams)\n",
    "\n",
    "from extra_token_func import print_first_n_items, remove_keys_from_nested_dict\n",
    "\n",
    "from additional_token_func import convert_strings_to_counts\n",
    "\n",
    "from dict_write import write_dict_to_files_with_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d557ac9-168b-4b35-ac00-28687dd85cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tokenized/\n",
      "Text files in the spellchecked directory: ['final/La réponse_corrected.txt']\n"
     ]
    }
   ],
   "source": [
    "text_loc = Path(\"./final\")\n",
    "text_files = glob.glob(f\"{text_loc}/*.txt\")\n",
    "output_folder = './tokenized/'\n",
    "tokenized_folder = Path(output_folder)\n",
    "tokenized_folder.mkdir(exist_ok=True)\n",
    "print(output_folder)\n",
    "print(\"Text files in the spellchecked directory:\", text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b085009a-d824-4bf2-aedc-fd567abf2dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw texts: ['La réponse_corrected']\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = {}\n",
    "for txt in text_files:\n",
    "    with open(txt, 'r') as f:\n",
    "        content = f.read()\n",
    "        file_name = txt.split('\\\\')[-1]\n",
    "        #key = file_name.split('.')[0]\n",
    "        key = os.path.splitext(os.path.basename(file_name))[0]\n",
    "        tokenized_texts[key] = content\n",
    "print(\"Raw texts:\", list(tokenized_texts.keys()))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f8cc71e-5849-4195-8b5c-585cc06d2916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved content for 'La réponse_corrected' to ./tokenized/La réponse_corrected.txt\n"
     ]
    }
   ],
   "source": [
    "unigrams = {}\n",
    "\n",
    "for key, value in tokenized_texts.items():\n",
    "    unigram_list = wordpunct_tokenize(value)\n",
    "    cleanwords = [wordcleaner(w) for w in unigram_list]\n",
    "    unigrams[key] = cleanwords\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    filename = f\"./tokenized/{key}.txt\"\n",
    "    write_words_to_file(value, filename, words_per_line=20)\n",
    "    print(f\"Saved content for '{key}' to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d044c3f8-9aab-4362-8b85-a3709e228a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram texts:\n",
      "La réponse_corrected\n"
     ]
    }
   ],
   "source": [
    "print(\"Unigram texts:\")\n",
    "for key in unigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51492bb5-b662-4e41-bf0d-35e2bd3e3e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Counts:\n",
      "La réponse_corrected\n"
     ]
    }
   ],
   "source": [
    "# Count up the tokens using a Counter() object\n",
    "unigram_counts = {}\n",
    "for key, value in unigrams.items():\n",
    "    unigram_counts_dict = Counter(value)\n",
    "    unigram_counts[key] = unigram_counts_dict\n",
    "\n",
    "print(\"Unigram Counts:\")\n",
    "for key in unigram_counts:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47725d22-cfe1-4bae-80a7-1dd079591dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in La réponse_corrected:\n",
      ": 5338\n",
      "de: 597\n",
      "d: 394\n",
      "en: 391\n",
      "la: 384\n",
      "l: 335\n",
      "le: 335\n",
      "à: 332\n",
      "qui: 302\n",
      "que: 300\n",
      "les: 285\n",
      "qu: 267\n",
      "il: 235\n",
      "pour: 196\n",
      "des: 180\n",
      "plus: 161\n",
      "eft: 161\n",
      "n: 157\n",
      "au: 145\n",
      "ne: 141\n",
      "ce: 136\n",
      "on: 130\n",
      "du: 130\n",
      "a: 117\n",
      "y: 108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_first_n_items(unigram_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fa6226b-1236-4eb7-b4b3-7b8c79c0a6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eftoit', 'eftre', 'auoir', '', 'x', 'v', 'ee', 'or', 'q', 'f']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open stopwords CSV file and list the contents\n",
    "with open('./stop_words.csv', 'r') as f:\n",
    "    stopwords = f.read().strip().split(\",\")\n",
    "stopwords[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1300638a-16da-4c7f-8e9c-1de304b45009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in La réponse_corrected:\n",
      "plus: 161\n",
      "argent: 100\n",
      "cens: 57\n",
      "comme: 57\n",
      "pris: 54\n",
      "peuple: 52\n",
      "sous: 50\n",
      "deux: 49\n",
      "bien: 48\n",
      "fait: 47\n",
      "trois: 46\n",
      "escus: 45\n",
      "mil: 45\n",
      "quatre: 44\n",
      "peu: 44\n",
      "tout: 43\n",
      "monnoye: 43\n",
      "ans: 42\n",
      "dix: 41\n",
      "choses: 40\n",
      "cinq: 40\n",
      "aussi: 39\n",
      "peut: 39\n",
      "an: 38\n",
      "depuis: 38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove specified keys from the dictionary\n",
    "stripped_unigrams = remove_keys_from_nested_dict(unigram_counts, stopwords)\n",
    "\n",
    "print_first_n_items(stripped_unigrams, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2d63ded-ea90-4894-af13-c8373b235afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved La réponse_corrected_unigram_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(stripped_unigrams, output_folder, 'unigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d6661b6-baf5-47d8-a58b-49bfedc0a32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams:\n",
      "La réponse_corrected\n"
     ]
    }
   ],
   "source": [
    "bigrams = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    bigrams_list = list(nltk.bigrams(unigram_list))\n",
    "    bigrams[key] = bigrams_list\n",
    "\n",
    "print(\"Bigrams:\")\n",
    "for key in bigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24b278bb-d5b9-436c-8a31-3d626532ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Counts:\n",
      "La réponse_corrected\n"
     ]
    }
   ],
   "source": [
    "bigram_counts = {}\n",
    "\n",
    "for key, value in bigrams.items():\n",
    "    string_bigrams = convert_tuple_bigrams(value)\n",
    "    bigramCount = convert_strings_to_counts(string_bigrams)\n",
    "    bigram_counts[key] = bigramCount\n",
    "\n",
    "print(\"Bigram Counts:\")\n",
    "for key in bigram_counts:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abf68090-62ec-4069-a472-7b7dbe6e7c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in La réponse_corrected:\n",
      "cinq cens: 13\n",
      "mil escus: 13\n",
      "cens ans: 10\n",
      "an cinq: 10\n",
      "beaucoup plus: 10\n",
      "quatre cens: 10\n",
      "deux cens: 9\n",
      "plus haut: 9\n",
      "trois cens: 8\n",
      "an mil: 8\n",
      "six den: 8\n",
      "cinq sous: 7\n",
      "cens mil: 7\n",
      "toutes choses: 6\n",
      "plus cher: 6\n",
      "peu pres: 6\n",
      "fois plus: 6\n",
      "meilleur conte: 6\n",
      "escus vieux: 6\n",
      "ay dit: 6\n",
      "peu peu: 5\n",
      "ans apres: 5\n",
      "cens vingt: 5\n",
      "foixante ans: 5\n",
      "dix fois: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_first_n_items(bigram_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c4eb003-3c3c-4d9e-b5e9-1979bd1a3fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved La réponse_corrected_bigram_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(bigram_counts, output_folder, 'bigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfe978cd-c9e2-46c6-9c37-fbb524fbbd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigrams:\n",
      "La réponse_corrected\n"
     ]
    }
   ],
   "source": [
    "trigrams = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    trigrams_list = list(nltk.trigrams(unigram_list))\n",
    "    trigrams[key] = trigrams_list\n",
    "\n",
    "print(\"Trigrams:\")\n",
    "for key in bigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b2a5667-7557-49d9-9904-184526684891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram Counts:\n",
      "La réponse_corrected\n"
     ]
    }
   ],
   "source": [
    "trigram_counts = {}\n",
    "\n",
    "for key, value in trigrams.items():\n",
    "    string_trigrams = convert_tuple_trigrams(value)\n",
    "    trigramCount = convert_strings_to_counts(string_trigrams)\n",
    "    trigram_counts[key] = trigramCount\n",
    "\n",
    "print(\"Trigram Counts:\")\n",
    "for key in trigram_counts:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43910dd4-8a43-4800-8068-8f582f5a0bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in La réponse_corrected:\n",
      "an cinq cens: 9\n",
      "trois cens ans: 6\n",
      "cens mil escus: 4\n",
      "cens vingt deux: 4\n",
      "an mil quatre: 4\n",
      "mil quatre cens: 4\n",
      "deniers douze grains: 4\n",
      "depuis foixante ans: 3\n",
      "cens quatre vins: 3\n",
      "dix ans apres: 3\n",
      "quatre cens vingt: 3\n",
      "plus efcu fol: 3\n",
      "fois plus cher: 2\n",
      "six vintz livres: 2\n",
      "cinq cens trente: 2\n",
      "tant foit peu: 2\n",
      "deux cens ans: 2\n",
      "den mout gras: 2\n",
      "gras auec laine: 2\n",
      "cochon dix den: 2\n",
      "six den hyuer: 2\n",
      "mil cinq cens: 2\n",
      "dix fois plus: 2\n",
      "quatre cens ans: 2\n",
      "comme dit pline: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_first_n_items(trigram_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d36ad6c4-4f5b-4d15-b463-25318d4095b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved La réponse_corrected_trigram_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(trigram_counts, output_folder, 'trigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7121f0e2-df9e-4b21-b929-144d4279227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collocations:\n",
      "La réponse_corrected\n"
     ]
    }
   ],
   "source": [
    "colloc_dict = {}\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    bigram_finder = BigramCollocationFinder.from_words(unigram_list)\n",
    "    bigram_finder.apply_freq_filter(5)   # make sure all collocations have occured at least 5 times\n",
    "    collocations = bigram_finder.nbest(BigramAssocMeasures.pmi, 500)\n",
    "    colloc_dict[key] = collocations\n",
    "\n",
    "print(\"Collocations:\")\n",
    "for key, value in colloc_dict.items():\n",
    "    print(key)\n",
    "    #for w1, w2 in value:\n",
    "        #print(' ', w1, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9613500d-ed13-4efa-a107-32c8ce7ef52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collocation Counts:\n",
      "La réponse_corrected\n"
     ]
    }
   ],
   "source": [
    "colloc_counts = {}\n",
    "\n",
    "for key, value in colloc_dict.items():\n",
    "    string_bigrams = convert_tuple_bigrams(value)\n",
    "    bigramCount = convert_strings_to_counts(string_bigrams)\n",
    "    colloc_counts[key] = string_bigrams\n",
    "    colloc_counts[key] = bigramCount\n",
    "\n",
    "print(\"Collocation Counts:\")\n",
    "for key in colloc_counts:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1814b84-b707-4058-9a98-0debd4f90c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in La réponse_corrected:\n",
      "hors mis: 1\n",
      "meilleur conte: 1\n",
      "roy henry: 1\n",
      "eau fort: 1\n",
      "peu pres: 1\n",
      "douze grains: 1\n",
      "escus vieux: 1\n",
      "toutes choses: 1\n",
      "pauure peuple: 1\n",
      "six den: 1\n",
      "ay dit: 1\n",
      "foixante ans: 1\n",
      "an cinq: 1\n",
      "mil escus: 1\n",
      "cinq cens: 1\n",
      "plus haut: 1\n",
      "argent pur: 1\n",
      "dix fois: 1\n",
      "an mil: 1\n",
      "cens vingt: 1\n",
      "douze deniers: 1\n",
      "cens ans: 1\n",
      "ans apres: 1\n",
      "quatre cens: 1\n",
      "abondance argent: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_first_n_items(colloc_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1956da3-dab0-4e63-ac2e-a98f2d1874d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved La réponse_corrected_collocation_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(colloc_counts, output_folder, 'collocation_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34b96f32-cba0-421c-b290-640bf7e458cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in La réponse_corrected:\n",
      "cin quiefme partie: 1\n",
      "partie charges ordinaires: 1\n",
      "den mout gras: 1\n",
      "temps louys douziefme: 1\n",
      "gras auec laine: 1\n",
      "dit cy deffus: 1\n",
      "francs pied cheual: 1\n",
      "fol ancié fin: 1\n",
      "faux monoyeur fait: 1\n",
      "six vintz livres: 1\n",
      "foleil dix couronne: 1\n",
      "partie del once: 1\n",
      "foixante mil francz: 1\n",
      "cochon dix den: 1\n",
      "valoit cinq nostres: 1\n",
      "six den hyuer: 1\n",
      "douze grains aloy: 1\n",
      "quarante livres erain: 1\n",
      "onze deniers douze: 1\n",
      "ancié fin argent: 1\n",
      "ay dit fera: 1\n",
      "deniers douze grains: 1\n",
      "vingt deux mois: 1\n",
      "comme dit pline: 1\n",
      "vingt fois autant: 1\n",
      "\n",
      "Saved La réponse_corrected_trigram_collocation_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "trigram_measures_dict = {}\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    trigram_finder = TrigramCollocationFinder.from_words(unigram_list)\n",
    "    trigram_finder.apply_freq_filter(2)   # make sure all collocations have occured at least 5 times\n",
    "    collocations = trigram_finder.nbest(TrigramAssocMeasures.pmi, 25)\n",
    "    trigram_measures_dict[key] = collocations\n",
    "\n",
    "trigram_colloc_counts = {}\n",
    "\n",
    "for key, value in trigram_measures_dict.items():\n",
    "    string_trigrams = convert_tuple_trigrams(value)\n",
    "    trigramCount = convert_strings_to_counts(string_trigrams)\n",
    "    trigram_colloc_counts[key] = string_trigrams\n",
    "    trigram_colloc_counts[key] = trigramCount\n",
    "\n",
    "print_first_n_items(trigram_colloc_counts, 25)\n",
    "\n",
    "dictionary_to_file(trigram_colloc_counts, output_folder, 'trigram_collocation_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7e2f4d1-a0cd-4382-ac98-0458ffe95edd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underscore Dictionary:\n",
      "La réponse_corrected\n"
     ]
    }
   ],
   "source": [
    "underscore_dict = {}\n",
    "for key, value in unigrams.items():\n",
    "\n",
    "    tokenized_words = unigrams.get(key)\n",
    "    collocations = colloc_dict.get(key)\n",
    "    \n",
    "    colloc_words = []\n",
    "    \n",
    "    # Iterate through the words making new versions combining collocations\n",
    "    i = 0\n",
    "    while i < len(tokenized_words) - 1:\n",
    "        # If we find a collocation, add and advance by two words\n",
    "        if (tokenized_words[i], tokenized_words[i + 1]) in collocations:\n",
    "            colloc_words.append('_'.join((tokenized_words[i], tokenized_words[i + 1])))\n",
    "            i += 2\n",
    "        # Otherwise, advance by one word\n",
    "        else:\n",
    "            colloc_words.append(tokenized_words[i])\n",
    "            i += 1\n",
    "\n",
    "    # Add the last word (if any)\n",
    "    if i == len(tokenized_words) - 1:\n",
    "        colloc_words.append(tokenized_words[i])\n",
    "    underscore_dict[key] = colloc_words\n",
    "\n",
    "print(\"Underscore Dictionary:\")\n",
    "for key in underscore_dict:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b482ee5a-560f-46e2-8c2a-13162fb7ccaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La réponse_corrected_underscore_bigrams.txt in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "write_dict_to_files_with_suffix(underscore_dict, output_folder, 'underscore_bigrams')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
