{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91544597-f773-4a92-98a0-28543e1728f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.stats import fisher_exact\n",
    "import little_mallet_wrapper\n",
    "import seaborn\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "# Path to MALLET\n",
    "path_to_mallet = 'mallet-2.0.8/bin/mallet'\n",
    "selected_stopwords_file_path = None\n",
    "\n",
    "# --- Utility Functions ---\n",
    "\n",
    "def tokenize_file(filepath):\n",
    "    \"\"\"\n",
    "    Reads a text file and tokenizes its contents into a list of words.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the file to be tokenized.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of words (tokens) from the file.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        return file.read().split()\n",
    "\n",
    "def list_txt_files(directory):\n",
    "    \"\"\"\n",
    "    Lists all .txt files in a specified directory.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of .txt file names in the directory.\n",
    "    \"\"\"\n",
    "    return sorted([f for f in os.listdir(directory) if f.endswith('.txt')])\n",
    "\n",
    "def list_csv_files(directory):\n",
    "    \"\"\"\n",
    "    Recursively lists all .csv files in a directory and its subdirectories.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of paths to .csv files.\n",
    "    \"\"\"\n",
    "    csv_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                csv_files.append(os.path.join(root, file))\n",
    "    return csv_files\n",
    "\n",
    "def choose_directory(prompt):\n",
    "    \"\"\"\n",
    "    Prompts the user to select a directory from the current working directory or any subdirectory.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Message to display to the user.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the selected directory.\n",
    "    \"\"\"\n",
    "    base_directory = os.getcwd()\n",
    "    subdirectories = [os.path.join(base_directory, o) for o in os.listdir(base_directory) if os.path.isdir(os.path.join(base_directory, o))]\n",
    "    subdirectories.append(base_directory)\n",
    "    print(prompt)\n",
    "    for i, subdir in enumerate(subdirectories):\n",
    "        print(f\"{i + 1}. {subdir}\")\n",
    "    choice = int(input(\"Enter your choice: \"))\n",
    "    return subdirectories[choice - 1]\n",
    "\n",
    "def choose_files(files):\n",
    "    \"\"\"\n",
    "    Prompts the user to select files from a list. The user can specify individual files, ranges, or patterns.\n",
    "\n",
    "    Args:\n",
    "        files (list): List of files available for selection.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of selected files.\n",
    "    \"\"\"\n",
    "    print(\"Select target .txt files (enter numbers separated by commas or ranges, or starting text patterns):\")\n",
    "    for i, file in enumerate(files):\n",
    "        print(f\"{i + 1}. {file}\")\n",
    "    choices = input(\"Enter your choices: \").strip()\n",
    "    selected_files = []\n",
    "    parts = choices.split(',')\n",
    "    for part in parts:\n",
    "        part = part.strip()\n",
    "        if '-' in part:\n",
    "            start, end = map(int, part.split('-'))\n",
    "            selected_files.extend(files[start - 1:end])\n",
    "        elif part.isdigit():\n",
    "            selected_files.append(files[int(part) - 1])\n",
    "        else:\n",
    "            selected_files.extend([file for file in files if file.startswith(part)])\n",
    "    return sorted(set(selected_files))  # Remove duplicates and sort\n",
    "\n",
    "def choose_csv_file(csv_files):\n",
    "    \"\"\"\n",
    "    Prompts the user to select a .csv file from a list.\n",
    "\n",
    "    Args:\n",
    "        csv_files (list): List of .csv file paths available for selection.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the selected .csv file.\n",
    "    \"\"\"\n",
    "    print(\"Select a .csv file to use as a stopwords file:\")\n",
    "    for i, file in enumerate(csv_files):\n",
    "        print(f\"{i + 1}. {file}\")\n",
    "    choice = int(input(\"Enter your choice: \"))\n",
    "    return csv_files[choice - 1]\n",
    "\n",
    "def read_stopwords(filepath):\n",
    "    \"\"\"\n",
    "    Reads a stopwords file and extracts the stopwords into a list.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the stopwords file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of stopwords.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        stopwords = []\n",
    "        for row in reader:\n",
    "            for word in row:\n",
    "                stopwords.extend(word.split(','))\n",
    "        return [word.strip() for word in stopwords]\n",
    "\n",
    "def get_fishers(word, count_dict, rate_dict, alternative='greater'):\n",
    "    \"\"\"\n",
    "    Calculates the p-value for Fisher's Exact Test for a given word.\n",
    "\n",
    "    Args:\n",
    "        word (str): The word to evaluate.\n",
    "        count_dict (dict): A dictionary of word counts in the target document.\n",
    "        rate_dict (dict): A dictionary of word rates across the corpus.\n",
    "        alternative (str): The type of hypothesis test ('greater', 'less', or 'two-sided').\n",
    "\n",
    "    Returns:\n",
    "        float: The p-value from Fisher's Exact Test.\n",
    "    \"\"\"\n",
    "    r = rate_dict.get(word, 0)\n",
    "    total_words = sum(count_dict.values())\n",
    "    observed = count_dict.get(word, 0)\n",
    "    remainder = total_words - observed\n",
    "    expected = round(r * total_words)\n",
    "    complement_expected = total_words - expected\n",
    "    p_value = fisher_exact([[observed, remainder], [expected, complement_expected]], alternative=alternative).pvalue\n",
    "    return p_value\n",
    "\n",
    "# --- Core Functions ---\n",
    "\n",
    "def calculate_rate_dictionary(rate_files, rate_directory):\n",
    "    \"\"\"\n",
    "    Calculates a rate dictionary of word frequencies across a set of rate files.\n",
    "\n",
    "    Args:\n",
    "        rate_files (list): List of rate files to process.\n",
    "        rate_directory (str): Directory containing the rate files.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are words and values are their relative frequencies.\n",
    "    \"\"\"\n",
    "    rate_word_counts = {}\n",
    "    total_word_count = 0\n",
    "    for file in rate_files:\n",
    "        words = tokenize_file(os.path.join(rate_directory, file))\n",
    "        for word in words:\n",
    "            rate_word_counts[word] = rate_word_counts.get(word, 0) + 1\n",
    "            total_word_count += 1\n",
    "    rate_dict = {word: count / total_word_count for word, count in rate_word_counts.items()}\n",
    "    return rate_dict\n",
    "\n",
    "def prepare_training_data(target_files, target_directory, stopwords, rate_dict, alpha):\n",
    "    \"\"\"\n",
    "    Filters and prepares training data by removing stopwords and words with p-values above the alpha threshold.\n",
    "\n",
    "    Args:\n",
    "        target_files (list): List of target files to process.\n",
    "        target_directory (str): Directory containing the target files.\n",
    "        stopwords (list): List of stopwords to exclude.\n",
    "        rate_dict (dict): Rate dictionary for calculating p-values.\n",
    "        alpha (float): Alpha threshold for Fisher's Exact Test.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of preprocessed and filtered text documents.\n",
    "    \"\"\"\n",
    "    filtered_data = []\n",
    "    for file in target_files:\n",
    "        words = tokenize_file(os.path.join(target_directory, file))\n",
    "        filtered_words = [\n",
    "            word for word in words if word not in stopwords and get_fishers(word, {word: words.count(word) for word in words}, rate_dict) < alpha\n",
    "        ]\n",
    "        filtered_data.append(' '.join(filtered_words))\n",
    "    return filtered_data\n",
    "\n",
    "def train_topic_model(training_data, num_topics, output_directory):\n",
    "    \"\"\"\n",
    "    Trains a topic model using MALLET with the given training data.\n",
    "\n",
    "    Args:\n",
    "        training_data (list): List of preprocessed documents for training.\n",
    "        num_topics (int): Number of topics to generate.\n",
    "        output_directory (str): Directory to save the model output.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of topics generated by the model.\n",
    "    \"\"\"\n",
    "    Path(output_directory).mkdir(parents=True, exist_ok=True)\n",
    "    little_mallet_wrapper.quick_train_topic_model(\n",
    "        path_to_mallet, output_directory, num_topics, training_data\n",
    "    )\n",
    "    topics = little_mallet_wrapper.load_topic_keys(f\"{output_directory}/mallet.topic_keys.{num_topics}\")\n",
    "    return topics\n",
    "\n",
    "def save_results_to_excel(filename, topics, topic_distributions, target_files):\n",
    "    \"\"\"\n",
    "    Saves topics and topic distributions to an Excel file with multiple sheets.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to the output Excel file.\n",
    "        topics (list): List of generated topics.\n",
    "        topic_distributions (list): Topic distributions for each document.\n",
    "        target_files (list): List of target file names.\n",
    "    \"\"\"\n",
    "    workbook = Workbook()\n",
    "    # Save topics\n",
    "    sheet = workbook.active\n",
    "    sheet.title = 'Topics'\n",
    "    for topic_number, topic in enumerate(topics):\n",
    "        sheet.append([f\"Topic {topic_number}\"] + topic)\n",
    "\n",
    "    # Save topic distributions\n",
    "    for file, distribution in zip(target_files, topic_distributions):\n",
    "        sheet_name = Path(file).stem\n",
    "        ws = workbook.create_sheet(title=sheet_name)\n",
    "        for row in dataframe_to_rows(pd.DataFrame(distribution), index=False, header=True):\n",
    "            ws.append(row)\n",
    "\n",
    "    workbook.save(filename)\n",
    "\n",
    "def display_success_message():\n",
    "    \"\"\"\n",
    "    Displays a success message to the user upon completion of the notebook.\n",
    "    \"\"\"\n",
    "    print(\"✅ The notebook has successfully completed processing!\")\n",
    "\n",
    "# --- Main Function ---\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the integrated workflow for Fisher's Exact Test-based\n",
    "    topic modeling with MALLET. Handles user input, file selection, preprocessing,\n",
    "    model training, and result output.\n",
    "    \"\"\"\n",
    "    # Step 1: Select stopwords file\n",
    "    stopwords_file = choose_csv_file(list_csv_files(os.getcwd()))\n",
    "    stopwords = read_stopwords(stopwords_file)\n",
    "\n",
    "    # Step 2: Select rate dictionary files\n",
    "    rate_directory = choose_directory(\"Select the directory for rate dictionary files:\")\n",
    "    rate_files = choose_files(list_txt_files(rate_directory))\n",
    "    rate_dict = calculate_rate_dictionary(rate_files, rate_directory)\n",
    "\n",
    "    # Step 3: Select target files\n",
    "    target_directory = choose_directory(\"Select the directory for target files:\")\n",
    "    target_files = choose_files(list_txt_files(target_directory))\n",
    "\n",
    "    # Step 4: Set alpha threshold\n",
    "    alpha = float(input(\"Enter the alpha threshold for Fisher's Exact Test: \"))\n",
    "\n",
    "    # Step 5: Prepare training data\n",
    "    training_data = prepare_training_data(target_files, target_directory, stopwords, rate_dict, alpha)\n",
    "\n",
    "    # Step 6: Specify number of topics\n",
    "    num_topics = int(input(\"Enter the number of topics to generate: \"))\n",
    "\n",
    "    # Step 7: Train topic model\n",
    "    output_directory = input(\"Enter a name for the output subfolder: \").strip()\n",
    "    topics = train_topic_model(training_data, num_topics, output_directory)\n",
    "\n",
    "    # Step 8: Save results to Excel\n",
    "    output_excel = f\"{output_directory}/topic_model_results.xlsx\"\n",
    "    save_results_to_excel(output_excel, topics, training_data, target_files)\n",
    "\n",
    "    # Step 9: Display success message\n",
    "    display_success_message()\n",
    "\n",
    "# --- Run the Notebook ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
