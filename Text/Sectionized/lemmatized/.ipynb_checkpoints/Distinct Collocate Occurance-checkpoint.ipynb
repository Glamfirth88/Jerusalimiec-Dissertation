{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c0ad7ea-573e-4631-8113-ecafa68e4997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to use predefined target word lists (yes/no)?  yes\n",
      "Enter the value for alpha:  0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords file selection\n",
      "Select a subdirectory:\n",
      "0. Current Working Directory\n",
      "1. .ipynb_checkpoints\n",
      "2. concordances\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a stopwords file from the following list:\n",
      "Select the files for stopwords file:\n",
      "1. stop_words.csv\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of the file, a range (e.g., 1-3), multiple ranges (e.g., 1-3,5-7), a text pattern to select files, or type 'all' to select all files:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected files:\n",
      "stop_words.csv\n",
      "Rate dictionary file selection\n",
      "Select a subdirectory:\n",
      "0. Current Working Directory\n",
      "1. .ipynb_checkpoints\n",
      "2. concordances\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select one or more rate dictionary files from the following list:\n",
      "Select the files for rate dictionary:\n",
      "1. Démonomanie preface Repair_corrected_stemmed.txt\n",
      "2. République preface_corrected_stemmed.txt\n",
      "3. Discours des raisons_corrected_stemmed.txt\n",
      "4. Démonomanie I.1_corrected_stemmed.txt\n",
      "5. Démonomanie I.2_corrected_stemmed.txt\n",
      "6. Démonomanie I.3_corrected_stemmed.txt\n",
      "7. Démonomanie I.4_corrected_stemmed.txt\n",
      "8. Démonomanie I.5_corrected_stemmed.txt\n",
      "9. Démonomanie I.6_corrected_stemmed.txt\n",
      "10. Démonomanie I.7_corrected_stemmed.txt\n",
      "11. Démonomanie II.1_corrected_stemmed.txt\n",
      "12. Démonomanie II.2_corrected_stemmed.txt\n",
      "13. Démonomanie II.3_corrected_stemmed.txt\n",
      "14. Démonomanie II.4_corrected_stemmed.txt\n",
      "15. Démonomanie II.5_corrected_stemmed.txt\n",
      "16. Démonomanie II.6_corrected_stemmed.txt\n",
      "17. Démonomanie II.7_corrected_stemmed.txt\n",
      "18. Démonomanie II.8_corrected_stemmed.txt\n",
      "19. Démonomanie III.1_corrected_stemmed.txt\n",
      "20. Démonomanie III.2_corrected_stemmed.txt\n",
      "21. Démonomanie III.3_corrected_stemmed.txt\n",
      "22. Démonomanie III.4_corrected_stemmed.txt\n",
      "23. Démonomanie III.5_corrected_stemmed.txt\n",
      "24. Démonomanie III.6_corrected_stemmed.txt\n",
      "25. Démonomanie IV.1_corrected_stemmed.txt\n",
      "26. Démonomanie IV.2_corrected_stemmed.txt\n",
      "27. Démonomanie IV.3_corrected_stemmed.txt\n",
      "28. Démonomanie IV.4_corrected_stemmed.txt\n",
      "29. Démonomanie IV.5_corrected_stemmed.txt\n",
      "30. Harangue - Fontainebleau_corrected_stemmed.txt\n",
      "31. Harangue - lit de justice_corrected_stemmed.txt\n",
      "32. Harangue - Orléans 2_corrected_stemmed.txt\n",
      "33. Harangue - Orléans_corrected_stemmed.txt\n",
      "34. Harangue - ouverture de parlement_corrected_stemmed.txt\n",
      "35. Harangue - parlement 2_corrected_stemmed.txt\n",
      "36. Harangue - parlement 3_corrected_stemmed.txt\n",
      "37. Harangue - parlement_corrected_stemmed.txt\n",
      "38. Harangue - Poissy_corrected_stemmed.txt\n",
      "39. Harangue - religion_corrected_stemmed.txt\n",
      "40. Harangue - Rouen_corrected_stemmed.txt\n",
      "41. Harangue - Saint Germain_corrected_stemmed.txt\n",
      "42. Harangue - septembre_corrected_stemmed.txt\n",
      "43. La réponse_corrected_stemmed.txt\n",
      "44. Le paradoxe_corrected_stemmed.txt\n",
      "45. Lettre_corrected_stemmed.txt\n",
      "46. Lit de justice_corrected_stemmed.txt\n",
      "47. Memoire - le but_corrected_stemmed.txt\n",
      "48. Memoire - Namur_corrected_stemmed.txt\n",
      "49. Memoire au roi_corrected_stemmed.txt\n",
      "50. Memoires d'État Refuge_corrected_stemmed.txt\n",
      "51. Memoires d'état_corrected_stemmed.txt\n",
      "52. Recueil_corrected_stemmed.txt\n",
      "53. Remonstrances - parlement_corrected_stemmed.txt\n",
      "54. Remonstrances - Royaume_corrected_stemmed.txt\n",
      "55. République I.1_corrected_stemmed.txt\n",
      "56. République I.2_corrected_stemmed.txt\n",
      "57. République I.3_corrected_stemmed.txt\n",
      "58. République I.4_corrected_stemmed.txt\n",
      "59. République I.5_corrected_stemmed.txt\n",
      "60. République I.6_corrected_stemmed.txt\n",
      "61. République I.7_corrected_stemmed.txt\n",
      "62. République I.8_corrected_stemmed.txt\n",
      "63. République I.910_corrected_stemmed.txt\n",
      "64. République I.911_corrected_stemmed.txt\n",
      "65. République I.9_corrected_stemmed.txt\n",
      "66. République II.1_corrected_stemmed.txt\n",
      "67. République II.2_corrected_stemmed.txt\n",
      "68. République II.3_corrected_stemmed.txt\n",
      "69. République II.4_corrected_stemmed.txt\n",
      "70. République II.5_corrected_stemmed.txt\n",
      "71. République II.6_corrected_stemmed.txt\n",
      "72. République II.7_corrected_stemmed.txt\n",
      "73. République III.1_corrected_stemmed.txt\n",
      "74. République III.2_corrected_stemmed.txt\n",
      "75. République III.3_corrected_stemmed.txt\n",
      "76. République III.4_corrected_stemmed.txt\n",
      "77. République III.5_corrected_stemmed.txt\n",
      "78. République III.6_corrected_stemmed.txt\n",
      "79. République III.7_corrected_stemmed.txt\n",
      "80. République IV.1_corrected_stemmed.txt\n",
      "81. République IV.2_corrected_stemmed.txt\n",
      "82. République IV.3_corrected_stemmed.txt\n",
      "83. République IV.4_corrected_stemmed.txt\n",
      "84. République IV.5_corrected_stemmed.txt\n",
      "85. République IV.6_corrected_stemmed.txt\n",
      "86. République IV.7_corrected_stemmed.txt\n",
      "87. République V.1_corrected_stemmed.txt\n",
      "88. République V.2_corrected_stemmed.txt\n",
      "89. République V.3_corrected_stemmed.txt\n",
      "90. République V.4_corrected_stemmed.txt\n",
      "91. République V.5_corrected_stemmed.txt\n",
      "92. République VI.1_corrected_stemmed.txt\n",
      "93. République VI.2_corrected_stemmed.txt\n",
      "94. République VI.3_corrected_stemmed.txt\n",
      "95. République VI.4_corrected_stemmed.txt\n",
      "96. République VI.5_corrected_stemmed.txt\n",
      "97. République VI.6_corrected_stemmed.txt\n",
      "98. Théatre I_corrected_stemmed.txt\n",
      "99. Théatre II_corrected_stemmed.txt\n",
      "100. Théatre III_corrected_stemmed.txt\n",
      "101. Théatre IV_corrected_stemmed.txt\n",
      "102. Théatre summary_corrected_stemmed.txt\n",
      "103. Théatre V_corrected_stemmed.txt\n",
      "104. Traite Justice V_corrected_stemmed.txt\n",
      "105. Traite Justice VI_corrected_stemmed.txt\n",
      "106. Traite Justice VII_corrected_stemmed.txt\n",
      "107. Traité Justice I_corrected_stemmed.txt\n",
      "108. Traité Justice II_corrected_stemmed.txt\n",
      "109. Traité Justice III_corrected_stemmed.txt\n",
      "110. Traité Justice IV_corrected_stemmed.txt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of the file, a range (e.g., 1-3), multiple ranges (e.g., 1-3,5-7), a text pattern to select files, or type 'all' to select all files:  all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected files:\n",
      "Démonomanie preface Repair_corrected_stemmed.txt\n",
      "République preface_corrected_stemmed.txt\n",
      "Discours des raisons_corrected_stemmed.txt\n",
      "Démonomanie I.1_corrected_stemmed.txt\n",
      "Démonomanie I.2_corrected_stemmed.txt\n",
      "Démonomanie I.3_corrected_stemmed.txt\n",
      "Démonomanie I.4_corrected_stemmed.txt\n",
      "Démonomanie I.5_corrected_stemmed.txt\n",
      "Démonomanie I.6_corrected_stemmed.txt\n",
      "Démonomanie I.7_corrected_stemmed.txt\n",
      "Démonomanie II.1_corrected_stemmed.txt\n",
      "Démonomanie II.2_corrected_stemmed.txt\n",
      "Démonomanie II.3_corrected_stemmed.txt\n",
      "Démonomanie II.4_corrected_stemmed.txt\n",
      "Démonomanie II.5_corrected_stemmed.txt\n",
      "Démonomanie II.6_corrected_stemmed.txt\n",
      "Démonomanie II.7_corrected_stemmed.txt\n",
      "Démonomanie II.8_corrected_stemmed.txt\n",
      "Démonomanie III.1_corrected_stemmed.txt\n",
      "Démonomanie III.2_corrected_stemmed.txt\n",
      "Démonomanie III.3_corrected_stemmed.txt\n",
      "Démonomanie III.4_corrected_stemmed.txt\n",
      "Démonomanie III.5_corrected_stemmed.txt\n",
      "Démonomanie III.6_corrected_stemmed.txt\n",
      "Démonomanie IV.1_corrected_stemmed.txt\n",
      "Démonomanie IV.2_corrected_stemmed.txt\n",
      "Démonomanie IV.3_corrected_stemmed.txt\n",
      "Démonomanie IV.4_corrected_stemmed.txt\n",
      "Démonomanie IV.5_corrected_stemmed.txt\n",
      "Harangue - Fontainebleau_corrected_stemmed.txt\n",
      "Harangue - lit de justice_corrected_stemmed.txt\n",
      "Harangue - Orléans 2_corrected_stemmed.txt\n",
      "Harangue - Orléans_corrected_stemmed.txt\n",
      "Harangue - ouverture de parlement_corrected_stemmed.txt\n",
      "Harangue - parlement 2_corrected_stemmed.txt\n",
      "Harangue - parlement 3_corrected_stemmed.txt\n",
      "Harangue - parlement_corrected_stemmed.txt\n",
      "Harangue - Poissy_corrected_stemmed.txt\n",
      "Harangue - religion_corrected_stemmed.txt\n",
      "Harangue - Rouen_corrected_stemmed.txt\n",
      "Harangue - Saint Germain_corrected_stemmed.txt\n",
      "Harangue - septembre_corrected_stemmed.txt\n",
      "La réponse_corrected_stemmed.txt\n",
      "Le paradoxe_corrected_stemmed.txt\n",
      "Lettre_corrected_stemmed.txt\n",
      "Lit de justice_corrected_stemmed.txt\n",
      "Memoire - le but_corrected_stemmed.txt\n",
      "Memoire - Namur_corrected_stemmed.txt\n",
      "Memoire au roi_corrected_stemmed.txt\n",
      "Memoires d'État Refuge_corrected_stemmed.txt\n",
      "Memoires d'état_corrected_stemmed.txt\n",
      "Recueil_corrected_stemmed.txt\n",
      "Remonstrances - parlement_corrected_stemmed.txt\n",
      "Remonstrances - Royaume_corrected_stemmed.txt\n",
      "République I.1_corrected_stemmed.txt\n",
      "République I.2_corrected_stemmed.txt\n",
      "République I.3_corrected_stemmed.txt\n",
      "République I.4_corrected_stemmed.txt\n",
      "République I.5_corrected_stemmed.txt\n",
      "République I.6_corrected_stemmed.txt\n",
      "République I.7_corrected_stemmed.txt\n",
      "République I.8_corrected_stemmed.txt\n",
      "République I.910_corrected_stemmed.txt\n",
      "République I.911_corrected_stemmed.txt\n",
      "République I.9_corrected_stemmed.txt\n",
      "République II.1_corrected_stemmed.txt\n",
      "République II.2_corrected_stemmed.txt\n",
      "République II.3_corrected_stemmed.txt\n",
      "République II.4_corrected_stemmed.txt\n",
      "République II.5_corrected_stemmed.txt\n",
      "République II.6_corrected_stemmed.txt\n",
      "République II.7_corrected_stemmed.txt\n",
      "République III.1_corrected_stemmed.txt\n",
      "République III.2_corrected_stemmed.txt\n",
      "République III.3_corrected_stemmed.txt\n",
      "République III.4_corrected_stemmed.txt\n",
      "République III.5_corrected_stemmed.txt\n",
      "République III.6_corrected_stemmed.txt\n",
      "République III.7_corrected_stemmed.txt\n",
      "République IV.1_corrected_stemmed.txt\n",
      "République IV.2_corrected_stemmed.txt\n",
      "République IV.3_corrected_stemmed.txt\n",
      "République IV.4_corrected_stemmed.txt\n",
      "République IV.5_corrected_stemmed.txt\n",
      "République IV.6_corrected_stemmed.txt\n",
      "République IV.7_corrected_stemmed.txt\n",
      "République V.1_corrected_stemmed.txt\n",
      "République V.2_corrected_stemmed.txt\n",
      "République V.3_corrected_stemmed.txt\n",
      "République V.4_corrected_stemmed.txt\n",
      "République V.5_corrected_stemmed.txt\n",
      "République VI.1_corrected_stemmed.txt\n",
      "République VI.2_corrected_stemmed.txt\n",
      "République VI.3_corrected_stemmed.txt\n",
      "République VI.4_corrected_stemmed.txt\n",
      "République VI.5_corrected_stemmed.txt\n",
      "République VI.6_corrected_stemmed.txt\n",
      "Théatre I_corrected_stemmed.txt\n",
      "Théatre II_corrected_stemmed.txt\n",
      "Théatre III_corrected_stemmed.txt\n",
      "Théatre IV_corrected_stemmed.txt\n",
      "Théatre summary_corrected_stemmed.txt\n",
      "Théatre V_corrected_stemmed.txt\n",
      "Traite Justice V_corrected_stemmed.txt\n",
      "Traite Justice VI_corrected_stemmed.txt\n",
      "Traite Justice VII_corrected_stemmed.txt\n",
      "Traité Justice I_corrected_stemmed.txt\n",
      "Traité Justice II_corrected_stemmed.txt\n",
      "Traité Justice III_corrected_stemmed.txt\n",
      "Traité Justice IV_corrected_stemmed.txt\n",
      "Select the files for analysis (KWIC):\n",
      "1. Démonomanie preface Repair_corrected_stemmed.txt\n",
      "2. République preface_corrected_stemmed.txt\n",
      "3. Discours des raisons_corrected_stemmed.txt\n",
      "4. Démonomanie I.1_corrected_stemmed.txt\n",
      "5. Démonomanie I.2_corrected_stemmed.txt\n",
      "6. Démonomanie I.3_corrected_stemmed.txt\n",
      "7. Démonomanie I.4_corrected_stemmed.txt\n",
      "8. Démonomanie I.5_corrected_stemmed.txt\n",
      "9. Démonomanie I.6_corrected_stemmed.txt\n",
      "10. Démonomanie I.7_corrected_stemmed.txt\n",
      "11. Démonomanie II.1_corrected_stemmed.txt\n",
      "12. Démonomanie II.2_corrected_stemmed.txt\n",
      "13. Démonomanie II.3_corrected_stemmed.txt\n",
      "14. Démonomanie II.4_corrected_stemmed.txt\n",
      "15. Démonomanie II.5_corrected_stemmed.txt\n",
      "16. Démonomanie II.6_corrected_stemmed.txt\n",
      "17. Démonomanie II.7_corrected_stemmed.txt\n",
      "18. Démonomanie II.8_corrected_stemmed.txt\n",
      "19. Démonomanie III.1_corrected_stemmed.txt\n",
      "20. Démonomanie III.2_corrected_stemmed.txt\n",
      "21. Démonomanie III.3_corrected_stemmed.txt\n",
      "22. Démonomanie III.4_corrected_stemmed.txt\n",
      "23. Démonomanie III.5_corrected_stemmed.txt\n",
      "24. Démonomanie III.6_corrected_stemmed.txt\n",
      "25. Démonomanie IV.1_corrected_stemmed.txt\n",
      "26. Démonomanie IV.2_corrected_stemmed.txt\n",
      "27. Démonomanie IV.3_corrected_stemmed.txt\n",
      "28. Démonomanie IV.4_corrected_stemmed.txt\n",
      "29. Démonomanie IV.5_corrected_stemmed.txt\n",
      "30. Harangue - Fontainebleau_corrected_stemmed.txt\n",
      "31. Harangue - lit de justice_corrected_stemmed.txt\n",
      "32. Harangue - Orléans 2_corrected_stemmed.txt\n",
      "33. Harangue - Orléans_corrected_stemmed.txt\n",
      "34. Harangue - ouverture de parlement_corrected_stemmed.txt\n",
      "35. Harangue - parlement 2_corrected_stemmed.txt\n",
      "36. Harangue - parlement 3_corrected_stemmed.txt\n",
      "37. Harangue - parlement_corrected_stemmed.txt\n",
      "38. Harangue - Poissy_corrected_stemmed.txt\n",
      "39. Harangue - religion_corrected_stemmed.txt\n",
      "40. Harangue - Rouen_corrected_stemmed.txt\n",
      "41. Harangue - Saint Germain_corrected_stemmed.txt\n",
      "42. Harangue - septembre_corrected_stemmed.txt\n",
      "43. La réponse_corrected_stemmed.txt\n",
      "44. Le paradoxe_corrected_stemmed.txt\n",
      "45. Lettre_corrected_stemmed.txt\n",
      "46. Lit de justice_corrected_stemmed.txt\n",
      "47. Memoire - le but_corrected_stemmed.txt\n",
      "48. Memoire - Namur_corrected_stemmed.txt\n",
      "49. Memoire au roi_corrected_stemmed.txt\n",
      "50. Memoires d'État Refuge_corrected_stemmed.txt\n",
      "51. Memoires d'état_corrected_stemmed.txt\n",
      "52. Recueil_corrected_stemmed.txt\n",
      "53. Remonstrances - parlement_corrected_stemmed.txt\n",
      "54. Remonstrances - Royaume_corrected_stemmed.txt\n",
      "55. République I.1_corrected_stemmed.txt\n",
      "56. République I.2_corrected_stemmed.txt\n",
      "57. République I.3_corrected_stemmed.txt\n",
      "58. République I.4_corrected_stemmed.txt\n",
      "59. République I.5_corrected_stemmed.txt\n",
      "60. République I.6_corrected_stemmed.txt\n",
      "61. République I.7_corrected_stemmed.txt\n",
      "62. République I.8_corrected_stemmed.txt\n",
      "63. République I.910_corrected_stemmed.txt\n",
      "64. République I.911_corrected_stemmed.txt\n",
      "65. République I.9_corrected_stemmed.txt\n",
      "66. République II.1_corrected_stemmed.txt\n",
      "67. République II.2_corrected_stemmed.txt\n",
      "68. République II.3_corrected_stemmed.txt\n",
      "69. République II.4_corrected_stemmed.txt\n",
      "70. République II.5_corrected_stemmed.txt\n",
      "71. République II.6_corrected_stemmed.txt\n",
      "72. République II.7_corrected_stemmed.txt\n",
      "73. République III.1_corrected_stemmed.txt\n",
      "74. République III.2_corrected_stemmed.txt\n",
      "75. République III.3_corrected_stemmed.txt\n",
      "76. République III.4_corrected_stemmed.txt\n",
      "77. République III.5_corrected_stemmed.txt\n",
      "78. République III.6_corrected_stemmed.txt\n",
      "79. République III.7_corrected_stemmed.txt\n",
      "80. République IV.1_corrected_stemmed.txt\n",
      "81. République IV.2_corrected_stemmed.txt\n",
      "82. République IV.3_corrected_stemmed.txt\n",
      "83. République IV.4_corrected_stemmed.txt\n",
      "84. République IV.5_corrected_stemmed.txt\n",
      "85. République IV.6_corrected_stemmed.txt\n",
      "86. République IV.7_corrected_stemmed.txt\n",
      "87. République V.1_corrected_stemmed.txt\n",
      "88. République V.2_corrected_stemmed.txt\n",
      "89. République V.3_corrected_stemmed.txt\n",
      "90. République V.4_corrected_stemmed.txt\n",
      "91. République V.5_corrected_stemmed.txt\n",
      "92. République VI.1_corrected_stemmed.txt\n",
      "93. République VI.2_corrected_stemmed.txt\n",
      "94. République VI.3_corrected_stemmed.txt\n",
      "95. République VI.4_corrected_stemmed.txt\n",
      "96. République VI.5_corrected_stemmed.txt\n",
      "97. République VI.6_corrected_stemmed.txt\n",
      "98. Théatre I_corrected_stemmed.txt\n",
      "99. Théatre II_corrected_stemmed.txt\n",
      "100. Théatre III_corrected_stemmed.txt\n",
      "101. Théatre IV_corrected_stemmed.txt\n",
      "102. Théatre summary_corrected_stemmed.txt\n",
      "103. Théatre V_corrected_stemmed.txt\n",
      "104. Traite Justice V_corrected_stemmed.txt\n",
      "105. Traite Justice VI_corrected_stemmed.txt\n",
      "106. Traite Justice VII_corrected_stemmed.txt\n",
      "107. Traité Justice I_corrected_stemmed.txt\n",
      "108. Traité Justice II_corrected_stemmed.txt\n",
      "109. Traité Justice III_corrected_stemmed.txt\n",
      "110. Traité Justice IV_corrected_stemmed.txt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of the file, a range (e.g., 1-3), multiple ranges (e.g., 1-3,5-7), a text pattern to select files, or type 'all' to select all files:  Dém,Rép\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected files:\n",
      "Démonomanie preface Repair_corrected_stemmed.txt\n",
      "République preface_corrected_stemmed.txt\n",
      "Démonomanie I.1_corrected_stemmed.txt\n",
      "Démonomanie I.2_corrected_stemmed.txt\n",
      "Démonomanie I.3_corrected_stemmed.txt\n",
      "Démonomanie I.4_corrected_stemmed.txt\n",
      "Démonomanie I.5_corrected_stemmed.txt\n",
      "Démonomanie I.6_corrected_stemmed.txt\n",
      "Démonomanie I.7_corrected_stemmed.txt\n",
      "Démonomanie II.1_corrected_stemmed.txt\n",
      "Démonomanie II.2_corrected_stemmed.txt\n",
      "Démonomanie II.3_corrected_stemmed.txt\n",
      "Démonomanie II.4_corrected_stemmed.txt\n",
      "Démonomanie II.5_corrected_stemmed.txt\n",
      "Démonomanie II.6_corrected_stemmed.txt\n",
      "Démonomanie II.7_corrected_stemmed.txt\n",
      "Démonomanie II.8_corrected_stemmed.txt\n",
      "Démonomanie III.1_corrected_stemmed.txt\n",
      "Démonomanie III.2_corrected_stemmed.txt\n",
      "Démonomanie III.3_corrected_stemmed.txt\n",
      "Démonomanie III.4_corrected_stemmed.txt\n",
      "Démonomanie III.5_corrected_stemmed.txt\n",
      "Démonomanie III.6_corrected_stemmed.txt\n",
      "Démonomanie IV.1_corrected_stemmed.txt\n",
      "Démonomanie IV.2_corrected_stemmed.txt\n",
      "Démonomanie IV.3_corrected_stemmed.txt\n",
      "Démonomanie IV.4_corrected_stemmed.txt\n",
      "Démonomanie IV.5_corrected_stemmed.txt\n",
      "République I.1_corrected_stemmed.txt\n",
      "République I.2_corrected_stemmed.txt\n",
      "République I.3_corrected_stemmed.txt\n",
      "République I.4_corrected_stemmed.txt\n",
      "République I.5_corrected_stemmed.txt\n",
      "République I.6_corrected_stemmed.txt\n",
      "République I.7_corrected_stemmed.txt\n",
      "République I.8_corrected_stemmed.txt\n",
      "République I.910_corrected_stemmed.txt\n",
      "République I.911_corrected_stemmed.txt\n",
      "République I.9_corrected_stemmed.txt\n",
      "République II.1_corrected_stemmed.txt\n",
      "République II.2_corrected_stemmed.txt\n",
      "République II.3_corrected_stemmed.txt\n",
      "République II.4_corrected_stemmed.txt\n",
      "République II.5_corrected_stemmed.txt\n",
      "République II.6_corrected_stemmed.txt\n",
      "République II.7_corrected_stemmed.txt\n",
      "République III.1_corrected_stemmed.txt\n",
      "République III.2_corrected_stemmed.txt\n",
      "République III.3_corrected_stemmed.txt\n",
      "République III.4_corrected_stemmed.txt\n",
      "République III.5_corrected_stemmed.txt\n",
      "République III.6_corrected_stemmed.txt\n",
      "République III.7_corrected_stemmed.txt\n",
      "République IV.1_corrected_stemmed.txt\n",
      "République IV.2_corrected_stemmed.txt\n",
      "République IV.3_corrected_stemmed.txt\n",
      "République IV.4_corrected_stemmed.txt\n",
      "République IV.5_corrected_stemmed.txt\n",
      "République IV.6_corrected_stemmed.txt\n",
      "République IV.7_corrected_stemmed.txt\n",
      "République V.1_corrected_stemmed.txt\n",
      "République V.2_corrected_stemmed.txt\n",
      "République V.3_corrected_stemmed.txt\n",
      "République V.4_corrected_stemmed.txt\n",
      "République V.5_corrected_stemmed.txt\n",
      "République VI.1_corrected_stemmed.txt\n",
      "République VI.2_corrected_stemmed.txt\n",
      "République VI.3_corrected_stemmed.txt\n",
      "République VI.4_corrected_stemmed.txt\n",
      "République VI.5_corrected_stemmed.txt\n",
      "République VI.6_corrected_stemmed.txt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the window size for concordance:  15\n",
      "Do you want to append results to an existing .xlsx file? (yes/no):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a directory to search for .xlsx files:\n",
      "Select a subdirectory:\n",
      "0. Current Working Directory\n",
      "1. .ipynb_checkpoints\n",
      "2. concordances\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select an existing .xlsx file from the following list:\n",
      "1. 15WindowSummary - Archive.xlsx\n",
      "2. 15winsum.xlsx\n",
      "3. most_distinct_collocates_20_window.xlsx\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of the file you want to select or 0 to cancel:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to existing file: /home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/lemmatized/concordances/15winsum.xlsx\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Skip Hypothesis 1? (yes/no):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Hypothesis 1.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Skip Hypothesis 2? (yes/no):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Hypothesis 2.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Skip Hypothesis 3? (yes/no):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Hypothesis 3.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Skip Hypothesis 4? (yes/no):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Hypothesis 4.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Skip Hypothesis 5? (yes/no):  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Hypothesis 5.\n",
      "\n",
      "=== Hypothesis 5 target words ===\n",
      "absolu, bien, chos, civil, droit, estat, just, justic, loi, maiest, princ, puissanc, republ, roy, royal, royaum, souverain, souverainet, sujet\n",
      "=======================================\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 577\u001b[0m\n\u001b[1;32m    575\u001b[0m     anal_files \u001b[38;5;241m=\u001b[39m prompt_files(find_text_files(os\u001b[38;5;241m.\u001b[39mgetcwd()), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manalysis (KWIC)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;66;03m# 3) call with both lists\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m     \u001b[43msearch_concordance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manal_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredefined_word_lists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo rate dictionary files selected.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 489\u001b[0m, in \u001b[0;36msearch_concordance\u001b[0;34m(reference_files, analysis_files, predefined_word_lists, stops, alpha)\u001b[0m\n\u001b[1;32m    486\u001b[0m manual_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(all_significant) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(auto_keywords))\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# 3) Prompt the user only on the manual pool\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m selected, min_count \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_collocates_with_removal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanual_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollocate_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;66;03m# 4) Merge the hidden auto_keywords back into selected\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kw \u001b[38;5;129;01min\u001b[39;00m auto_keywords:\n",
      "Cell \u001b[0;32mIn[1], line 286\u001b[0m, in \u001b[0;36mfilter_collocates_with_removal\u001b[0;34m(collocates, collocate_counts)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 286\u001b[0m         min_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter the minimum count threshold for collocates to include: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input. Please enter a valid number.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import nltk\n",
    "from scipy.stats import fisher_exact\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "\n",
    "# Function to prompt the user to select text files based on patterns\n",
    "def prompt_pattern_files(text_files, pattern):\n",
    "    selected_files = [file for file in text_files if file.startswith(pattern)]\n",
    "    return selected_files\n",
    "\n",
    "def generate_keyword_pairs(predefined_words):\n",
    "    \"\"\"\n",
    "    Generate all possible combinations of keyword pairs from the predefined word list.\n",
    "    \"\"\"\n",
    "    return list(combinations(predefined_words, 2))\n",
    "\n",
    "def prompt_files(text_files, purpose):\n",
    "    text_files = sorted(text_files, key=custom_file_sort_key)  # Custom sort for files\n",
    "    print(f\"Select the files for {purpose}:\")\n",
    "    for i, file in enumerate(text_files, start=1):\n",
    "        print(f\"{i}. {file}\")\n",
    "    \n",
    "    selection = input(\"Enter the number of the file, a range (e.g., 1-3), multiple ranges (e.g., 1-3,5-7), a text pattern to select files, or type 'all' to select all files: \").strip()\n",
    "    selected_files = []\n",
    "    \n",
    "    if selection.lower() == 'all':\n",
    "        selected_files = text_files\n",
    "    else:\n",
    "        # Split the input by commas to handle multiple ranges or numbers\n",
    "        parts = selection.split(',')\n",
    "        for part in parts:\n",
    "            part = part.strip()\n",
    "            if '-' in part:  # If the part is a range\n",
    "                try:\n",
    "                    start, end = map(int, part.split('-'))\n",
    "                    selected_files.extend(text_files[start-1:end])\n",
    "                except ValueError:\n",
    "                    print(f\"Invalid range: {part}. Please provide ranges like '1-3'.\")\n",
    "            elif part.isdigit():  # If the part is a single number\n",
    "                try:\n",
    "                    selected_files.append(text_files[int(part) - 1])\n",
    "                except IndexError:\n",
    "                    print(f\"Invalid number: {part}. Please select numbers from the list.\")\n",
    "            else:  # If the part is treated as a pattern\n",
    "                selected_files.extend(prompt_pattern_files(text_files, part))\n",
    "    \n",
    "    # Remove duplicates and sort the selected files\n",
    "    selected_files = sorted(set(selected_files), key=custom_file_sort_key)\n",
    "    \n",
    "    print(\"Selected files:\")\n",
    "    for file in selected_files:\n",
    "        print(file)\n",
    "    \n",
    "    return selected_files\n",
    "\n",
    "# Custom sort key for file names\n",
    "def custom_file_sort_key(filename):\n",
    "    # Prioritize 'preface' higher than patterns like 'I.1'\n",
    "    if 'preface' in filename.lower():\n",
    "        return ('', filename.lower())  # Sort 'preface' first\n",
    "    return (filename.lower(),)\n",
    "\n",
    "# Function to process text files\n",
    "def process_text_files(file_paths):\n",
    "    combined_text = \"\"\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            combined_text += file.read().lower() + \" \"\n",
    "    tokens = nltk.wordpunct_tokenize(combined_text)\n",
    "    return nltk.Text(tokens)\n",
    "\n",
    "# Function to find .txt files in a directory\n",
    "def find_text_files(directory):\n",
    "    return sorted([f for f in os.listdir(directory) if f.endswith('.txt')], key=custom_file_sort_key)  # Custom sort\n",
    "\n",
    "# Function to list subfolders in the current directory\n",
    "def list_subfolders():\n",
    "    return sorted([f.name for f in os.scandir() if f.is_dir()])  # Sort folders alphabetically\n",
    "\n",
    "# Function to prompt the user to select a subfolder or the current directory\n",
    "def prompt_subfolder(subfolders):\n",
    "    print(\"Select a subfolder or the current working directory:\")\n",
    "    print(\"0. Current Working Directory\")\n",
    "    for i, subfolder in enumerate(subfolders, start=1):\n",
    "        print(f\"{i}. {subfolder}\")\n",
    "    selected_index = int(input(\"Enter the number of the subfolder: \"))\n",
    "    return None if selected_index == 0 else subfolders[selected_index - 1]\n",
    "\n",
    "# Function to get predefined target words\n",
    "def get_predefined_target_words():\n",
    "    return [\n",
    "        ['citoyen', 'cour', 'domain', 'ressort'],  # List 1\n",
    "        ['guerr', 'paix', 'police', 'religion'],  # List 2\n",
    "        ['confess', 'demon', 'demoniaqu', 'diabl',\n",
    "         'diabol', 'dieu', 'divin', \n",
    "        'hebrieu', 'impiet', 'preuv', 'question',   'sathan', \n",
    "        'sorceller', 'sorci'],  # List 3\n",
    "        ['arrest',  'conseil', 'conseiller', 'consul', \n",
    "         'couron', 'édict', 'iurisdict', 'jug', 'magistrat',\n",
    "         'offic', 'offici', 'ordon', 'parlement',\n",
    "        'seigneur', 'seigneurial', 'statut'],  # List 4\n",
    "        ['absolu', 'bien', 'chos', 'civil', 'droit', 'estat', 'just', 'justic',\n",
    "         'loi', 'maiest', 'princ', 'puissanc',\n",
    "        'republ', 'roy', 'royal', 'royaum', 'souverain', 'souverainet', 'sujet']  # List 5\n",
    "    ]\n",
    "\n",
    "# Function to choose subdirectory for stopwords csv file\n",
    "def choose_subdirectory(subdirectories):\n",
    "    print(\"Select a subdirectory:\")\n",
    "    print(\"0. Current Working Directory\")\n",
    "    for i, subdir in enumerate(subdirectories, start=1):\n",
    "        print(f\"{i}. {subdir}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter your choice: \"))\n",
    "            if 0 <= choice <= len(subdirectories):\n",
    "                return None if choice == 0 else subdirectories[choice - 1]\n",
    "            else:\n",
    "                print(\"Invalid selection. Please try again.\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a number.\")\n",
    "\n",
    "# Function to read stopwords from a csv file\n",
    "def read_stopwords(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        stopwords = []\n",
    "        for row in reader:\n",
    "            for word in row:\n",
    "                stopwords.extend(word.split(','))\n",
    "        return [word.strip() for word in stopwords]\n",
    "\n",
    "# Function to find .csv files in a directory\n",
    "def find_csv_files(directory):\n",
    "    return sorted([f for f in os.listdir(directory) if f.endswith('.csv')])  # Sort files alphabetically\n",
    "\n",
    "# Function to select files for the stopwords\n",
    "def select_stopwords_file():\n",
    "    print('Stopwords file selection')\n",
    "    stopwords_subfolders = list_subfolders()\n",
    "    selected_stopwords_subfolder = choose_subdirectory(stopwords_subfolders)\n",
    "    \n",
    "    # Check if the user selected a subfolder or the current directory\n",
    "    stopwords_subfolder_path = os.getcwd() if selected_stopwords_subfolder is None else os.path.join(os.getcwd(), selected_stopwords_subfolder)\n",
    "    \n",
    "    # Find .csv files in the selected directory\n",
    "    stopwords_files = find_csv_files(stopwords_subfolder_path)\n",
    "    if stopwords_files:\n",
    "        print('Select a stopwords file from the following list:')\n",
    "        # Prompt the user to select a single .csv file\n",
    "        selected_file = prompt_files(stopwords_files, \"stopwords file\")\n",
    "        if selected_file:\n",
    "            return selected_file[0], stopwords_subfolder_path  # Return the first selected file and its path\n",
    "        else:\n",
    "            print(\"No stopwords file selected.\")\n",
    "            return None, None\n",
    "    else:\n",
    "        print(f\"No .csv stopwords files found in '{selected_stopwords_subfolder}'.\")\n",
    "        return None, None\n",
    "\n",
    "# Function to select files for the rate dictionary\n",
    "def select_rate_dictionary_files():\n",
    "    print('Rate dictionary file selection')\n",
    "    rate_dictionary_subfolders = list_subfolders()\n",
    "    selected_rate_dictionary_subfolder = choose_subdirectory(rate_dictionary_subfolders)\n",
    "    \n",
    "    # Check if the user selected a subfolder or the current directory\n",
    "    rate_dictionary_subfolder_path = os.getcwd() if selected_rate_dictionary_subfolder is None else os.path.join(os.getcwd(), selected_rate_dictionary_subfolder)\n",
    "    \n",
    "    # Find .txt files in the selected directory\n",
    "    rate_dictionary_files = find_text_files(rate_dictionary_subfolder_path)\n",
    "    if rate_dictionary_files:\n",
    "        print('Select one or more rate dictionary files from the following list:')\n",
    "        selected_files = prompt_files(rate_dictionary_files, \"rate dictionary\")\n",
    "        if selected_files:\n",
    "            return selected_files, rate_dictionary_subfolder_path  # Return the selected files and their path\n",
    "        else:\n",
    "            print(\"No rate dictionary files selected.\")\n",
    "            return [], None\n",
    "    else:\n",
    "        print(f\"No .txt rate dictionary files found in '{selected_rate_dictionary_subfolder}'.\")\n",
    "        return [], None\n",
    "\n",
    "def select_existing_xlsx_file():\n",
    "    print(\"Select a directory to search for .xlsx files:\")\n",
    "    subfolders = list_subfolders()\n",
    "    selected_subfolder = choose_subdirectory(subfolders)\n",
    "\n",
    "    # Check if the user selected a subfolder or the current directory\n",
    "    folder_path = os.getcwd() if selected_subfolder is None else os.path.join(os.getcwd(), selected_subfolder)\n",
    "\n",
    "    # Find .xlsx files in the selected directory\n",
    "    xlsx_files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]\n",
    "    if xlsx_files:\n",
    "        print(\"Select an existing .xlsx file from the following list:\")\n",
    "        for i, file in enumerate(xlsx_files, start=1):\n",
    "            print(f\"{i}. {file}\")\n",
    "        while True:\n",
    "            try:\n",
    "                choice = int(input(\"Enter the number of the file you want to select or 0 to cancel: \"))\n",
    "                if 0 <= choice <= len(xlsx_files):\n",
    "                    return None if choice == 0 else os.path.join(folder_path, xlsx_files[choice - 1])\n",
    "                else:\n",
    "                    print(\"Invalid selection. Please try again.\")\n",
    "            except ValueError:\n",
    "                print(\"Please enter a number.\")\n",
    "    else:\n",
    "        print(f\"No .xlsx files found in '{folder_path}'.\")\n",
    "        return None\n",
    "\n",
    "# Utility function to clean file names\n",
    "def clean_file_name(file_name):\n",
    "    \"\"\"\n",
    "    Clean the file name for display, including replacing specific patterns.\n",
    "    \"\"\"\n",
    "    file_name = file_name.replace('_', '').replace('corrected', '').replace('stemmed', '')\n",
    "    if 'Démonomanie' in file_name:\n",
    "        file_name = file_name.replace('Démonomanie', 'Dém')\n",
    "    if 'République' in file_name:\n",
    "        file_name = file_name.replace('République', 'Rép')\n",
    "   \n",
    "    # Replace '911' with '11' and '910' with '10' (NEW CHANGE)\n",
    "    file_name = file_name.replace('911', '11').replace('910', '10')  # <--- CHANGE HERE\n",
    "   \n",
    "    return os.path.splitext(file_name)[0]\n",
    "\n",
    "# Function to process the subset of text files for KWIC and counts\n",
    "def process_subset_files(file_paths):\n",
    "    combined_text = \"\"\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as f:\n",
    "            file_contents = f.read().lower()\n",
    "            combined_text += file_contents + \" \"\n",
    "    tokens = nltk.wordpunct_tokenize(combined_text)\n",
    "    return tokens\n",
    "\n",
    "def get_kwic(sometargetterm, somelistofwords, window=10, excl_target=True, source_file=None):\n",
    "    kwics = []\n",
    "    for n, w in enumerate(somelistofwords):\n",
    "        if w == sometargetterm:\n",
    "            start = max(0, n - window)\n",
    "            end = min(n + window + 1, len(somelistofwords))\n",
    "            if excl_target:\n",
    "                # Updated: Exclude keyword itself from the window\n",
    "                k = [word for word in (somelistofwords[start:n] + somelistofwords[n + 1:end]) if word != sometargetterm]\n",
    "            else:\n",
    "                k = somelistofwords[start:end]\n",
    "            kwics.append((k, source_file))\n",
    "    return kwics\n",
    "   \n",
    "\n",
    "def add_to_count_dict(word, count_dict):\n",
    "    if word in count_dict:\n",
    "        count_dict[word] += 1\n",
    "    else:\n",
    "        count_dict[word] = 1\n",
    "\n",
    "def get_fishers(someword, somecountdict, someratedict, alternative='greater'):\n",
    "    r = someratedict[someword]\n",
    "    wc = sum(somecountdict.values())\n",
    "    a = somecountdict[someword]\n",
    "    b = wc - a\n",
    "    c = round(r * wc)\n",
    "    d = wc - c\n",
    "    p = fisher_exact([[a, b], [c, d]], alternative=alternative)[1]\n",
    "    return p\n",
    "\n",
    "def filter_collocates_with_removal(collocates, collocate_counts):\n",
    "    \"\"\"\n",
    "    Allow the user to filter the list of significant collocates and remove any selected collocates in error.\n",
    "\n",
    "    Parameters:\n",
    "        collocates (list): A sorted list of significant collocates.\n",
    "        collocate_counts (dict): A dictionary of collocates and their counts.\n",
    "\n",
    "    Returns:\n",
    "        list: A filtered list of collocates selected by the user.\n",
    "    \"\"\"\n",
    "\n",
    "    # Allow the user to refine the minimum‐count threshold repeatedly\n",
    "    while True:\n",
    "        try:\n",
    "            min_count = int(input(\"Enter the minimum count threshold for collocates to include: \").strip())\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid number.\")\n",
    "            continue\n",
    "\n",
    "        filtered_collocates = [c for c in collocates if collocate_counts[c] >= min_count]\n",
    "        print(f\"\\nCollocates with counts >= {min_count} ({len(filtered_collocates)} items):\")\n",
    "        for i, collocate in enumerate(filtered_collocates, start=1):\n",
    "            print(f\"{i}. {collocate} (Count: {collocate_counts[collocate]})\")\n",
    "    \n",
    "        choice = input(\"\\nType 'refine' to try a new threshold, or press Enter to proceed: \").strip().lower()\n",
    "        if choice == 'refine':\n",
    "            continue\n",
    "        break\n",
    "        \n",
    "\n",
    "    print(\"\\nYou can select collocates by entering:\")\n",
    "    print(\"- A single number (e.g., 3) to select one collocate.\")\n",
    "    print(\"- A range of numbers (e.g., 3-6) to select multiple collocates.\")\n",
    "    print(\"- Multiple selections separated by commas (e.g., 3,5-7,9).\")\n",
    "    print(\"- Type 'all' to select all collocates.\")\n",
    "    print(\"- Type 'done' to finalize your selection.\")\n",
    "\n",
    "    selected_collocates = []\n",
    "\n",
    "    while True:\n",
    "        selection = input(\"Enter your selection: \").strip()\n",
    "        if selection.lower() == 'done':\n",
    "            break\n",
    "        elif selection.lower() == 'all':\n",
    "            selected_collocates = filtered_collocates\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            parts = selection.split(',')\n",
    "            for part in parts:\n",
    "                part = part.strip()\n",
    "                if '-' in part:  # Handle ranges\n",
    "                    start, end = map(int, part.split('-'))\n",
    "                    selected_collocates.extend(filtered_collocates[start-1:end])\n",
    "                elif part.isdigit():  # Handle single numbers\n",
    "                    selected_collocates.append(filtered_collocates[int(part) - 1])\n",
    "                else:\n",
    "                    print(f\"Invalid selection: {part}. Please try again.\")\n",
    "        except (ValueError, IndexError):\n",
    "            print(f\"Invalid input: {selection}. Please try again.\")\n",
    "\n",
    "        # Remove duplicates and sort the selected collocates\n",
    "        selected_collocates = sorted(set(selected_collocates), key=filtered_collocates.index)\n",
    "\n",
    "        print(\"Currently selected collocates:\")\n",
    "        for collocate in selected_collocates:\n",
    "            print(collocate)\n",
    "\n",
    "    # Allow users to review and remove collocates selected in error\n",
    "    while True:\n",
    "        print(\"\\nFinalized collocates:\")\n",
    "        for i, collocate in enumerate(selected_collocates, start=1):\n",
    "            print(f\"{i}. {collocate}\")\n",
    "\n",
    "        remove_error = input(\n",
    "            \"Would you like to remove any collocates selected in error? (yes/no): \"\n",
    "        ).strip().lower()\n",
    "        if remove_error == 'yes':\n",
    "            remove_selection = input(\n",
    "                \"Enter the numbers of the collocates to remove (e.g., 2,4-5): \"\n",
    "            ).strip()\n",
    "            try:\n",
    "                parts = remove_selection.split(',')\n",
    "                to_remove = []\n",
    "                for part in parts:\n",
    "                    part = part.strip()\n",
    "                    if '-' in part:  # Handle ranges\n",
    "                        start, end = map(int, part.split('-'))\n",
    "                        to_remove.extend(selected_collocates[start-1:end])\n",
    "                    elif part.isdigit():  # Handle single numbers\n",
    "                        to_remove.append(selected_collocates[int(part) - 1])\n",
    "                    else:\n",
    "                        print(f\"Invalid selection: {part}. Please try again.\")\n",
    "                selected_collocates = [\n",
    "                    collocate for collocate in selected_collocates\n",
    "                    if collocate not in to_remove\n",
    "                ]\n",
    "            except (ValueError, IndexError):\n",
    "                print(f\"Invalid input: {remove_selection}. Please try again.\")\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return selected_collocates, min_count\n",
    "\n",
    "def search_concordance(\n",
    "    reference_files,         # files → build the rate dictionary\n",
    "    analysis_files,          # files → do KWIC & Fisher tests\n",
    "    predefined_word_lists,\n",
    "    stops,\n",
    "    alpha\n",
    "):\n",
    "    # --- A) window prompt & workbook setup (unchanged) ---\n",
    "    window = int(input(\"Enter the window size for concordance: \").strip())\n",
    "\n",
    "    append_to_existing = input(\"Do you want to append results to an existing .xlsx file? (yes/no): \").strip().lower()\n",
    "    if append_to_existing == 'yes':\n",
    "        existing_file = select_existing_xlsx_file()\n",
    "        if existing_file:\n",
    "            wb = load_workbook(existing_file)\n",
    "            print(f\"Appending to existing file: {existing_file}\")\n",
    "        else:\n",
    "            print(\"No existing workbook selected. Creating a new workbook instead.\")\n",
    "            wb = Workbook()\n",
    "    else:\n",
    "        wb = Workbook()\n",
    "        print(\"Creating a new workbook.\")\n",
    "    if 'Sheet' in wb.sheetnames:\n",
    "        del wb['Sheet']\n",
    "\n",
    "    if append_to_existing == 'yes' and existing_file:\n",
    "        output_filepath = existing_file\n",
    "    else:\n",
    "        output_filename = input(\"Enter a unique name for the .xlsx file (without extension): \").strip() or \"distinct_collocates\"\n",
    "        output_filepath = os.path.join(\"concordances\", f\"{output_filename}.xlsx\")\n",
    "\n",
    "    # --- B) Build expected_rates from reference_files ---\n",
    "    ref_paths  = [os.path.join(os.getcwd(), f) for f in reference_files]\n",
    "    ref_tokens = process_subset_files(ref_paths)\n",
    "    ref_counts = {}\n",
    "    # sum(predefined_word_lists, []) flattens all hypotheses lists\n",
    "    all_targets = set(sum(predefined_word_lists, []))\n",
    "    for tok in ref_tokens:\n",
    "        if tok not in stops and tok not in all_targets:\n",
    "            add_to_count_dict(tok, ref_counts)\n",
    "\n",
    "    total_ref = sum(ref_counts.values())\n",
    "    if total_ref == 0:\n",
    "        raise ValueError(\"Reference corpus is empty after filtering!\")\n",
    "    expected_rates = {w: c / total_ref for w, c in ref_counts.items()}\n",
    "\n",
    "    # --- C) Loop over each hypothesis list ---\n",
    "    for idx, predefined_words in enumerate(predefined_word_lists, start=1):\n",
    "        if input(f\"Skip Hypothesis {idx}? (yes/no): \").strip().lower() == 'yes':\n",
    "            print(f\"Skipping Hypothesis {idx}.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing Hypothesis {idx}.\")\n",
    "        ws = wb.create_sheet(title=f\"Hypothesis {idx}\")\n",
    "        headers = ['Word'] + [clean_file_name(f) for f in analysis_files] + ['Total']\n",
    "        ws.append(headers)\n",
    "        predefined_words = sorted(predefined_words)\n",
    "        keyword_pairs    = generate_keyword_pairs(predefined_words)\n",
    "\n",
    "        # --- C1) Build counts_by_file_kw (one map only) ---\n",
    "        counts_by_file_kw = {\n",
    "            f: { kw: Counter() for kw in predefined_words }\n",
    "            for f in analysis_files\n",
    "        }\n",
    "        \n",
    "        for f in analysis_files:\n",
    "            tokens = process_subset_files([os.path.join(os.getcwd(), f)])\n",
    "            for kw in predefined_words:\n",
    "                for context, _ in get_kwic(kw, tokens, window):\n",
    "                    uniq = set(context) - {kw}\n",
    "                    for c in uniq:\n",
    "                        if c in stops:\n",
    "                            continue\n",
    "                        # count every collocate (including when c is itself one of your keywords)\n",
    "                        counts_by_file_kw[f][kw][c] += 1\n",
    "        \n",
    "     \n",
    "        # --- C2) Fisher & user‐filter (fixed file_total calculation) ---\n",
    "        all_significant = set()\n",
    "        from collections import Counter as _Counter\n",
    "        collocate_counts = _Counter()\n",
    "        \n",
    "        for f, cnts in counts_by_file_kw.items():\n",
    "            # flatten all kw‐buckets into one counter\n",
    "            flat = _Counter()\n",
    "            for kw in predefined_words:\n",
    "                flat.update(cnts[kw])\n",
    "            file_total = sum(flat.values())\n",
    "            if file_total == 0:\n",
    "                continue\n",
    "        \n",
    "            for coll, obs in flat.items():\n",
    "                exp_cnt = round(expected_rates.get(coll, 0.0) * file_total)\n",
    "                a, b = obs, file_total - obs\n",
    "                c, d = exp_cnt, file_total - exp_cnt\n",
    "                p = fisher_exact([[a, b], [c, d]], alternative='greater')[1]\n",
    "                if p < alpha:\n",
    "                    all_significant.add(coll)\n",
    "                    collocate_counts[coll] += obs\n",
    "\n",
    "        print(f\"\\n=== Hypothesis {idx} target words ===\")\n",
    "        print(\", \".join(predefined_words))\n",
    "        print(\"=======================================\\n\")\n",
    "\n",
    "        \n",
    "        # … just before you call filter_collocates_with_removal() …\n",
    "        # 1) Identify any hypothesis keywords that are significant collocates\n",
    "        auto_keywords = [kw for kw in predefined_words if kw in all_significant]\n",
    "        \n",
    "        # 2) Build the manual pool by removing auto_keywords\n",
    "        manual_pool = sorted(set(all_significant) - set(auto_keywords))\n",
    "        \n",
    "        # 3) Prompt the user only on the manual pool\n",
    "        selected, min_count = filter_collocates_with_removal(manual_pool, collocate_counts)\n",
    "        \n",
    "        # 4) Merge the hidden auto_keywords back into selected\n",
    "        for kw in auto_keywords:\n",
    "            if kw not in selected:\n",
    "                selected.append(kw)\n",
    "        if auto_keywords:\n",
    "            print(f\"\\nAutomatically included hidden keyword collocates: {auto_keywords}\\n\")\n",
    "        \n",
    "        # --- C3) Write main table and build summary_by_kw ---\n",
    "        summary_by_kw = { kw: set() for kw in predefined_words }\n",
    "        for kw in predefined_words:\n",
    "            row = [kw]\n",
    "            row_total = 0\n",
    "        \n",
    "            for f in analysis_files:\n",
    "                # restrict to only those you selected as significant\n",
    "                coll_hits = {\n",
    "                    c for c, cnt in counts_by_file_kw[f][kw].items()\n",
    "                    if c in selected\n",
    "                }\n",
    "                # accumulate to summary (includes both “normal” collocates and keyword–keyword)\n",
    "                summary_by_kw[kw].update(coll_hits)\n",
    "        \n",
    "                hits = len(coll_hits)\n",
    "                row.append(hits)          # <- integer only\n",
    "                row_total += hits\n",
    "        \n",
    "            row.append(row_total)        # <- integer only\n",
    "            ws.append(row)\n",
    "        \n",
    "        # --- C4) Totals row (integers only) ---\n",
    "        column_totals = [0]*len(analysis_files)\n",
    "        for r in range(len(predefined_words)):\n",
    "            for c in range(len(analysis_files)):\n",
    "                val = ws.cell(row=r+2, column=c+2).value or 0\n",
    "                column_totals[c] += val\n",
    "        grand_total = sum(column_totals)\n",
    "        ws.append(['Total'] + column_totals + [grand_total])\n",
    "        \n",
    "        # --- C5) Single summary list below the table ---\n",
    "        ws.append([])\n",
    "        ws.append([\"Keyword\", \"Significant Collocates\"])\n",
    "        for kw in predefined_words:\n",
    "            coll_list = \", \".join(sorted(summary_by_kw[kw]))\n",
    "            ws.append([kw, coll_list])\n",
    "\n",
    "        # --- C7) Footer info & optional save/exit per‐hypothesis ---\n",
    "        ws.append([]); ws.append(['p-value threshold:', alpha])\n",
    "        ws.append(['window size:', window])\n",
    "        ws.append(['minimum count threshold:', min_count])\n",
    "\n",
    "        if input(f\"Save results for Hypothesis {idx}? (yes/no): \").strip().lower() == 'yes':\n",
    "            os.makedirs('concordances', exist_ok=True)\n",
    "            wb.save(output_filepath)\n",
    "            print(f\"Results up to Hypothesis {idx} saved to {output_filepath}.\")\n",
    "\n",
    "        if input(\"Exit after this hypothesis? (yes/no): \").strip().lower() == 'yes':\n",
    "            print(\"Exiting.\")\n",
    "            return\n",
    "\n",
    "    # --- D) Final save of workbook ---\n",
    "    os.makedirs('concordances', exist_ok=True)\n",
    "    wb.save(output_filepath)\n",
    "    print(f\"Concordance has been saved to {output_filepath}.\")\n",
    "    \n",
    "# Example usage\n",
    "use_predefined = input(\"Do you want to use predefined target word lists (yes/no)? \").strip().lower() == 'yes'\n",
    "if use_predefined:\n",
    "    predefined_word_lists = get_predefined_target_words()\n",
    "else:\n",
    "    predefined_word_lists = [input(\"Enter words for a group separated by spaces: \").strip().split() for _ in range(5)]\n",
    "\n",
    "alpha = float(input(\"Enter the value for alpha: \").strip())\n",
    "\n",
    "stopwords_file, stopwords_path = select_stopwords_file()\n",
    "if stopwords_file:\n",
    "    stops = read_stopwords(os.path.join(stopwords_path, stopwords_file))\n",
    "    rate_dictionary_files, rate_dictionary_path = select_rate_dictionary_files()\n",
    "    if rate_dictionary_files:\n",
    "       #    build full path if needed:\n",
    "        ref_files = [\n",
    "            os.path.join(rate_dictionary_path, f)\n",
    "            for f in rate_dictionary_files\n",
    "        ]\n",
    "        # 2) pick analysis files\n",
    "        anal_files = prompt_files(find_text_files(os.getcwd()), \"analysis (KWIC)\")\n",
    "        # 3) call with both lists\n",
    "        search_concordance(ref_files, anal_files, predefined_word_lists, stops, alpha)\n",
    "    else:\n",
    "        print(\"No rate dictionary files selected.\")\n",
    "else:\n",
    "    print(\"No stopwords file selected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
