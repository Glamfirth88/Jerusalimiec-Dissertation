{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8caff67c-3802-4748-b128-46821af8a5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the directory for the rate dictionary files:\n",
      "1. /home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/lemmatized\n",
      "2. /home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie\n",
      "3. /home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/.ipynb_checkpoints\n",
      "4. /home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/République\n",
      "5. /home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to include all .txt files in your rate dictionary (default is no)? (yes/no)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " yes\n",
      "Do you want to use the predefined list of words? (yes/no):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the directory for the target files:\n",
      "1. /home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/lemmatized\n",
      "2. /home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie\n",
      "3. /home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/.ipynb_checkpoints\n",
      "4. /home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/République\n",
      "5. /home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select target .txt files (enter numbers separated by commas or ranges, or starting text patterns):\n",
      "1. Discours des raisons_corrected_stemmed.txt\n",
      "2. Démonomanie I.1_corrected_stemmed.txt\n",
      "3. Démonomanie I.2_corrected_stemmed.txt\n",
      "4. Démonomanie I.3_corrected_stemmed.txt\n",
      "5. Démonomanie I.4_corrected_stemmed.txt\n",
      "6. Démonomanie I.5_corrected_stemmed.txt\n",
      "7. Démonomanie I.6_corrected_stemmed.txt\n",
      "8. Démonomanie I.7_corrected_stemmed.txt\n",
      "9. Démonomanie II.1_corrected_stemmed.txt\n",
      "10. Démonomanie II.2_corrected_stemmed.txt\n",
      "11. Démonomanie II.3_corrected_stemmed.txt\n",
      "12. Démonomanie II.4_corrected_stemmed.txt\n",
      "13. Démonomanie II.5_corrected_stemmed.txt\n",
      "14. Démonomanie II.6_corrected_stemmed.txt\n",
      "15. Démonomanie II.7_corrected_stemmed.txt\n",
      "16. Démonomanie II.8_corrected_stemmed.txt\n",
      "17. Démonomanie III.1_corrected_stemmed.txt\n",
      "18. Démonomanie III.2_corrected_stemmed.txt\n",
      "19. Démonomanie III.3_corrected_stemmed.txt\n",
      "20. Démonomanie III.4_corrected_stemmed.txt\n",
      "21. Démonomanie III.5_corrected_stemmed.txt\n",
      "22. Démonomanie III.6_corrected_stemmed.txt\n",
      "23. Démonomanie IV.1_corrected_stemmed.txt\n",
      "24. Démonomanie IV.2_corrected_stemmed.txt\n",
      "25. Démonomanie IV.3_corrected_stemmed.txt\n",
      "26. Démonomanie IV.4_corrected_stemmed.txt\n",
      "27. Démonomanie IV.5_corrected_stemmed.txt\n",
      "28. Démonomanie preface Repair_corrected_stemmed.txt\n",
      "29. Harangue - Fontainebleau_corrected_stemmed.txt\n",
      "30. Harangue - Orléans 2_corrected_stemmed.txt\n",
      "31. Harangue - Orléans_corrected_stemmed.txt\n",
      "32. Harangue - Poissy_corrected_stemmed.txt\n",
      "33. Harangue - Rouen_corrected_stemmed.txt\n",
      "34. Harangue - Saint Germain_corrected_stemmed.txt\n",
      "35. Harangue - lit de justice_corrected_stemmed.txt\n",
      "36. Harangue - ouverture de parlement_corrected_stemmed.txt\n",
      "37. Harangue - parlement 2_corrected_stemmed.txt\n",
      "38. Harangue - parlement 3_corrected_stemmed.txt\n",
      "39. Harangue - parlement_corrected_stemmed.txt\n",
      "40. Harangue - religion_corrected_stemmed.txt\n",
      "41. Harangue - septembre_corrected_stemmed.txt\n",
      "42. La réponse_corrected_stemmed.txt\n",
      "43. Le paradoxe_corrected_stemmed.txt\n",
      "44. Lettre_corrected_stemmed.txt\n",
      "45. Lit de justice_corrected_stemmed.txt\n",
      "46. Memoire - Namur_corrected_stemmed.txt\n",
      "47. Memoire - le but_corrected_stemmed.txt\n",
      "48. Memoire au roi_corrected_stemmed.txt\n",
      "49. Memoires d'État Refuge_corrected_stemmed.txt\n",
      "50. Memoires d'état_corrected_stemmed.txt\n",
      "51. Recueil_corrected_stemmed.txt\n",
      "52. Remonstrances - Royaume_corrected_stemmed.txt\n",
      "53. Remonstrances - parlement_corrected_stemmed.txt\n",
      "54. République I.1_corrected_stemmed.txt\n",
      "55. République I.2_corrected_stemmed.txt\n",
      "56. République I.3_corrected_stemmed.txt\n",
      "57. République I.4_corrected_stemmed.txt\n",
      "58. République I.5_corrected_stemmed.txt\n",
      "59. République I.6_corrected_stemmed.txt\n",
      "60. République I.7_corrected_stemmed.txt\n",
      "61. République I.8_corrected_stemmed.txt\n",
      "62. République I.910_corrected_stemmed.txt\n",
      "63. République I.911_corrected_stemmed.txt\n",
      "64. République I.9_corrected_stemmed.txt\n",
      "65. République II.1_corrected_stemmed.txt\n",
      "66. République II.2_corrected_stemmed.txt\n",
      "67. République II.3_corrected_stemmed.txt\n",
      "68. République II.4_corrected_stemmed.txt\n",
      "69. République II.5_corrected_stemmed.txt\n",
      "70. République II.6_corrected_stemmed.txt\n",
      "71. République II.7_corrected_stemmed.txt\n",
      "72. République III.1_corrected_stemmed.txt\n",
      "73. République III.2_corrected_stemmed.txt\n",
      "74. République III.3_corrected_stemmed.txt\n",
      "75. République III.4_corrected_stemmed.txt\n",
      "76. République III.5_corrected_stemmed.txt\n",
      "77. République III.6_corrected_stemmed.txt\n",
      "78. République III.7_corrected_stemmed.txt\n",
      "79. République IV.1_corrected_stemmed.txt\n",
      "80. République IV.2_corrected_stemmed.txt\n",
      "81. République IV.3_corrected_stemmed.txt\n",
      "82. République IV.4_corrected_stemmed.txt\n",
      "83. République IV.5_corrected_stemmed.txt\n",
      "84. République IV.6_corrected_stemmed.txt\n",
      "85. République IV.7_corrected_stemmed.txt\n",
      "86. République V.1_corrected_stemmed.txt\n",
      "87. République V.2_corrected_stemmed.txt\n",
      "88. République V.3_corrected_stemmed.txt\n",
      "89. République V.4_corrected_stemmed.txt\n",
      "90. République V.5_corrected_stemmed.txt\n",
      "91. République VI.1_corrected_stemmed.txt\n",
      "92. République VI.2_corrected_stemmed.txt\n",
      "93. République VI.3_corrected_stemmed.txt\n",
      "94. République VI.4_corrected_stemmed.txt\n",
      "95. République VI.5_corrected_stemmed.txt\n",
      "96. République VI.6_corrected_stemmed.txt\n",
      "97. République preface_corrected_stemmed.txt\n",
      "98. Théatre III_corrected_stemmed.txt\n",
      "99. Théatre II_corrected_stemmed.txt\n",
      "100. Théatre IV_corrected_stemmed.txt\n",
      "101. Théatre I_corrected_stemmed.txt\n",
      "102. Théatre V_corrected_stemmed.txt\n",
      "103. Théatre summary_corrected_stemmed.txt\n",
      "104. Traite Justice VII_corrected_stemmed.txt\n",
      "105. Traite Justice VI_corrected_stemmed.txt\n",
      "106. Traite Justice V_corrected_stemmed.txt\n",
      "107. Traité Justice III_corrected_stemmed.txt\n",
      "108. Traité Justice II_corrected_stemmed.txt\n",
      "109. Traité Justice IV_corrected_stemmed.txt\n",
      "110. Traité Justice I_corrected_stemmed.txt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choices:  Dém,Rép\n",
      "Enter the threshold for word count (default is 5):  1\n",
      "Enter the p-value threshold (default is 0.10):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a .csv file to use as a stopwords file:\n",
      "1. /home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/lemmatized/stop_words.csv\n",
      "2. /home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/stop_words.csv\n",
      "3. /home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/République/stop_words.csv\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas-jerusalimiec/.local/lib/python3.12/site-packages/openpyxl/workbook/child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n",
      "/home/lucas-jerusalimiec/.local/lib/python3.12/site-packages/openpyxl/workbook/child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to select new target files in a new directory? (yes/no):  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results successfully written to /home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/results_mdw.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from scipy.stats import fisher_exact\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Define a list of words to calculate Fisher's exact test for\n",
    "predefined_words = [\n",
    "    'absolu', 'arrest', 'bien', 'chos', 'citoyen', 'conseil', 'conseiller', 'confess', \n",
    "    'cour', 'couron', 'demon', 'demoniaqu', 'diabl', 'diabol', 'dieu', 'divin', 'domain', \n",
    "    'droit', 'édict', 'estat', 'hebrieu', 'impiet', 'iurisdict', 'jug', 'just', 'loi', \n",
    "    'magistrat', 'maiest', 'offic', 'offici', 'ordon', 'parlement', 'preuv', 'princ', \n",
    "    'puissanc', 'question', 'republ', 'ressort', 'roy', 'royal', 'royaum', 'sathan', \n",
    "    'seigneur', 'sorceller', 'sorci', 'souverain', 'souverainet', 'statut', 'sujet'\n",
    "]\n",
    "\n",
    "# Global variable to store the chosen stopwords file path\n",
    "selected_stopwords_file_path = None\n",
    "\n",
    "def tokenize_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        return file.read().split()\n",
    "\n",
    "def list_txt_files(directory):\n",
    "    return sorted([f for f in os.listdir(directory) if f.endswith('.txt')])\n",
    "\n",
    "def choose_directory(prompt):\n",
    "    base_directory = os.getcwd()\n",
    "    subdirectories = [os.path.join(base_directory, o) for o in os.listdir(base_directory) if os.path.isdir(os.path.join(base_directory, o))]\n",
    "    subdirectories.append(base_directory)\n",
    "    print(prompt)\n",
    "    for i, subdir in enumerate(subdirectories):\n",
    "        print(f\"{i + 1}. {subdir}\")\n",
    "    choice = int(input(\"Enter your choice: \"))\n",
    "    return subdirectories[choice - 1]\n",
    "\n",
    "def choose_files(files):\n",
    "    print(\"Select target .txt files (enter numbers separated by commas or ranges, or starting text patterns):\")\n",
    "    for i, file in enumerate(files):\n",
    "        print(f\"{i + 1}. {file}\")\n",
    "    choices = input(\"Enter your choices: \").strip()\n",
    "    selected_files = []\n",
    "    parts = choices.split(',')\n",
    "    for part in parts:\n",
    "        part = part.strip()\n",
    "        if '-' in part:\n",
    "            start, end = map(int, part.split('-'))\n",
    "            selected_files.extend(files[start - 1:end])\n",
    "        elif part.isdigit():\n",
    "            selected_files.append(files[int(part) - 1])\n",
    "        else:\n",
    "            selected_files.extend([file for file in files if file.startswith(part)])\n",
    "    return sorted(set(selected_files))  # Remove duplicates and sort\n",
    "\n",
    "def include_files(files):\n",
    "    print(\"Available .txt files:\")\n",
    "    for i, file in enumerate(files):\n",
    "        print(f\"{i + 1}. {file}\")\n",
    "    print(\"Enter the numbers of the files you want to include, separated by commas:\")\n",
    "    choices = input().split(',')\n",
    "    included_files = [files[int(choice.strip()) - 1] for choice in choices if choice.strip().isdigit()]\n",
    "    return included_files\n",
    "\n",
    "def exclude_files(files):\n",
    "    print(\"Available .txt files:\")\n",
    "    for i, file in enumerate(files):\n",
    "        print(f\"{i + 1}. {file}\")\n",
    "    print(\"Enter the numbers of the files you want to exclude, separated by commas:\")\n",
    "    choices = input().split(',')\n",
    "    excluded_files = [files[int(choice.strip()) - 1] for choice in choices if choice.strip().isdigit()]\n",
    "    return [file for file in files if file not in excluded_files]\n",
    "\n",
    "def get_fishers(someword, somecountdict, someratedict, alternative='greater'):\n",
    "    r = someratedict[someword]\n",
    "    wc = sum(somecountdict.values())\n",
    "    a = somecountdict[someword]\n",
    "    b = wc - a\n",
    "    c = round(r * wc)\n",
    "    d = wc - c\n",
    "    p = fisher_exact([[a, b], [c, d]], alternative=alternative).pvalue\n",
    "    return p\n",
    "\n",
    "def list_csv_files(directory):\n",
    "    csv_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv') and 'stop' in file:\n",
    "                csv_files.append(os.path.join(root, file))\n",
    "    return csv_files\n",
    "\n",
    "def choose_csv_file(csv_files):\n",
    "    print(\"Select a .csv file to use as a stopwords file:\")\n",
    "    for i, file in enumerate(csv_files):\n",
    "        print(f\"{i + 1}. {file}\")\n",
    "    choice = int(input(\"Enter your choice: \"))\n",
    "    return csv_files[choice - 1]\n",
    "\n",
    "def read_stopwords(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        stopwords = []\n",
    "        for row in reader:\n",
    "            for word in row:\n",
    "                stopwords.extend(word.split(','))\n",
    "        return [word.strip() for word in stopwords]\n",
    "\n",
    "def calculate_fishers_exact_for_corpus():\n",
    "    global selected_stopwords_file_path\n",
    "\n",
    "    # Prompt user to select the directory for rate dictionary files\n",
    "    rate_directory = choose_directory(\"Select the directory for the rate dictionary files:\")\n",
    "    rate_files = list_txt_files(rate_directory)\n",
    "    if not rate_files:\n",
    "        print(\"No .txt files found in the selected rate directory.\")\n",
    "        return\n",
    "\n",
    "    # Prompt user to include all or use custom selection\n",
    "    print(\"Do you want to include all .txt files in your rate dictionary (default is no)? (yes/no)\")\n",
    "    include_all = input().strip().lower()\n",
    "    if include_all == 'yes':\n",
    "        selected_rate_files = rate_files\n",
    "    else:\n",
    "        print(\"Would you like to include specific files or exclude specific files?\")\n",
    "        print(\"1. Include specific files\")\n",
    "        print(\"2. Exclude specific files\")\n",
    "        method = input(\"Enter 1 or 2: \").strip()\n",
    "        if method == '1':\n",
    "            selected_rate_files = include_files(rate_files)\n",
    "        elif method == '2':\n",
    "            selected_rate_files = exclude_files(rate_files)\n",
    "        else:\n",
    "            print(\"Invalid choice. Exiting.\")\n",
    "            return\n",
    "\n",
    "    if not selected_rate_files:\n",
    "        print(\"No .txt files selected after custom selection.\")\n",
    "        return\n",
    "\n",
    "    # Create an Excel writer\n",
    "    output_filename = \"results_mdw.xlsx\"\n",
    "    output_filepath = os.path.join(os.getcwd(), output_filename)\n",
    "    with pd.ExcelWriter(output_filepath, engine='openpyxl') as writer:\n",
    "        # Ensure at least one visible sheet\n",
    "        writer.book.create_sheet(title=\"Placeholder\")\n",
    "\n",
    "        # Prompt user if they want to use the predefined list of words\n",
    "        use_predefined_list = input(\"Do you want to use the predefined list of words? (yes/no): \").strip().lower() == 'yes'\n",
    "        words_to_check = predefined_words if use_predefined_list else None\n",
    "\n",
    "        while True:\n",
    "            # Prompt user to select the directory for target files\n",
    "            target_directory = choose_directory(\"Select the directory for the target files:\")\n",
    "            target_files = list_txt_files(target_directory)\n",
    "            if not target_files:\n",
    "                print(\"No .txt files found in the selected target directory.\")\n",
    "                return\n",
    "\n",
    "            target_files = choose_files(target_files)\n",
    "            target_file_paths = [os.path.join(target_directory, file) for file in target_files]\n",
    "\n",
    "            # Initialize dictionaries\n",
    "            rate_doc_counts = {}\n",
    "            target_doc_counts = {}\n",
    "            rates = {}\n",
    "\n",
    "            # Count words in rate_files\n",
    "            all_counts = {}\n",
    "            for f in selected_rate_files:\n",
    "                rate_doc_counts[f] = {}\n",
    "                words = tokenize_file(os.path.join(rate_directory, f))\n",
    "                for w in words:\n",
    "                    if w not in rate_doc_counts[f]:\n",
    "                        rate_doc_counts[f][w] = 0\n",
    "                    rate_doc_counts[f][w] += 1\n",
    "                    if w not in all_counts:\n",
    "                        all_counts[w] = 0\n",
    "                    all_counts[w] += 1\n",
    "\n",
    "            total_wc = sum(all_counts.values())\n",
    "\n",
    "            # Calculate rates using rate_doc_counts\n",
    "            for word in all_counts:\n",
    "                rates[word] = all_counts[word] / total_wc\n",
    "\n",
    "            # Count words in target_files\n",
    "            for f in target_files:\n",
    "                target_doc_counts[f] = {}\n",
    "                words = tokenize_file(os.path.join(target_directory, f))\n",
    "                for w in words:\n",
    "                    if w not in target_doc_counts[f]:\n",
    "                        target_doc_counts[f][w] = 0\n",
    "                    target_doc_counts[f][w] += 1\n",
    "\n",
    "            # Ask user for threshold\n",
    "            threshold = input(\"Enter the threshold for word count (default is 5): \")\n",
    "            if not threshold.isdigit():\n",
    "                threshold = 5\n",
    "            else:\n",
    "                threshold = int(threshold)\n",
    "\n",
    "            # Ask user for p-value\n",
    "            p_value_threshold = input(\"Enter the p-value threshold (default is 0.10): \")\n",
    "            if not p_value_threshold.replace('.', '', 1).isdigit():\n",
    "                p_value_threshold = 0.10\n",
    "            else:\n",
    "                p_value_threshold = float(p_value_threshold)\n",
    "\n",
    "            # Process each target file\n",
    "            for target_file in target_files:\n",
    "                countdict = target_doc_counts[target_file]\n",
    "\n",
    "                # List .csv files in the current working directory and subdirectories\n",
    "                csv_files = list_csv_files(os.getcwd())\n",
    "                if not csv_files:\n",
    "                    print(\"No .csv files found in the current working directory or subdirectories.\")\n",
    "                    return\n",
    "\n",
    "                # Choose a .csv file if not already selected\n",
    "                if not selected_stopwords_file_path:\n",
    "                    selected_stopwords_file_path = choose_csv_file(csv_files)\n",
    "\n",
    "                # Read stopwords from the selected .csv file\n",
    "                stops = read_stopwords(selected_stopwords_file_path)\n",
    "\n",
    "                # Prepare output table\n",
    "                output_table = [['token_', 'count', 'p-value', 'obs/exp']]\n",
    "                words_to_check = predefined_words if use_predefined_list else countdict.keys()\n",
    "                \n",
    "                for word in words_to_check:\n",
    "                    if word not in countdict or countdict[word] < threshold:\n",
    "                        continue\n",
    "                    if word in stops:\n",
    "                        continue\n",
    "                    p = get_fishers(word, countdict, rates)\n",
    "                    exp = rates[word] * sum(countdict.values())\n",
    "                    if p < p_value_threshold:\n",
    "                        new_row = [word, countdict[word], p, countdict[word] / exp]\n",
    "                        output_table.append(new_row)\n",
    "\n",
    "                # Sort the output table by count in descending order\n",
    "                output_table[1:] = sorted(output_table[1:], key=lambda x: x[1], reverse=True)\n",
    "\n",
    "                # Convert output table to DataFrame\n",
    "                df_output = pd.DataFrame(output_table[1:], columns=output_table[0])\n",
    "\n",
    "                # Write results to a new sheet in the Excel file\n",
    "                sheet_name = os.path.splitext(target_file)[0]\n",
    "                df_output.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "                # Remove the placeholder sheet once a real sheet is added\n",
    "                if \"Placeholder\" in writer.book.sheetnames:\n",
    "                    writer.book.remove(writer.book[\"Placeholder\"])\n",
    "\n",
    "            # Ask user if they want to select new target files\n",
    "            new_target_files = input(\"Do you want to select new target files in a new directory? (yes/no): \").strip().lower()\n",
    "            if new_target_files != 'yes':\n",
    "                break\n",
    "\n",
    "    # Check if the file was saved\n",
    "    if os.path.isfile(output_filepath):\n",
    "        print(f\"Results successfully written to {output_filepath}\")\n",
    "    else:\n",
    "        print(\"Error: The file was not saved.\")\n",
    "\n",
    "# Call the function\n",
    "calculate_fishers_exact_for_corpus()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
