{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcd07665-38bc-4fed-8621-4a04acb65976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import glob, a module that helps with file management.\n",
    "import glob\n",
    "import pandas as pd\n",
    "from spellchecker import SpellChecker\n",
    "from pathlib import Path\n",
    "from nltk import wordpunct_tokenize\n",
    "from collections import Counter\n",
    "import os\n",
    "import re\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Alignment, Font\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27b7fc5d-c697-4ef5-ac4d-c6345a5936cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text files to be spellchecked: ['Démonomanie I.1.txt', 'Démonomanie I.2.txt', 'Démonomanie I.3.txt', 'Démonomanie I.4.txt', 'Démonomanie I.5.txt', 'Démonomanie I.6.txt', 'Démonomanie I.7.txt', 'Démonomanie II.1.txt', 'Démonomanie II.2.txt', 'Démonomanie II.3.txt', 'Démonomanie II.4.txt', 'Démonomanie II.5.txt', 'Démonomanie II.6.txt', 'Démonomanie II.7.txt', 'Démonomanie II.8.txt', 'Démonomanie III.1.txt', 'Démonomanie III.2.txt', 'Démonomanie III.3.txt', 'Démonomanie III.4.txt', 'Démonomanie III.5.txt', 'Démonomanie III.6.txt', 'Démonomanie IV.1.txt', 'Démonomanie IV.2.txt', 'Démonomanie IV.3.txt', 'Démonomanie IV.4.txt', 'Démonomanie IV.5.txt', 'Démonomanie preface Repair.txt']\n",
      "current_directory = 'Démonomanie'\n"
     ]
    }
   ],
   "source": [
    "# Define the output path and create the directory if it doesn't exist\n",
    "outputpath = \"./final\"\n",
    "outputfile_path = Path(outputpath)\n",
    "outputfile_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Get the current working directory\n",
    "texts_folder = Path.cwd()\n",
    "\n",
    "# Find all .txt files in the current directory\n",
    "texts_list = sorted(glob.glob(\"*.txt\"))\n",
    "print(\"Text files to be spellchecked:\", texts_list)\n",
    "\n",
    "current_directory = os.path.basename(os.getcwd())\n",
    "\n",
    "print(f\"current_directory = '{current_directory}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8251a74-964b-47ac-9752-9d785cb06cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spellchecker dictionary.\n",
    "# Replace the language attribute with another 2 letter code\n",
    "# to select another language. Options are: English - ‘en’, Spanish - ‘es’,\n",
    "# French - ‘fr’, Portuguese - ‘pt’, German - ‘de’, Russian - ‘ru’.\n",
    "\n",
    "spell = SpellChecker(language='fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ecc53a-e640-428e-8a1a-8a1d83daaf7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie I.1.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie I.2.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie I.3.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie I.4.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie I.5.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie I.6.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie I.7.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie II.1.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie II.2.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie II.3.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie II.4.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie II.5.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie II.6.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie II.7.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie II.8.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie III.1.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie III.2.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie III.3.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie III.4.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie III.5.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie III.6.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie IV.1.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie IV.2.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie IV.3.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie IV.4.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie IV.5.txt checked for readability.\n",
      "/home/lucas-jerusalimiec/Documents/OCR Text/Text/Sectionized/Démonomanie/Démonomanie preface Repair.txt checked for readability.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>token_count</th>\n",
       "      <th>unknown_count</th>\n",
       "      <th>readability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie I.1.txt</td>\n",
       "      <td>2931</td>\n",
       "      <td>1218</td>\n",
       "      <td>58.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie I.2.txt</td>\n",
       "      <td>3639</td>\n",
       "      <td>1371</td>\n",
       "      <td>62.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie I.3.txt</td>\n",
       "      <td>3189</td>\n",
       "      <td>1286</td>\n",
       "      <td>59.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie I.4.txt</td>\n",
       "      <td>3574</td>\n",
       "      <td>1373</td>\n",
       "      <td>61.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie I.5.txt</td>\n",
       "      <td>6484</td>\n",
       "      <td>2274</td>\n",
       "      <td>64.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie I.6.txt</td>\n",
       "      <td>3195</td>\n",
       "      <td>1335</td>\n",
       "      <td>58.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie I.7.txt</td>\n",
       "      <td>1467</td>\n",
       "      <td>659</td>\n",
       "      <td>55.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie II.1.txt</td>\n",
       "      <td>3553</td>\n",
       "      <td>1420</td>\n",
       "      <td>60.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie II.2.txt</td>\n",
       "      <td>4481</td>\n",
       "      <td>1733</td>\n",
       "      <td>61.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie II.3.txt</td>\n",
       "      <td>4955</td>\n",
       "      <td>2053</td>\n",
       "      <td>58.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie II.4.txt</td>\n",
       "      <td>4492</td>\n",
       "      <td>1821</td>\n",
       "      <td>59.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie II.5.txt</td>\n",
       "      <td>2396</td>\n",
       "      <td>1117</td>\n",
       "      <td>53.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie II.6.txt</td>\n",
       "      <td>4307</td>\n",
       "      <td>1675</td>\n",
       "      <td>61.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie II.7.txt</td>\n",
       "      <td>2221</td>\n",
       "      <td>1009</td>\n",
       "      <td>54.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie II.8.txt</td>\n",
       "      <td>4329</td>\n",
       "      <td>1775</td>\n",
       "      <td>59.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie III.1.txt</td>\n",
       "      <td>4761</td>\n",
       "      <td>1906</td>\n",
       "      <td>59.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie III.2.txt</td>\n",
       "      <td>2324</td>\n",
       "      <td>971</td>\n",
       "      <td>58.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie III.3.txt</td>\n",
       "      <td>2890</td>\n",
       "      <td>1218</td>\n",
       "      <td>57.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie III.4.txt</td>\n",
       "      <td>2351</td>\n",
       "      <td>1010</td>\n",
       "      <td>57.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sectionized/Démonomanie/Démonomanie III.5.txt</td>\n",
       "      <td>4416</td>\n",
       "      <td>1692</td>\n",
       "      <td>61.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        file_name  token_count  unknown_count  \\\n",
       "0     Sectionized/Démonomanie/Démonomanie I.1.txt         2931           1218   \n",
       "1     Sectionized/Démonomanie/Démonomanie I.2.txt         3639           1371   \n",
       "2     Sectionized/Démonomanie/Démonomanie I.3.txt         3189           1286   \n",
       "3     Sectionized/Démonomanie/Démonomanie I.4.txt         3574           1373   \n",
       "4     Sectionized/Démonomanie/Démonomanie I.5.txt         6484           2274   \n",
       "5     Sectionized/Démonomanie/Démonomanie I.6.txt         3195           1335   \n",
       "6     Sectionized/Démonomanie/Démonomanie I.7.txt         1467            659   \n",
       "7    Sectionized/Démonomanie/Démonomanie II.1.txt         3553           1420   \n",
       "8    Sectionized/Démonomanie/Démonomanie II.2.txt         4481           1733   \n",
       "9    Sectionized/Démonomanie/Démonomanie II.3.txt         4955           2053   \n",
       "10   Sectionized/Démonomanie/Démonomanie II.4.txt         4492           1821   \n",
       "11   Sectionized/Démonomanie/Démonomanie II.5.txt         2396           1117   \n",
       "12   Sectionized/Démonomanie/Démonomanie II.6.txt         4307           1675   \n",
       "13   Sectionized/Démonomanie/Démonomanie II.7.txt         2221           1009   \n",
       "14   Sectionized/Démonomanie/Démonomanie II.8.txt         4329           1775   \n",
       "15  Sectionized/Démonomanie/Démonomanie III.1.txt         4761           1906   \n",
       "16  Sectionized/Démonomanie/Démonomanie III.2.txt         2324            971   \n",
       "17  Sectionized/Démonomanie/Démonomanie III.3.txt         2890           1218   \n",
       "18  Sectionized/Démonomanie/Démonomanie III.4.txt         2351           1010   \n",
       "19  Sectionized/Démonomanie/Démonomanie III.5.txt         4416           1692   \n",
       "\n",
       "    readability  \n",
       "0         58.44  \n",
       "1         62.32  \n",
       "2         59.67  \n",
       "3         61.58  \n",
       "4         64.93  \n",
       "5         58.22  \n",
       "6         55.08  \n",
       "7         60.03  \n",
       "8         61.33  \n",
       "9         58.57  \n",
       "10        59.46  \n",
       "11        53.38  \n",
       "12        61.11  \n",
       "13        54.57  \n",
       "14        59.00  \n",
       "15        59.97  \n",
       "16        58.22  \n",
       "17        57.85  \n",
       "18        57.04  \n",
       "19        61.68  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty list to collect data\n",
    "data_list = []\n",
    "\n",
    "with pd.ExcelWriter(f'{current_directory}_spellcheck_data.xlsx', engine='openpyxl') as writer:\n",
    "    for txt_file in sorted(texts_folder.glob('*.txt')):\n",
    "        \n",
    "        # Extract the relevant parts of the file path\n",
    "        parts = txt_file.parts[-3:]\n",
    "        file_name = os.path.join(parts[0], parts[1], parts[2])\n",
    "        \n",
    "        # Open each text file and read text into `ocrText`\n",
    "        with open(txt_file, 'r') as inputFile:\n",
    "            ocrText = inputFile.read()\n",
    "            \n",
    "        # Join hyphenated words that are split between lines\n",
    "        ocrText = ocrText.replace(\"-\\n\", \"\")\n",
    "        \n",
    "        # Tokenize the text\n",
    "        tokens = wordpunct_tokenize(ocrText)\n",
    "        \n",
    "        # Lowercase all tokens and filter out non-alphabetic tokens\n",
    "        tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "        \n",
    "        # Identify unknown words\n",
    "        spell = SpellChecker()\n",
    "        unknown = spell.unknown(tokens)\n",
    "        \n",
    "        # Calculate readability\n",
    "        if len(unknown) != 0:\n",
    "            readability = round(100 - (float(len(unknown)) / float(len(tokens)) * 100), 2)\n",
    "        else:\n",
    "            readability = 100\n",
    "        \n",
    "        # Sort the unknown words first by 'counts' descending and then by 'unknown_tokens' alphabetically\n",
    "        sorted_unknown = sorted(Counter(unknown).items(), key=lambda item: (-item[1], item[0]))\n",
    "        \n",
    "        # Append the data for this file to the list\n",
    "        data_list.append({\n",
    "            \"file_name\": file_name,\n",
    "            \"token_count\": len(tokens),\n",
    "            \"unknown_count\": len(unknown),\n",
    "            \"readability\": readability,\n",
    "        })\n",
    "        \n",
    "        # Write the DataFrame to a new sheet in the Excel file\n",
    "        pd.DataFrame([data_list[-1]]).to_excel(writer, sheet_name=os.path.splitext(txt_file.name)[0], index=False)\n",
    "        \n",
    "        # Write the unknown tokens and counts vertically\n",
    "        sheet = writer.sheets[os.path.splitext(txt_file.name)[0]]\n",
    "        start_row = 6  # Add two extra rows of space\n",
    "        sheet.cell(row=start_row, column=1, value=\"unknown_tokens\").font = Font(bold=True)\n",
    "        sheet.cell(row=start_row, column=2, value=\"counts\").font = Font(bold=True)\n",
    "        for i, (token, count) in enumerate(sorted_unknown, start=start_row + 1):\n",
    "            sheet.cell(row=i, column=1, value=token)\n",
    "            sheet.cell(row=i, column=2, value=count)\n",
    "        \n",
    "        # Print a message indicating the file has been processed\n",
    "        print(txt_file, \"checked for readability.\")\n",
    "    \n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame(data_list)\n",
    "\n",
    "  \n",
    "    # Write the combined DataFrame to a summary sheet\n",
    "    df.to_excel(writer, sheet_name='Summary', index=False)\n",
    "\n",
    "# Load the workbook to adjust cell alignment\n",
    "wb = load_workbook(f'{current_directory}_spellcheck_data.xlsx')\n",
    "\n",
    "# Align cells in the summary sheet\n",
    "summary_sheet = wb['Summary']\n",
    "for row in summary_sheet.iter_rows(min_row=2, max_row=summary_sheet.max_row, min_col=1, max_col=4):\n",
    "    for cell in row:\n",
    "        cell.alignment = Alignment(vertical='top')\n",
    "\n",
    "# Align cells in each individual sheet\n",
    "for sheet_name in wb.sheetnames:\n",
    "    if sheet_name != 'Summary':\n",
    "        sheet = wb[sheet_name]\n",
    "        for row in sheet.iter_rows(min_row=2, max_row=sheet.max_row, min_col=1, max_col=4):\n",
    "            for cell in row:\n",
    "                cell.alignment = Alignment(vertical='top')\n",
    "\n",
    "# Save the workbook with the updated alignment\n",
    "wb.save(f'{current_directory}_spellcheck_data.xlsx')\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30da9866-7585-4a98-973a-601c3c991bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_words = [\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'ainfi', 'ariftote', 'auffi', 'aufli', 'auons', 'auoient',\n",
    "    'brufler', 'bruflé', 'bruflés', 'bruflées', 'bruflerent', 'brufloient',\n",
    "    'caufe', 'caufes', 'cefte', 'celeftes', 'celte', 'chan- \\ngement', \n",
    "    'chofe', 'chofes', 'ciuil',\n",
    "    'confefla', 'confefle', 'confeflé', 'confefler', 'confeflerent', 'confeflion', 'conveflions', 'confefloyent',\n",
    "    'deffus', 'deflus', 'deſquels', 'def- \\nquels', 'dia ble', 'dia- \\n\\nbles', \n",
    "    'dia- \\nble', 'dia- \\nbolique', 'dia- \\nboliques', 'diabo- \\nliques', ' difant', 'difoit',\n",
    "    'diuin', 'diuins', 'diuine', 'diuines', 'diuinité', 'doibt',\n",
    "    'efcript', 'efcripte', 'efcriptes', 'efcripture', 'efprit', 'efprits', 'eftà', 'empe- \\nreur', ' enla ', 'enlaloy', ' eten ', 'expe- \\nrience',\n",
    "    'faiét', 'faifant', 'faincte', 'fans', 'fix', 'fem- \\nblable', \n",
    "    'fem- \\nblables', 'feulement', 'fouuent', 'fupernaturelles',\n",
    "    'hiftoire', 'hiftoires', 'honteufes', 'hu- \\nmainc', 'hu- \\nmaine',\n",
    "    'imagi- \\nner', 'l\\'imagi- \\nnation', \n",
    "    ' laloy ', 'lefe', 'leuiathan', 'liure',\n",
    "    'maiftre', 'male- \\nfices', 'maling', 'malings', 'mefme', 'mefmes', 'monftré', 'mouuement', 'mou- \\nrir', 'moyés',\n",
    "    'na- \\nture', 'natu- \\nre', 'natu- \\nrc', \n",
    "    'natu- \\nrelle', 'œuures', 'ordi- \\nnaire', 'ordi- naires',\n",
    "    'parlemens', 'paruenire', 'perfonne', 'perfonnes', 'perfonnage', 'perfonnages',\n",
    "    'peuuent', 'plufieurs', 'plu- \\n\\nfieurs', \n",
    "    'plu- \\nficurs', 'plu- \\nfieurs', 'prefomption', 'prefomptions', 'preuue',\n",
    "    'pro- \\nphetie', 'pro- \\npheties', 'pro- \\nphetize', \n",
    "    'pro- \\nphetes', 'puiflance', 'qvatriesme', 'raifon', 'sor- \\ncelleries', 'sor- \\ncicr', 'sor- \\nciet', 'sor- \\nciere', \n",
    "    'sor- \\ncier', 'trouua', 'trouue', 'trouué', 'trouuées', 'vns'\n",
    "]\n",
    "\n",
    "\n",
    "known_words = [\n",
    "    '', '', '', '', '', '', '', '', '', '', 'ainsi', 'aristote', 'aussi', 'aussi', 'avons', 'avoient',\n",
    "    'brûler', 'brûlé', 'brûlés', 'brûlées', 'brûlerent', 'brûloient',\n",
    "    'cause', 'causes', 'ceste', 'celestes', 'ceste', 'changement', \n",
    "    'chose', 'choses', 'civil',\n",
    "    'confessa', 'confesse', 'confessé', 'confesser', 'confessèrent', 'confession', 'confessions', 'confessaient',\n",
    "    'dessus', 'dessus', 'desquels', 'desquels', 'diable', 'diables', \n",
    "    'diable', 'diabolique', 'diaboliques', 'diaboliques', ' disant', 'disoit',\n",
    "    'divin', 'divins', 'divine', 'divines', 'divinité', 'doit',\n",
    "    'escript', 'escripte', 'escriptes', 'escripture', 'esprit', 'esprits', 'cest à', 'empereur', ' en la', 'en la loy', ' et en ', 'experience',\n",
    "    'fait', 'faisant', 'saincte', 'sans', 'six', 'semblable',\n",
    "    'semblables', 'seulement', 'souvent', 'supernaturelles',\n",
    "    'histoire', 'histoires', 'honteuses', 'humaine', 'humaine',\n",
    "    'imaginer', 'l\\'imagination',\n",
    "    'la loy ', 'lese', 'leviathan', 'livre',\n",
    "    'maistre', 'malefices', 'malin', 'malins', 'mesme', 'mesmes', 'monstré', 'mouvement', 'mourir', 'moyens',\n",
    "    'nature', 'nature', 'nature',\n",
    "    'naturelle', 'oeuvres', 'ordinaire', 'ordinaires',\n",
    "    'parlements', 'parvenir', 'personne', 'personnes', 'personnage', 'personnages',\n",
    "    'peuvent', 'plusieurs', 'plusieurs',\n",
    "    'plusieurs', 'plusieurs', 'presomption', 'presomptions', 'preuve',\n",
    "    'prophetie', 'propheties', 'prophetize',\n",
    "    'prophetes', 'puissance', 'quatriesme', 'raison', 'sorcelleries', 'sorcier', 'sorcier', 'sorciere',\n",
    "    'sorcier', 'trouva', 'trouve', 'trouvé', 'trouvées', 'uns'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c1a9b4d-255b-4d65-89ac-1bd2147041e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All instances of '0' replaced with ''.\n",
      "All instances of '1' replaced with ''.\n",
      "All instances of '2' replaced with ''.\n",
      "All instances of '3' replaced with ''.\n",
      "All instances of '4' replaced with ''.\n",
      "All instances of '5' replaced with ''.\n",
      "All instances of '6' replaced with ''.\n",
      "All instances of '7' replaced with ''.\n",
      "All instances of '8' replaced with ''.\n",
      "All instances of '9' replaced with ''.\n",
      "All instances of 'ainfi' replaced with 'ainsi'.\n",
      "All instances of 'ariftote' replaced with 'aristote'.\n",
      "All instances of 'auffi' replaced with 'aussi'.\n",
      "All instances of 'aufli' replaced with 'aussi'.\n",
      "All instances of 'auons' replaced with 'avons'.\n",
      "All instances of 'auoient' replaced with 'avoient'.\n",
      "All instances of 'brufler' replaced with 'brûler'.\n",
      "All instances of 'bruflé' replaced with 'brûlé'.\n",
      "All instances of 'bruflés' replaced with 'brûlés'.\n",
      "All instances of 'bruflées' replaced with 'brûlées'.\n",
      "All instances of 'bruflerent' replaced with 'brûlerent'.\n",
      "All instances of 'brufloient' replaced with 'brûloient'.\n",
      "All instances of 'caufe' replaced with 'cause'.\n",
      "All instances of 'caufes' replaced with 'causes'.\n",
      "All instances of 'cefte' replaced with 'ceste'.\n",
      "All instances of 'celeftes' replaced with 'celestes'.\n",
      "All instances of 'celte' replaced with 'ceste'.\n",
      "All instances of 'chan- \n",
      "gement' replaced with 'changement'.\n",
      "All instances of 'chofe' replaced with 'chose'.\n",
      "All instances of 'chofes' replaced with 'choses'.\n",
      "All instances of 'ciuil' replaced with 'civil'.\n",
      "All instances of 'confefla' replaced with 'confessa'.\n",
      "All instances of 'confefle' replaced with 'confesse'.\n",
      "All instances of 'confeflé' replaced with 'confessé'.\n",
      "All instances of 'confefler' replaced with 'confesser'.\n",
      "All instances of 'confeflerent' replaced with 'confessèrent'.\n",
      "All instances of 'confeflion' replaced with 'confession'.\n",
      "All instances of 'conveflions' replaced with 'confessions'.\n",
      "All instances of 'confefloyent' replaced with 'confessaient'.\n",
      "All instances of 'deffus' replaced with 'dessus'.\n",
      "All instances of 'deflus' replaced with 'dessus'.\n",
      "All instances of 'deſquels' replaced with 'desquels'.\n",
      "All instances of 'def- \n",
      "quels' replaced with 'desquels'.\n",
      "All instances of 'dia ble' replaced with 'diable'.\n",
      "All instances of 'dia- \n",
      "\n",
      "bles' replaced with 'diables'.\n",
      "All instances of 'dia- \n",
      "ble' replaced with 'diable'.\n",
      "All instances of 'dia- \n",
      "bolique' replaced with 'diabolique'.\n",
      "All instances of 'dia- \n",
      "boliques' replaced with 'diaboliques'.\n",
      "All instances of 'diabo- \n",
      "liques' replaced with 'diaboliques'.\n",
      "All instances of ' difant' replaced with ' disant'.\n",
      "All instances of 'difoit' replaced with 'disoit'.\n",
      "All instances of 'diuin' replaced with 'divin'.\n",
      "All instances of 'diuins' replaced with 'divins'.\n",
      "All instances of 'diuine' replaced with 'divine'.\n",
      "All instances of 'diuines' replaced with 'divines'.\n",
      "All instances of 'diuinité' replaced with 'divinité'.\n",
      "All instances of 'doibt' replaced with 'doit'.\n",
      "All instances of 'efcript' replaced with 'escript'.\n",
      "All instances of 'efcripte' replaced with 'escripte'.\n",
      "All instances of 'efcriptes' replaced with 'escriptes'.\n",
      "All instances of 'efcripture' replaced with 'escripture'.\n",
      "All instances of 'efprit' replaced with 'esprit'.\n",
      "All instances of 'efprits' replaced with 'esprits'.\n",
      "All instances of 'eftà' replaced with 'cest à'.\n",
      "All instances of 'empe- \n",
      "reur' replaced with 'empereur'.\n",
      "All instances of ' enla ' replaced with ' en la'.\n",
      "All instances of 'enlaloy' replaced with 'en la loy'.\n",
      "All instances of ' eten ' replaced with ' et en '.\n",
      "All instances of 'expe- \n",
      "rience' replaced with 'experience'.\n",
      "All instances of 'faiét' replaced with 'fait'.\n",
      "All instances of 'faifant' replaced with 'faisant'.\n",
      "All instances of 'faincte' replaced with 'saincte'.\n",
      "All instances of 'fans' replaced with 'sans'.\n",
      "All instances of 'fix' replaced with 'six'.\n",
      "All instances of 'fem- \n",
      "blable' replaced with 'semblable'.\n",
      "All instances of 'fem- \n",
      "blables' replaced with 'semblables'.\n",
      "All instances of 'feulement' replaced with 'seulement'.\n",
      "All instances of 'fouuent' replaced with 'souvent'.\n",
      "All instances of 'fupernaturelles' replaced with 'supernaturelles'.\n",
      "All instances of 'hiftoire' replaced with 'histoire'.\n",
      "All instances of 'hiftoires' replaced with 'histoires'.\n",
      "All instances of 'honteufes' replaced with 'honteuses'.\n",
      "All instances of 'hu- \n",
      "mainc' replaced with 'humaine'.\n",
      "All instances of 'hu- \n",
      "maine' replaced with 'humaine'.\n",
      "All instances of 'imagi- \n",
      "ner' replaced with 'imaginer'.\n",
      "All instances of 'l'imagi- \n",
      "nation' replaced with 'l'imagination'.\n",
      "All instances of ' laloy ' replaced with 'la loy '.\n",
      "All instances of 'lefe' replaced with 'lese'.\n",
      "All instances of 'leuiathan' replaced with 'leviathan'.\n",
      "All instances of 'liure' replaced with 'livre'.\n",
      "All instances of 'maiftre' replaced with 'maistre'.\n",
      "All instances of 'male- \n",
      "fices' replaced with 'malefices'.\n",
      "All instances of 'maling' replaced with 'malin'.\n",
      "All instances of 'malings' replaced with 'malins'.\n",
      "All instances of 'mefme' replaced with 'mesme'.\n",
      "All instances of 'mefmes' replaced with 'mesmes'.\n",
      "All instances of 'monftré' replaced with 'monstré'.\n",
      "All instances of 'mouuement' replaced with 'mouvement'.\n",
      "All instances of 'mou- \n",
      "rir' replaced with 'mourir'.\n",
      "All instances of 'moyés' replaced with 'moyens'.\n",
      "All instances of 'na- \n",
      "ture' replaced with 'nature'.\n",
      "All instances of 'natu- \n",
      "re' replaced with 'nature'.\n",
      "All instances of 'natu- \n",
      "rc' replaced with 'nature'.\n",
      "All instances of 'natu- \n",
      "relle' replaced with 'naturelle'.\n",
      "All instances of 'œuures' replaced with 'oeuvres'.\n",
      "All instances of 'ordi- \n",
      "naire' replaced with 'ordinaire'.\n",
      "All instances of 'ordi- naires' replaced with 'ordinaires'.\n",
      "All instances of 'parlemens' replaced with 'parlements'.\n",
      "All instances of 'paruenire' replaced with 'parvenir'.\n",
      "All instances of 'perfonne' replaced with 'personne'.\n",
      "All instances of 'perfonnes' replaced with 'personnes'.\n",
      "All instances of 'perfonnage' replaced with 'personnage'.\n",
      "All instances of 'perfonnages' replaced with 'personnages'.\n",
      "All instances of 'peuuent' replaced with 'peuvent'.\n",
      "All instances of 'plufieurs' replaced with 'plusieurs'.\n",
      "All instances of 'plu- \n",
      "\n",
      "fieurs' replaced with 'plusieurs'.\n",
      "All instances of 'plu- \n",
      "ficurs' replaced with 'plusieurs'.\n",
      "All instances of 'plu- \n",
      "fieurs' replaced with 'plusieurs'.\n",
      "All instances of 'prefomption' replaced with 'presomption'.\n",
      "All instances of 'prefomptions' replaced with 'presomptions'.\n",
      "All instances of 'preuue' replaced with 'preuve'.\n",
      "All instances of 'pro- \n",
      "phetie' replaced with 'prophetie'.\n",
      "All instances of 'pro- \n",
      "pheties' replaced with 'propheties'.\n",
      "All instances of 'pro- \n",
      "phetize' replaced with 'prophetize'.\n",
      "All instances of 'pro- \n",
      "phetes' replaced with 'prophetes'.\n",
      "All instances of 'puiflance' replaced with 'puissance'.\n",
      "All instances of 'qvatriesme' replaced with 'quatriesme'.\n",
      "All instances of 'raifon' replaced with 'raison'.\n",
      "All instances of 'sor- \n",
      "celleries' replaced with 'sorcelleries'.\n",
      "All instances of 'sor- \n",
      "cicr' replaced with 'sorcier'.\n",
      "All instances of 'sor- \n",
      "ciet' replaced with 'sorcier'.\n",
      "All instances of 'sor- \n",
      "ciere' replaced with 'sorciere'.\n",
      "All instances of 'sor- \n",
      "cier' replaced with 'sorcier'.\n",
      "All instances of 'trouua' replaced with 'trouva'.\n",
      "All instances of 'trouue' replaced with 'trouve'.\n",
      "All instances of 'trouué' replaced with 'trouvé'.\n",
      "All instances of 'trouuées' replaced with 'trouvées'.\n",
      "All instances of 'vns' replaced with 'uns'.\n",
      "Corrected file saved as final/Démonomanie I.1_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie I.2_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie I.3_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie I.4_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie I.5_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie I.6_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie I.7_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie II.1_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie II.2_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie II.3_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie II.4_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie II.5_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie II.6_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie II.7_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie II.8_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie III.1_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie III.2_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie III.3_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie III.4_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie III.5_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie III.6_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie IV.1_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie IV.2_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie IV.3_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie IV.4_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie IV.5_corrected.txt.\n",
      "Corrected file saved as final/Démonomanie preface Repair_corrected.txt.\n"
     ]
    }
   ],
   "source": [
    "first_file_iteration = True  # Flag to control the print statement\n",
    "\n",
    "for file in texts_list:\n",
    "    \n",
    "    # Identify the output file path for each text file\n",
    "    outputfile = f'{outputfile_path}/{Path(file).stem}_corrected.txt'\n",
    "    \n",
    "    # Open a file in \"read\" (r) mode\n",
    "    with open(file, \"r\") as text:\n",
    "        # Read in the contents of that file\n",
    "        word_correction = text.read()\n",
    "\n",
    "    word_correction = word_correction.lower()\n",
    "    \n",
    "    # Find instances of an unknown word and replace with a known word\n",
    "    for i in range(len(known_words)):\n",
    "        unknown_word = unknown_words[i]\n",
    "        known_word = known_words[i]\n",
    "        word_correction = word_correction.replace(unknown_word, known_word)\n",
    "        \n",
    "        if first_file_iteration:\n",
    "            print(f\"All instances of '{unknown_word}' replaced with '{known_word}'.\")\n",
    "    \n",
    "    # Open the file in \"write\" (w) mode\n",
    "    with open(outputfile, \"w\") as file:\n",
    "        # Add the changed word into the reopened file\n",
    "        file.write(word_correction)\n",
    "    \n",
    "    print(f\"Corrected file saved as {outputfile}.\")\n",
    "    first_file_iteration = False  # Disable the flag after the first file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bf5b492-13d8-4f0d-8eca-fb8b007a0a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spellchecked Démonomanie I.1_corrected.txt. Readability = 70.5\n",
      "Spellchecked Démonomanie I.2_corrected.txt. Readability = 71.72\n",
      "Spellchecked Démonomanie I.3_corrected.txt. Readability = 69.59\n",
      "Spellchecked Démonomanie I.4_corrected.txt. Readability = 70.89\n",
      "Spellchecked Démonomanie I.5_corrected.txt. Readability = 74.36\n",
      "Spellchecked Démonomanie I.6_corrected.txt. Readability = 68.5\n",
      "Spellchecked Démonomanie I.7_corrected.txt. Readability = 65.91\n",
      "Spellchecked Démonomanie II.1_corrected.txt. Readability = 70.0\n",
      "Spellchecked Démonomanie II.2_corrected.txt. Readability = 71.2\n",
      "Spellchecked Démonomanie II.3_corrected.txt. Readability = 68.39\n",
      "Spellchecked Démonomanie II.4_corrected.txt. Readability = 72.65\n",
      "Spellchecked Démonomanie II.5_corrected.txt. Readability = 64.44\n",
      "Spellchecked Démonomanie II.6_corrected.txt. Readability = 75.78\n",
      "Spellchecked Démonomanie II.7_corrected.txt. Readability = 66.48\n",
      "Spellchecked Démonomanie II.8_corrected.txt. Readability = 71.1\n",
      "Spellchecked Démonomanie III.1_corrected.txt. Readability = 69.76\n",
      "Spellchecked Démonomanie III.2_corrected.txt. Readability = 66.75\n",
      "Spellchecked Démonomanie III.3_corrected.txt. Readability = 67.15\n",
      "Spellchecked Démonomanie III.4_corrected.txt. Readability = 66.09\n",
      "Spellchecked Démonomanie III.5_corrected.txt. Readability = 70.98\n",
      "Spellchecked Démonomanie III.6_corrected.txt. Readability = 71.22\n",
      "Spellchecked Démonomanie IV.1_corrected.txt. Readability = 69.96\n",
      "Spellchecked Démonomanie IV.2_corrected.txt. Readability = 72.38\n",
      "Spellchecked Démonomanie IV.3_corrected.txt. Readability = 71.45\n",
      "Spellchecked Démonomanie IV.4_corrected.txt. Readability = 72.18\n",
      "Spellchecked Démonomanie IV.5_corrected.txt. Readability = 76.19\n",
      "Spellchecked Démonomanie preface Repair_corrected.txt. Readability = 76.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas-jerusalimiec/.local/lib/python3.12/site-packages/openpyxl/workbook/child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data combined into final/Démonomanie_corrected_spellcheck_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "\n",
    "# Set the locale to your desired setting (e.g., 'fr_FR.UTF-8' for French)\n",
    "locale.setlocale(locale.LC_ALL, 'fr_FR.UTF-8')\n",
    "\n",
    "# Assume spell is a previously defined spell checker instance\n",
    "# outputfile_path is the directory path to save the Excel file\n",
    "# outputpath is the directory path containing the .txt files\n",
    "\n",
    "# Create an Excel writer object\n",
    "with pd.ExcelWriter(f'{outputfile_path}/{Path.cwd().name}_corrected_spellcheck_data.xlsx', engine='openpyxl') as writer:\n",
    "\n",
    "    # Get list of files and sort them alphabetically using locale-aware sorting\n",
    "    files = [f for f in os.listdir(outputpath) if f.endswith('.txt')]\n",
    "    sorted_files = sorted(files, key=locale.strxfrm)\n",
    "\n",
    "    for filename in sorted_files:\n",
    "        file_path = os.path.join(outputpath, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "        text_data = text_data.replace(\"-\\n\", \"\")\n",
    "\n",
    "        words = wordpunct_tokenize(text_data)\n",
    "\n",
    "        misspelled = spell.unknown(words)\n",
    "\n",
    "        if len(misspelled) != 0:\n",
    "            readability = round(100 - (float(len(misspelled)) / float(len(words)) * 100), 2)\n",
    "        else:\n",
    "            readability = 100\n",
    "\n",
    "        # Count the frequency of each misspelled word\n",
    "        word_counts = Counter(misspelled)\n",
    "\n",
    "        # Sort word_counts first by 'count' descending and then by 'word' alphabetically\n",
    "        sorted_word_counts = sorted(word_counts.items(), key=lambda item: (-item[1], item[0]))\n",
    "\n",
    "        # Create a DataFrame and sort by frequency\n",
    "        misspelled_df = pd.DataFrame(sorted_word_counts, columns=['word', 'count'])\n",
    "\n",
    "        # Add readability as the first row\n",
    "        readability_header = pd.DataFrame([[\"Readability\", readability]], columns=['word', 'count'])\n",
    "        blank_rows = pd.DataFrame([[\"\", \"\"]], columns=['word', 'count'])\n",
    "        header_row = pd.DataFrame([[\"word\", \"count\"]], columns=['word', 'count'])\n",
    "        misspelled_df = pd.concat([readability_header, blank_rows, header_row, misspelled_df], ignore_index=True)\n",
    "\n",
    "        # Write the DataFrame to a new sheet in the Excel file\n",
    "        sheet_name = os.path.splitext(filename)[0]\n",
    "        misspelled_df.to_excel(writer, sheet_name=sheet_name, index=False, header=False)\n",
    "\n",
    "        print(f'Spellchecked {filename}. Readability = {readability}')\n",
    "\n",
    "print(f\"All data combined into {outputfile_path}/{Path.cwd().name}_corrected_spellcheck_data.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
