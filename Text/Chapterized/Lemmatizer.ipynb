{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "230a299f-681f-4ee2-a5df-a37c6d009975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade --force-reinstall git+https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git\n",
    "import os\n",
    "import french_lefff_lemmatizer \n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
    "lefff_data_path = os.path.join(os.path.dirname(french_lefff_lemmatizer.__file__), \"data\", \"lefff-3.4.mlex\")\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# Initialize the stemmer and lemmatizer for French\n",
    "stemmer = SnowballStemmer(language='french')\n",
    "lemmatizer = FrenchLefffLemmatizer(lefff_file_path=lefff_data_path)\n",
    "\n",
    "# Global flag to control application of custom rules without mutating the dictionary.\n",
    "# If not yet defined (e.g., when running this cell first), default to True.\n",
    "try:\n",
    "    APPLY_CUSTOM_RULES\n",
    "except NameError:\n",
    "    APPLY_CUSTOM_RULES = True\n",
    "\n",
    "# Define custom stemming/lemmatization rules sorted alphabetically with five entries per line\n",
    "CUSTOM_RULES = {\n",
    "    \"abfolu\": \"absolu\", \"abfoluë\": \"absolu\", \"accuf\": \"accus\", \"aduient\": \"advient\", \"aduis\": \"advis\",\n",
    "    \"affemble\": \"assemble\", \"aguerr\": \"guerr\", \"aifn\": \"aisn\", \"alor\": \"alors\", \"ariftot\": \"aristot\", \"aufquel\": \"ausquel\",\n",
    "    \"auantag\": \"avantag\", \"auon\": \"avon\", \"auoyent\": \"avoyent\", \"beft\": \"best\", \"bourgcoif\": \"bourgeois\",\n",
    "    \"cai\": \"cayer\", \"ceft\": \"cest\", \"chágement\": \"changemen\", \"comand\": \"command\", \"comiffion\": \"commission\",\n",
    "    \"commiffion\": \"commission\", \"commiflair\": \"commissair\", \"commiflion\": \"commission\", \"confent \": \"consent\", \"confeff\": \"confess\",\n",
    "    \"conful\": \"consul\", \"coft\": \"cost\", \"costé\": \"côté\", \"debuoir\": \"debvoir\", \"defquel\": \"desquel\",\n",
    "    \"desloix\": \"des loi\", \"deteft\": \"detest\", \"difcord\": \"discord\", \"difent\": \"disent\", \"difoit\": \"disoit\",\n",
    "    \"diuif\": \"divis\", \"diuin\": \"divin\", \"droi\": \"doit\", \"droict\": \"droit\", \"edit\": \"édict\",\n",
    "    \"édictz\": \"édict\", \"eglif\": \"eglis\", \"efcript\": \"escript\", \"efpaign\": \"espaigne\", \"efpargn\": \"espargn\",\n",
    "    \"efpec\": \"espec\", \"efprit\": \"esprit\", \"eftant\": \"estant\", \"efté\": \"esté\", \"eftim\": \"estim\",\n",
    "    \"eftoyent\": \"estoyent\", \"empefch\": \"empesch\", \"enfans\": \"enfant\", \"enfembl\": \"ensembl\", \"ennem\": \"ennemy\", \"ensan\": \"enfant\",\n",
    "    \"ensans\": \"enfant\", \"enuer\": \"enver\", \"esglis\": \"églis\", \"espic\": \"épice\", \"estar\": \"estat\",\n",
    "    \"estatz\": \"estat\", \"état\": \"estat\", \"euft\": \"eust\", \"fag\": \"sag\", \"faif\": \"sais\",\n",
    "    \"faifoit\": \"faisoit\", \"facrific\": \"sacrific\", \"fedit\": \"sedit\", \"feliqu\": \"felicit\", \"fembl\": \"sembl\", \"femblabl\": \"semblabl\",\n",
    "    \"fecond\": \"second\", \"fept\": \"sept\", \"feulg\": \"seul\", \"felon\": \"selon\", \"fent\": \"sent\",\n",
    "    \"feroit\": \"seroit\", \"fcauoir\": \"savoir\", \"fcigneur\": \"seigneur\", \"fçauoir\": \"savoir\", \"finon\": \"sinon\",\n",
    "    \"fimpl\": \"simpl\", \"fignif\": \"signif\", \"file\": \"fill\", \"fong\": \"song\", \"foyent\": \"soyent\",\n",
    "    \"fouuet\": \"souvent\", \"fucced\": \"succeed\", \"fucceffeur\": \"successeur\", \"fuft\": \"fust\", \"foudain\": \"soudain\",\n",
    "    \"gouuern\": \"gouvern\", \"gouuerneur\": \"gouverneur\", \"hebrieux\": \"hebrieu\", \"iug\": \"jug\", \"iufqu\": \"iusqu\",\n",
    "    \"iurifdiet\": \"iurisdict\", \"iurifdict\": \"iurisdict\", \"iust\": \"just\", \"iustic\": \"justic\", \"impoft\": \"impost\",\n",
    "    \"laloy\": \"la loi\", \"laiff\": \"laiss\", \"lefquel\": \"lesquel\", \"leroy\": \"le roy\", \"lesloix\": \"les loi\",\n",
    "    \"lifon\": \"lir\", \"liur\": \"livr\", \"loix\": \"loi\", \"loy\": \"loi\", \"loyx\": \"phoi\",\n",
    "    \"maicft\": \"maiest\", \"maifon\": \"maison\", \"maiftr\": \"maistr\", \"majeft\": \"majest\", \"magiftrat\": \"magistrat\",\n",
    "    \"magiftrats\": \"magistrat\", \"magiltrat\": \"magistrat\", \"mefine\": \"même\", \"mefines\": \"mêmes\", \"meím\": \"mesm\",\n",
    "    \"mesmoir\": \"memoir\", \"monftr\": \"monstr\", \"naturc\": \"natur\", \"noftr\": \"nostr\", \"obeiff\": \"obeiss\",\n",
    "    \"obeifl\": \"obeiss\", \"pai\": \"pay\", \"parlem\": \"parlement\", \"parlements\": \"parlement\", \"penf\": \"pens\",\n",
    "    \"peuuent\": \"peuvent\", \"pluficur\": \"plusieur\", \"plutfoft\": \"plustost\", \"pouuoir\": \"pouvoir\", \"pouuoit\": \"pouvoit\",\n",
    "    \"pourueu\": \"pourveu\", \"prefent\": \"present\", \"prefqu\": \"presqu\", \"preftr\": \"prestr\", \"prerogatiu\": \"prerogativ\",\n",
    "    \"prifonni\": \"prisonni\", \"prin c\": \"prince\", \"prin ces\": \"princ\", \"pris\": \"prix\", \"priuileg\": \"privileg\", \"priuileig\": \"privileg\", \"procez\": \"proc\",\n",
    "    \"puiff\": \"puiss\", \"puifle\": \"puiss\", \"puiffanc\": \"puissanc\", \"quc\": \"que\", \"queftion\": \"question\",\n",
    "    \"raifon\": \"raison\", \"reffort\": \"ressort\", \"republie\": \"republ\", \"repvbliqu\": \"republ\", \"républicque\": \"republ\",\"respublicqu\":\"republ\",\n",
    "    \"royaulm\": \"royaum\", \"royau me\": \"royaum\", \"sorcicr\": \"sorcier\", \"sorciere\": \"sorci\", \"sorcieres\": \"sorci\",\n",
    "    \"soubverain\": \"souverain\", \"souverian\": \"souverain\", \"souverianet\": \"souverainet\", \"subject\": \"sujet\", \"subjectz\": \"sujet\",\n",
    "    \"tiltr\": \"titr\", \"toufiour\": \"tousiour\", \"traitt\": \"traict\", \"trouu\": \"trouv\", \"vaffal\": \"vassal\", \"vaflal\": \"vassal\",\n",
    "    \"vertus\": \"vertu\", \"viur\": \"viv\", \"vifion\": \"vision\", \"ftatut\": \"statut\", \"blafph\": \"blasph\", \n",
    "    \"blafphem\":\"blasphem\", \"feruir\":\"servyr\", \"iuft\":\"just\",\"mefchan\":\"meschan\",\"mefchancet\":\"meschancet\", \"perpetucl\":\"perpetuel\", \"ferment\":\"serment\",\n",
    "    \"commád\":\"command\", \"commifl\":\"commiss\", \"defenf\":\"defens\",\"fuperieur\":\"superieur\",\"iurifconfult\":\"jurisconsult\",\"ofhcier\":\"officier\",\n",
    "    \"iour\":\"jour\", \"saig\":\"sag\", \"genz\":\"gen\",\"soyt\":\"soit\", \"hommaig\":\"hommag\", \"doibt\":\"doit\", \"ruyn\":\"ruin\",\n",
    "    \"feul\":\"seul\", \"fixes\":\"fixé\", \"fubftanc\":\"substanc\", \"debvoir\":\"devoir\", \"doibvent\":\"dev\",\"facon\":\"façon\",\n",
    "    \"aduint\":\"advint\", \"receuoir\":\"recevoir\", \"grad\":\"grand\", \"impoffibl\":\"impossibl\", \"prif\":\"pris\", \"iur\":\"jur\",\n",
    "    \"publicqu\":\"public\", 'hault':'haut', \"maulv\":\"mauvais\", \"maulvais\":\"mauvais\",\n",
    "    \"mauu\":\"mauvais\", \"fang\":\"sang\", \"pauur\":\"pauvr\", \"noy\":\"roy\", \"paff\":\"pass\", \"fecret\":\"secret\", \"rendr\":\"rend\",\n",
    "    \"veut\":\"veu\", \"scavoir\":\"savoir\", \"vivr\":\"viv\", \"judg\":\"jug\", \"présen\":\"present\", \"longu\":\"long\", \"majest\":\"maiest\",\n",
    "    \"nobleff\":\"nobless\", \"neceffair\":\"necessair\",\"ailles\":\"aile\", \"ailes\":\"aile\", \"verit\":\"vérit\",\n",
    "    \"teneus\":\"tenu\", \"veult\":\"veu\", \"vouloit\":\"veu\", \"jehan\":\"jean\", \"vouleu\":\"veu\", \"voul\":\"veu\", \"veulent\":\"veu\",\n",
    "    \"efleu\":\"elu\", \"esleu\":\"elu\", \"befoin\":\"besoin\", \"affeur\":\"asseur\",\"neceflair\":\"necessair\",\"ariftocrat\":\"aristocrat\",\n",
    "    \"rend\":\"rend\", \"besoing\":\"besoin\", \"courts\":\"cour\", \"prennent\":\"prend\", \"occafion\":\"occasion\", \"philofoph\":\"philosoph\",\n",
    "    \"miz\":\"mis\",\"prouinc\":\"provinc\",\"voulut\":\"veu\",\"grád\":\"grand\", \"cognoiftr\":\"cognoistr\", \"faueur\":\"faveur\",\n",
    "    \"veneu\":\"venu\",\"voulu\":\"veu\",\"daulphin\":\"dauphin\",\"veoi\":\"voit\",\"chaff\":\"chass\",\"proche\":\"proche\", \"proches\":\"proche\",\n",
    "    \"enuoi\":\"envoi\",\"puiffant\":\"puissan\", \"puiffante\":\"puissan\",\"roi\":\"roy\",\"rois\":\"roi\",\"servy\":\"servyr\",\"maulx\":\"mal\",\"uoir\":\"voir\",\"hiftoir\":\"histoir\",\n",
    "    \"expérient\":\"expérienc\", \"pos  sible\":\"possible\", \"pos ible\":\"possible\", \"beaulx\":\"beau\", \"mœur\":\"moeur\", \"perfon\":\"person\", \"fcienc\":\"scienc\", \"auant\":\"avant\",\n",
    "    \"louis\":\"louis\", \"ambaffadeur\":\"ambassadeur\", \"confent\":\"consent\",\"preuu\":\"preuv\", \"enten\":\"entend\",\n",
    "    \"justicf\":\"justice\", \"efgal\":\"esgal\", \"diuifion\":\"division\", \"efpaignol\":\"espaignol\", \"demonftr\":\"demonstr\",\n",
    "    \"oifeau\":\"oiseau\", \"conuen\":\"conven\", \"lug\": \"jug\", \"eleétion\": \"election\", \"refolu\":\"resolu\",\n",
    "    \"renuerf\":\"renvers\", \"phyficien\":\"physicien\"\n",
    "}\n",
    "\n",
    "def custom_stem_or_lemmatize(word, use_lemmatizer):\n",
    "    \"\"\"\n",
    "    Apply custom rules during stemming or lemmatizing on a single token.\n",
    "    \"\"\"\n",
    "    use_rules = globals().get('APPLY_CUSTOM_RULES', True)\n",
    "    if use_rules and word in CUSTOM_RULES:\n",
    "        return CUSTOM_RULES[word]\n",
    "    if use_lemmatizer:\n",
    "        lemmatized_word = lemmatizer.lemmatize(word)\n",
    "        return CUSTOM_RULES.get(lemmatized_word, lemmatized_word) if use_rules else lemmatized_word\n",
    "    else:\n",
    "        stemmed_word = stemmer.stem(word)\n",
    "        return CUSTOM_RULES.get(stemmed_word, stemmed_word) if use_rules else stemmed_word\n",
    "\n",
    "def return_stem(text, use_lemmatizer=False):\n",
    "    \"\"\"\n",
    "    Replace multi-token sequences first, then process the text token by token.\n",
    "\n",
    "    Multi-token replacement works by scanning the entire text for any key in CUSTOM_RULES\n",
    "    that contains a space. Since these keys represent phrases that should be merged into a single token,\n",
    "    the code replaces each occurrence with its corresponding value (which does not contain the space).\n",
    "    This way, when the text is later split into tokens (using text.split()),\n",
    "    phrases like \"royau me\" (if present in CUSTOM_RULES) will be replaced by \"royaum\" and treated as one token.\n",
    "    \"\"\"\n",
    "    # Replace multi-token sequences before tokenizing, but only if the flag is enabled.\n",
    "    if globals().get('APPLY_CUSTOM_RULES', True):\n",
    "        for phrase, replacement in CUSTOM_RULES.items():\n",
    "            if \" \" in phrase:\n",
    "                text = text.replace(phrase, replacement)\n",
    "    tokens = text.split()\n",
    "    final_processed = [custom_stem_or_lemmatize(token, use_lemmatizer) for token in tokens]\n",
    "    return ' '.join(final_processed)\n",
    "\n",
    "def process_file(file_path, use_lemmatizer=True):\n",
    "    \"\"\"\n",
    "    Process the contents of a file using custom rules.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    processed_content = return_stem(content, use_lemmatizer)\n",
    "    return processed_content\n",
    "\n",
    "def save_processed_content(original_file, processed_content, use_lemmatizer):\n",
    "    \"\"\"\n",
    "    Save processed content to a new file in a 'lemmatized' subdirectory.\n",
    "    \"\"\"\n",
    "    output_dir = os.path.join(os.getcwd(), 'lemmatized')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    suffix = '_lemmatized.txt' if use_lemmatizer else '_stemmed.txt'\n",
    "    new_file_name = os.path.splitext(os.path.basename(original_file))[0] + suffix\n",
    "    new_file_path = os.path.join(output_dir, new_file_name)\n",
    "    with open(new_file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(processed_content)\n",
    "    print(f\"Processed content saved to {new_file_path}\")\n",
    "\n",
    "def select_subdirectory():\n",
    "    \"\"\"\n",
    "    Prompt the user to select a subdirectory or use the current directory.\n",
    "    \"\"\"\n",
    "    current_directory = os.getcwd()\n",
    "    subdirectories = sorted([d for d in os.listdir(current_directory) if os.path.isdir(d)])\n",
    "    if not subdirectories:\n",
    "        print(\"No subdirectories found.\")\n",
    "        return None\n",
    "    print(\"Available subdirectories:\")\n",
    "    for i, subdir in enumerate(subdirectories):\n",
    "        print(f\"{i + 1}. {subdir}\")\n",
    "    while True:\n",
    "        user_input = input(\"Select a subdirectory number for target files (leave empty for current directory): \").strip()\n",
    "        if not user_input:\n",
    "            return current_directory\n",
    "        try:\n",
    "            choice = int(user_input) - 1\n",
    "            if choice < 0 or choice >= len(subdirectories):\n",
    "                print(\"Invalid choice. Please enter a valid number.\")\n",
    "                continue\n",
    "            return os.path.join(current_directory, subdirectories[choice])\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a number.\")\n",
    "\n",
    "def select_files():\n",
    "    \"\"\"\n",
    "    List and allow the user to select text files from a directory.\n",
    "    \"\"\"\n",
    "    directory = select_subdirectory()\n",
    "    if directory is None:\n",
    "        directory = os.getcwd()\n",
    "    txt_files = sorted([f for f in os.listdir(directory) if f.endswith('.txt')])\n",
    "    if not txt_files:\n",
    "        print(\"No text files found in the selected directory.\")\n",
    "        return []\n",
    "    print(\"Available text files:\")\n",
    "    for i, file in enumerate(txt_files):\n",
    "        print(f\"{i + 1}. {file}\")\n",
    "    selected_files = []\n",
    "    while True:\n",
    "        user_input = input(\"Select file numbers (e.g., 1,3-5 or press Enter to select all): \").strip()\n",
    "        if not user_input:\n",
    "            selected_files = txt_files\n",
    "            break\n",
    "        try:\n",
    "            parts = user_input.split(',')\n",
    "            for part in parts:\n",
    "                if '-' in part:\n",
    "                    start, end = map(int, part.split('-'))\n",
    "                    selected_files.extend(txt_files[start - 1:end])\n",
    "                else:\n",
    "                    selected_files.append(txt_files[int(part) - 1])\n",
    "            break\n",
    "        except (ValueError, IndexError):\n",
    "            print(\"Invalid input. Please enter valid numbers or ranges.\")\n",
    "    selected_files = [os.path.join(directory, file) for file in selected_files]\n",
    "    return selected_files\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to handle file processing.\n",
    "    \"\"\"\n",
    "    file_paths = select_files()\n",
    "    if not file_paths:\n",
    "        return\n",
    "    use_lemmatizer = input(\"Use FrenchLefffLemmatizer? (y/n, default is n): \").strip().lower() == 'y'\n",
    "    for file_path in file_paths:\n",
    "        processed_content = process_file(file_path, use_lemmatizer)\n",
    "        save_processed_content(file_path, processed_content, use_lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad23bc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total custom rules: 303\n",
      "abfolu\t=>\tabsolu\n",
      "abfoluë\t=>\tabsolu\n",
      "accuf\t=>\taccus\n",
      "aduient\t=>\tadvient\n",
      "aduint\t=>\tadvint\n",
      "aduis\t=>\tadvis\n",
      "affemble\t=>\tassemble\n",
      "affeur\t=>\tasseur\n",
      "aguerr\t=>\tguerr\n",
      "aifn\t=>\taisn\n",
      "ailes\t=>\taile\n",
      "ailles\t=>\taile\n",
      "alor\t=>\talors\n",
      "ambaffadeur\t=>\tambassadeur\n",
      "ariftocrat\t=>\taristocrat\n",
      "ariftot\t=>\taristot\n",
      "auant\t=>\tavant\n",
      "auantag\t=>\tavantag\n",
      "aufquel\t=>\tausquel\n",
      "auon\t=>\tavon\n",
      "auoyent\t=>\tavoyent\n",
      "beaulx\t=>\tbeau\n",
      "befoin\t=>\tbesoin\n",
      "beft\t=>\tbest\n",
      "besoing\t=>\tbesoin\n",
      "blafph\t=>\tblasph\n",
      "blafphem\t=>\tblasphem\n",
      "bourgcoif\t=>\tbourgeois\n",
      "cai\t=>\tcayer\n",
      "ceft\t=>\tcest\n",
      "chaff\t=>\tchass\n",
      "chágement\t=>\tchangemen\n",
      "coft\t=>\tcost\n",
      "cognoiftr\t=>\tcognoistr\n",
      "comand\t=>\tcommand\n",
      "comiffion\t=>\tcommission\n",
      "commiffion\t=>\tcommission\n",
      "commifl\t=>\tcommiss\n",
      "commiflair\t=>\tcommissair\n",
      "commiflion\t=>\tcommission\n",
      "commád\t=>\tcommand\n",
      "confeff\t=>\tconfess\n",
      "confent\t=>\tconsent\n",
      "confent \t=>\tconsent\n",
      "conful\t=>\tconsul\n",
      "conuen\t=>\tconven\n",
      "costé\t=>\tcôté\n",
      "courts\t=>\tcour\n",
      "daulphin\t=>\tdauphin\n",
      "debuoir\t=>\tdebvoir\n",
      "debvoir\t=>\tdevoir\n",
      "defenf\t=>\tdefens\n",
      "defquel\t=>\tdesquel\n",
      "demonftr\t=>\tdemonstr\n",
      "desloix\t=>\tdes loi\n",
      "deteft\t=>\tdetest\n",
      "difcord\t=>\tdiscord\n",
      "difent\t=>\tdisent\n",
      "difoit\t=>\tdisoit\n",
      "diuif\t=>\tdivis\n",
      "diuifion\t=>\tdivision\n",
      "diuin\t=>\tdivin\n",
      "doibt\t=>\tdoit\n",
      "doibvent\t=>\tdev\n",
      "droi\t=>\tdoit\n",
      "droict\t=>\tdroit\n",
      "edit\t=>\tédict\n",
      "efcript\t=>\tescript\n",
      "efgal\t=>\tesgal\n",
      "efleu\t=>\telu\n",
      "efpaign\t=>\tespaigne\n",
      "efpaignol\t=>\tespaignol\n",
      "efpargn\t=>\tespargn\n",
      "efpec\t=>\tespec\n",
      "efprit\t=>\tesprit\n",
      "eftant\t=>\testant\n",
      "eftim\t=>\testim\n",
      "eftoyent\t=>\testoyent\n",
      "efté\t=>\testé\n",
      "eglif\t=>\teglis\n",
      "eleétion\t=>\telection\n",
      "empefch\t=>\tempesch\n",
      "enfans\t=>\tenfant\n",
      "enfembl\t=>\tensembl\n",
      "ennem\t=>\tennemy\n",
      "ensan\t=>\tenfant\n",
      "ensans\t=>\tenfant\n",
      "enten\t=>\tentend\n",
      "enuer\t=>\tenver\n",
      "enuoi\t=>\tenvoi\n",
      "esglis\t=>\téglis\n",
      "esleu\t=>\telu\n",
      "espic\t=>\tépice\n",
      "estar\t=>\testat\n",
      "estatz\t=>\testat\n",
      "euft\t=>\teust\n",
      "expérient\t=>\texpérienc\n",
      "facon\t=>\tfaçon\n",
      "facrific\t=>\tsacrific\n",
      "fag\t=>\tsag\n",
      "faif\t=>\tsais\n",
      "faifoit\t=>\tfaisoit\n",
      "fang\t=>\tsang\n",
      "faueur\t=>\tfaveur\n",
      "fcauoir\t=>\tsavoir\n",
      "fcienc\t=>\tscienc\n",
      "fcigneur\t=>\tseigneur\n",
      "fecond\t=>\tsecond\n",
      "fecret\t=>\tsecret\n",
      "fedit\t=>\tsedit\n",
      "feliqu\t=>\tfelicit\n",
      "felon\t=>\tselon\n",
      "fembl\t=>\tsembl\n",
      "femblabl\t=>\tsemblabl\n",
      "fent\t=>\tsent\n",
      "fept\t=>\tsept\n",
      "ferment\t=>\tserment\n",
      "feroit\t=>\tseroit\n",
      "feruir\t=>\tservyr\n",
      "feul\t=>\tseul\n",
      "feulg\t=>\tseul\n",
      "fignif\t=>\tsignif\n",
      "file\t=>\tfill\n",
      "fimpl\t=>\tsimpl\n",
      "finon\t=>\tsinon\n",
      "fixes\t=>\tfixé\n",
      "fong\t=>\tsong\n",
      "foudain\t=>\tsoudain\n",
      "fouuet\t=>\tsouvent\n",
      "foyent\t=>\tsoyent\n",
      "ftatut\t=>\tstatut\n",
      "fubftanc\t=>\tsubstanc\n",
      "fucced\t=>\tsucceed\n",
      "fucceffeur\t=>\tsuccesseur\n",
      "fuft\t=>\tfust\n",
      "fuperieur\t=>\tsuperieur\n",
      "fçauoir\t=>\tsavoir\n",
      "genz\t=>\tgen\n",
      "gouuern\t=>\tgouvern\n",
      "gouuerneur\t=>\tgouverneur\n",
      "grad\t=>\tgrand\n",
      "grád\t=>\tgrand\n",
      "hault\t=>\thaut\n",
      "hebrieux\t=>\thebrieu\n",
      "hiftoir\t=>\thistoir\n",
      "hommaig\t=>\thommag\n",
      "impoffibl\t=>\timpossibl\n",
      "impoft\t=>\timpost\n",
      "iour\t=>\tjour\n",
      "iufqu\t=>\tiusqu\n",
      "iuft\t=>\tjust\n",
      "iug\t=>\tjug\n",
      "iur\t=>\tjur\n",
      "iurifconfult\t=>\tjurisconsult\n",
      "iurifdict\t=>\tiurisdict\n",
      "iurifdiet\t=>\tiurisdict\n",
      "iust\t=>\tjust\n",
      "iustic\t=>\tjustic\n",
      "jehan\t=>\tjean\n",
      "judg\t=>\tjug\n",
      "justicf\t=>\tjustice\n",
      "laiff\t=>\tlaiss\n",
      "laloy\t=>\tla loi\n",
      "lefquel\t=>\tlesquel\n",
      "leroy\t=>\tle roy\n",
      "lesloix\t=>\tles loi\n",
      "lifon\t=>\tlir\n",
      "liur\t=>\tlivr\n",
      "loix\t=>\tloi\n",
      "longu\t=>\tlong\n",
      "louis\t=>\tlouis\n",
      "loy\t=>\tloi\n",
      "loyx\t=>\tphoi\n",
      "lug\t=>\tjug\n",
      "magiftrat\t=>\tmagistrat\n",
      "magiftrats\t=>\tmagistrat\n",
      "magiltrat\t=>\tmagistrat\n",
      "maicft\t=>\tmaiest\n",
      "maifon\t=>\tmaison\n",
      "maiftr\t=>\tmaistr\n",
      "majeft\t=>\tmajest\n",
      "majest\t=>\tmaiest\n",
      "maulv\t=>\tmauvais\n",
      "maulvais\t=>\tmauvais\n",
      "maulx\t=>\tmal\n",
      "mauu\t=>\tmauvais\n",
      "mefchan\t=>\tmeschan\n",
      "mefchancet\t=>\tmeschancet\n",
      "mefine\t=>\tmême\n",
      "mefines\t=>\tmêmes\n",
      "mesmoir\t=>\tmemoir\n",
      "meím\t=>\tmesm\n",
      "miz\t=>\tmis\n",
      "monftr\t=>\tmonstr\n",
      "mœur\t=>\tmoeur\n",
      "naturc\t=>\tnatur\n",
      "neceffair\t=>\tnecessair\n",
      "neceflair\t=>\tnecessair\n",
      "nobleff\t=>\tnobless\n",
      "noftr\t=>\tnostr\n",
      "noy\t=>\troy\n",
      "obeiff\t=>\tobeiss\n",
      "obeifl\t=>\tobeiss\n",
      "occafion\t=>\toccasion\n",
      "ofhcier\t=>\tofficier\n",
      "oifeau\t=>\toiseau\n",
      "paff\t=>\tpass\n",
      "pai\t=>\tpay\n",
      "parlem\t=>\tparlement\n",
      "parlements\t=>\tparlement\n",
      "pauur\t=>\tpauvr\n",
      "penf\t=>\tpens\n",
      "perfon\t=>\tperson\n",
      "perpetucl\t=>\tperpetuel\n",
      "peuuent\t=>\tpeuvent\n",
      "philofoph\t=>\tphilosoph\n",
      "phyficien\t=>\tphysicien\n",
      "pluficur\t=>\tplusieur\n",
      "plutfoft\t=>\tplustost\n",
      "pos  sible\t=>\tpossible\n",
      "pos ible\t=>\tpossible\n",
      "pourueu\t=>\tpourveu\n",
      "pouuoir\t=>\tpouvoir\n",
      "pouuoit\t=>\tpouvoit\n",
      "prefent\t=>\tpresent\n",
      "prefqu\t=>\tpresqu\n",
      "preftr\t=>\tprestr\n",
      "prennent\t=>\tprend\n",
      "prerogatiu\t=>\tprerogativ\n",
      "preuu\t=>\tpreuv\n",
      "prif\t=>\tpris\n",
      "prifonni\t=>\tprisonni\n",
      "prin c\t=>\tprince\n",
      "prin ces\t=>\tprinc\n",
      "pris\t=>\tprix\n",
      "priuileg\t=>\tprivileg\n",
      "priuileig\t=>\tprivileg\n",
      "procez\t=>\tproc\n",
      "proche\t=>\tproche\n",
      "proches\t=>\tproche\n",
      "prouinc\t=>\tprovinc\n",
      "présen\t=>\tpresent\n",
      "publicqu\t=>\tpublic\n",
      "puiff\t=>\tpuiss\n",
      "puiffanc\t=>\tpuissanc\n",
      "puiffant\t=>\tpuissan\n",
      "puiffante\t=>\tpuissan\n",
      "puifle\t=>\tpuiss\n",
      "quc\t=>\tque\n",
      "queftion\t=>\tquestion\n",
      "raifon\t=>\traison\n",
      "receuoir\t=>\trecevoir\n",
      "reffort\t=>\tressort\n",
      "refolu\t=>\tresolu\n",
      "rend\t=>\trend\n",
      "rendr\t=>\trend\n",
      "renuerf\t=>\trenvers\n",
      "republie\t=>\trepubl\n",
      "repvbliqu\t=>\trepubl\n",
      "respublicqu\t=>\trepubl\n",
      "roi\t=>\troy\n",
      "rois\t=>\troi\n",
      "royau me\t=>\troyaum\n",
      "royaulm\t=>\troyaum\n",
      "ruyn\t=>\truin\n",
      "républicque\t=>\trepubl\n",
      "saig\t=>\tsag\n",
      "scavoir\t=>\tsavoir\n",
      "servy\t=>\tservyr\n",
      "sorcicr\t=>\tsorcier\n",
      "sorciere\t=>\tsorci\n",
      "sorcieres\t=>\tsorci\n",
      "soubverain\t=>\tsouverain\n",
      "souverian\t=>\tsouverain\n",
      "souverianet\t=>\tsouverainet\n",
      "soyt\t=>\tsoit\n",
      "subject\t=>\tsujet\n",
      "subjectz\t=>\tsujet\n",
      "teneus\t=>\ttenu\n",
      "tiltr\t=>\ttitr\n",
      "toufiour\t=>\ttousiour\n",
      "traitt\t=>\ttraict\n",
      "trouu\t=>\ttrouv\n",
      "uoir\t=>\tvoir\n",
      "vaffal\t=>\tvassal\n",
      "vaflal\t=>\tvassal\n",
      "veneu\t=>\tvenu\n",
      "veoi\t=>\tvoit\n",
      "verit\t=>\tvérit\n",
      "vertus\t=>\tvertu\n",
      "veulent\t=>\tveu\n",
      "veult\t=>\tveu\n",
      "veut\t=>\tveu\n",
      "vifion\t=>\tvision\n",
      "viur\t=>\tviv\n",
      "vivr\t=>\tviv\n",
      "voul\t=>\tveu\n",
      "vouleu\t=>\tveu\n",
      "vouloit\t=>\tveu\n",
      "voulu\t=>\tveu\n",
      "voulut\t=>\tveu\n",
      "édictz\t=>\tédict\n",
      "état\t=>\testat\n"
     ]
    }
   ],
   "source": [
    "# Display all custom rule entries sorted alphabetically by key\n",
    "# This does not modify CUSTOM_RULES; it just presents a sorted view.\n",
    "try:\n",
    "    sorted_custom_rules_items = sorted(CUSTOM_RULES.items(), key=lambda kv: kv[0])\n",
    "    print(f\"Total custom rules: {len(sorted_custom_rules_items)}\")\n",
    "    for k, v in sorted_custom_rules_items:\n",
    "        print(f\"{k}\\t=>\\t{v}\")\n",
    "except NameError:\n",
    "    print(\"CUSTOM_RULES is not defined yet. Run the cell defining it first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2fa809b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n\u001b[32m      6\u001b[39m     CUSTOM_RULES = {}\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m resp = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mApply custom lemmatization rules? (Y/n, press Enter for Yes): \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.strip().lower()\n\u001b[32m      9\u001b[39m APPLY_CUSTOM_RULES = (resp \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33myes\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m APPLY_CUSTOM_RULES:\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Disable by using a flag so downstream lookups become no-ops (without modifying the dictionary)\u001b[39;00m\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# CUSTOM_RULES.clear()  # <-- no longer needed; preserved for reference but intentionally not executed\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py:1282\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1280\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1282\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1283\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1284\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1285\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1287\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py:1325\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1323\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1324\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1327\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Toggle whether to apply custom lemmatization rules (default: yes)\n",
    "try:\n",
    "    # Ensure CUSTOM_RULES exists even if cells run out of order\n",
    "    CUSTOM_RULES\n",
    "except NameError:\n",
    "    CUSTOM_RULES = {}\n",
    "    \n",
    "resp = input(\"Apply custom lemmatization rules? (Y/n, press Enter for Yes): \").strip().lower()\n",
    "APPLY_CUSTOM_RULES = (resp in (\"\", \"y\", \"yes\"))\n",
    "if not APPLY_CUSTOM_RULES:\n",
    "    # Disable by using a flag so downstream lookups become no-ops (without modifying the dictionary)\n",
    "    # CUSTOM_RULES.clear()  # <-- no longer needed; preserved for reference but intentionally not executed\n",
    "    print(\"Custom rules disabled for this run.\")\n",
    "else:\n",
    "    print(\"Custom rules enabled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac3dc68-3960-4bed-abbc-f3ba61d602f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available subdirectories:\n",
      "1. .ipynb_checkpoints\n",
      "2. Démonomanie\n",
      "3. République\n",
      "4. Théatre\n",
      "5. lemmatized\n",
      "Available text files:\n",
      "1. Discours des raisons_corrected.txt\n",
      "2. Démonomanie III_corrected.txt\n",
      "3. Démonomanie II_corrected.txt\n",
      "4. Démonomanie IV_corrected.txt\n",
      "5. Démonomanie I_corrected.txt\n",
      "6. Démonomanie preface Repair_corrected.txt\n",
      "7. Harangue - Fontainebleau_corrected.txt\n",
      "8. Harangue - Orléans 2_corrected.txt\n",
      "9. Harangue - Orléans_corrected.txt\n",
      "10. Harangue - Poissy_corrected.txt\n",
      "11. Harangue - Rouen_corrected.txt\n",
      "12. Harangue - Saint Germain_corrected.txt\n",
      "13. Harangue - lit de justice_corrected.txt\n",
      "14. Harangue - ouverture de parlement_corrected.txt\n",
      "15. Harangue - parlement 2_corrected.txt\n",
      "16. Harangue - parlement 3_corrected.txt\n",
      "17. Harangue - parlement_corrected.txt\n",
      "18. Harangue - religion_corrected.txt\n",
      "19. Harangue - septembre_corrected.txt\n",
      "20. La réponse_corrected.txt\n",
      "21. Le paradoxe_corrected.txt\n",
      "22. Lettre_corrected.txt\n",
      "23. Lit de justice_corrected.txt\n",
      "24. Memoire - Namur_corrected.txt\n",
      "25. Memoire - le but_corrected.txt\n",
      "26. Memoire au roi_corrected.txt\n",
      "27. Memoires d'État Refuge_corrected.txt\n",
      "28. Memoires d'état_corrected.txt\n",
      "29. Recueil_corrected.txt\n",
      "30. Remonstrances - Royaume_corrected.txt\n",
      "31. Remonstrances - parlement_corrected.txt\n",
      "32. République III_corrected.txt\n",
      "33. République II_corrected.txt\n",
      "34. République IV_corrected.txt\n",
      "35. République I_corrected.txt\n",
      "36. République Preface_corrected.txt\n",
      "37. République VI_corrected.txt\n",
      "38. République V_corrected.txt\n",
      "39. Théatre III_corrected.txt\n",
      "40. Théatre II_corrected.txt\n",
      "41. Théatre IV_corrected.txt\n",
      "42. Théatre I_corrected.txt\n",
      "43. Théatre V_corrected.txt\n",
      "44. Théatre summary_corrected.txt\n",
      "45. Traite Justice VII_corrected.txt\n",
      "46. Traite Justice VI_corrected.txt\n",
      "47. Traite Justice V_corrected.txt\n",
      "48. Traité Justice III_corrected.txt\n",
      "49. Traité Justice II_corrected.txt\n",
      "50. Traité Justice IV_corrected.txt\n",
      "51. Traité Justice I_corrected.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Discours des raisons_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Démonomanie III_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Démonomanie II_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Démonomanie IV_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Démonomanie I_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Démonomanie preface Repair_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Harangue - Fontainebleau_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Harangue - Orléans 2_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Harangue - Orléans_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Harangue - Poissy_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Harangue - Rouen_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Harangue - Saint Germain_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Harangue - lit de justice_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Harangue - ouverture de parlement_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Harangue - parlement 2_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Harangue - parlement 3_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Harangue - parlement_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Harangue - religion_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Harangue - septembre_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/La réponse_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Le paradoxe_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Lettre_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Lit de justice_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Memoire - Namur_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Memoire - le but_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Memoire au roi_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Memoires d'État Refuge_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Memoires d'état_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Recueil_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Remonstrances - Royaume_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Remonstrances - parlement_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/République III_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/République II_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/République IV_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/République I_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/République Preface_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/République VI_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/République V_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Théatre III_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Théatre II_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Théatre IV_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Théatre I_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Théatre V_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Théatre summary_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Traite Justice VII_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Traite Justice VI_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Traite Justice V_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Traité Justice III_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Traité Justice II_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Traité Justice IV_corrected_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Chapterized/lemmatized/Traité Justice I_corrected_stemmed.txt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
