{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "230a299f-681f-4ee2-a5df-a37c6d009975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade --force-reinstall git+https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git\n",
    "import os\n",
    "import french_lefff_lemmatizer \n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
    "lefff_data_path = os.path.join(os.path.dirname(french_lefff_lemmatizer.__file__), \"data\", \"lefff-3.4.mlex\")\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# Initialize the stemmer and lemmatizer for French\n",
    "stemmer = SnowballStemmer(language='french')\n",
    "lemmatizer = FrenchLefffLemmatizer(lefff_file_path=lefff_data_path)\n",
    "\n",
    "# Define custom stemming/lemmatization rules sorted alphabetically with five entries per line\n",
    "CUSTOM_RULES = {\n",
    "    \"abfolu\": \"absolu\", \"abfoluë\": \"absolu\", \"accuf\": \"accus\", \"aduient\": \"advient\", \"aduis\": \"advis\",\n",
    "    \"affemble\": \"assemble\", \"aguerr\": \"guerr\", \"aifn\": \"aisn\", \"alor\": \"alors\", \"ariftot\": \"aristot\", \"aufquel\": \"ausquel\",\n",
    "    \"auantag\": \"avantag\", \"auon\": \"avon\", \"auoyent\": \"avoyent\", \"beft\": \"best\", \"bourgcoif\": \"bourgeois\",\n",
    "    \"cai\": \"cayer\", \"ceft\": \"cest\", \"chágement\": \"changemen\", \"comand\": \"command\", \"comiffion\": \"commission\",\n",
    "    \"commiffion\": \"commission\", \"commiflair\": \"commissair\", \"commiflion\": \"commission\", \"confent \": \"consent\", \"confeff\": \"confess\",\n",
    "    \"conful\": \"consul\", \"coft\": \"cost\", \"costé\": \"côté\", \"debuoir\": \"debvoir\", \"defquel\": \"desquel\",\n",
    "    \"desloix\": \"des loi\", \"deteft\": \"detest\", \"difcord\": \"discord\", \"difent\": \"disent\", \"difoit\": \"disoit\",\n",
    "    \"diuif\": \"divis\", \"diuin\": \"divin\", \"droi\": \"doit\", \"droict\": \"droit\", \"edit\": \"édict\",\n",
    "    \"édictz\": \"édict\", \"eglif\": \"eglis\", \"efcript\": \"escript\", \"efpaign\": \"espaigne\", \"efpargn\": \"espargn\",\n",
    "    \"efpec\": \"espec\", \"efprit\": \"esprit\", \"eftant\": \"estant\", \"efté\": \"esté\", \"eftim\": \"estim\",\n",
    "    \"eftoyent\": \"estoyent\", \"empefch\": \"empesch\", \"enfans\": \"enfant\", \"enfembl\": \"ensembl\", \"ennem\": \"ennemy\", \"ensan\": \"enfant\",\n",
    "    \"ensans\": \"enfant\", \"enuer\": \"enver\", \"esglis\": \"églis\", \"espic\": \"épice\", \"estar\": \"estat\",\n",
    "    \"estatz\": \"estat\", \"état\": \"estat\", \"euft\": \"eust\", \"fag\": \"sag\", \"faif\": \"sais\",\n",
    "    \"faifoit\": \"faisoit\", \"facrific\": \"sacrific\", \"fedit\": \"sedit\", \"feliqu\": \"felicit\", \"fembl\": \"sembl\", \"femblabl\": \"semblabl\",\n",
    "    \"fecond\": \"second\", \"fept\": \"sept\", \"feulg\": \"seul\", \"felon\": \"selon\", \"fent\": \"sent\",\n",
    "    \"feroit\": \"seroit\", \"fcauoir\": \"savoir\", \"fcigneur\": \"seigneur\", \"fçauoir\": \"savoir\", \"finon\": \"sinon\",\n",
    "    \"fimpl\": \"simpl\", \"fignif\": \"signif\", \"file\": \"fill\", \"fong\": \"song\", \"foyent\": \"soyent\",\n",
    "    \"fouuet\": \"souvent\", \"fucced\": \"succeed\", \"fucceffeur\": \"successeur\", \"fuft\": \"fust\", \"foudain\": \"soudain\",\n",
    "    \"gouuern\": \"gouvern\", \"gouuerneur\": \"gouverneur\", \"hebrieux\": \"hebrieu\", \"iug\": \"jug\", \"iufqu\": \"iusqu\",\n",
    "    \"iurifdiet\": \"iurisdict\", \"iurifdict\": \"iurisdict\", \"iust\": \"just\", \"iustic\": \"justic\", \"impoft\": \"impost\",\n",
    "    \"laloy\": \"la loi\", \"laiff\": \"laiss\", \"lefquel\": \"lesquel\", \"leroy\": \"le roy\", \"lesloix\": \"les loi\",\n",
    "    \"lifon\": \"lir\", \"liur\": \"livr\", \"loix\": \"loi\", \"loy\": \"loi\", \"loyx\": \"loi\",\n",
    "    \"maicft\": \"maiest\", \"maifon\": \"maison\", \"maiftr\": \"maistr\", \"majeft\": \"majest\", \"magiftrat\": \"magistrat\",\n",
    "    \"magiftrats\": \"magistrat\", \"magiltrat\": \"magistrat\", \"mefine\": \"même\", \"mefines\": \"mêmes\", \"meím\": \"mesm\",\n",
    "    \"mesmoir\": \"memoir\", \"monftr\": \"monstr\", \"naturc\": \"natur\", \"noftr\": \"nostr\", \"obeiff\": \"obeiss\",\n",
    "    \"obeifl\": \"obeiss\", \"pai\": \"pay\", \"parlem\": \"parlement\", \"parlements\": \"parlement\", \"penf\": \"pens\",\n",
    "    \"peuuent\": \"peuvent\", \"pluficur\": \"plusieur\", \"plutfoft\": \"plustost\", \"pouuoir\": \"pouvoir\", \"pouuoit\": \"pouvoit\",\n",
    "    \"pourueu\": \"pourveu\", \"prefent\": \"present\", \"prefqu\": \"presqu\", \"preftr\": \"prestr\", \"prerogatiu\": \"prerogativ\",\n",
    "    \"prifonni\": \"prisonni\", \"prin c\": \"prince\", \"prin ces\": \"princ\", \"pris\": \"prix\", \"priuileg\": \"privileg\", \"priuileig\": \"privileg\", \"procez\": \"procès\",\n",
    "    \"puiff\": \"puiss\", \"puifle\": \"puiss\", \"puiffanc\": \"puissanc\", \"quc\": \"que\", \"queftion\": \"question\",\n",
    "    \"raifon\": \"raison\", \"reffort\": \"ressort\", \"republie\": \"republ\", \"repvbliqu\": \"republ\", \"républicque\": \"republ\",\"respublicqu\":\"republ\",\n",
    "    \"royaulm\": \"royaum\", \"royau me\": \"royaum\", \"sorcicr\": \"sorcier\", \"sorciere\": \"sorci\", \"sorcieres\": \"sorci\",\n",
    "    \"soubverain\": \"souverain\", \"souverian\": \"souverain\", \"souverianet\": \"souverainet\", \"subject\": \"sujet\", \"subjectz\": \"sujet\",\n",
    "    \"tiltr\": \"titr\", \"toufiour\": \"tousiour\", \"traitt\": \"traict\", \"trouu\": \"trouv\", \"vaffal\": \"vassal\", \"vaflal\": \"vassal\",\n",
    "    \"vertus\": \"vertu\", \"viur\": \"viv\", \"vifion\": \"vision\", \"ftatut\": \"statut\", \"blafph\": \"blasph\", \n",
    "    \"blafphem\":\"blasphem\", \"feruir\":\"servir\", \"iuft\":\"just\",\"mefchan\":\"meschan\",\"mefchancet\":\"meschancet\", \"perpetucl\":\"perpetuel\", \"ferment\":\"serment\",\n",
    "    \"commád\":\"command\", \"commifl\":\"commiss\", \"defenf\":\"defens\",\"fuperieur\":\"superieur\",\"iurifconfult\":\"jurisconsult\",\"ofhcier\":\"officier\",\n",
    "    \"iour\":\"jour\", \"saig\":\"sag\", \"genz\":\"gen\",\"soyt\":\"soit\", \"hommaig\":\"hommag\", \"doibt\":\"doit\", \"ruyn\":\"ruin\",\n",
    "    \"feul\":\"seul\", \"fixes\":\"fixé\", \"fubftanc\":\"substanc\", \"debvoir\":\"devoir\", \"doibvent\":\"dev\",\"facon\":\"façon\",\n",
    "    \"aduint\":\"advint\", \"receuoir\":\"recevoir\", \"grad\":\"grand\", \"impoffibl\":\"impossibl\", \"prif\":\"pris\", \"iur\":\"jur\",\n",
    "    \"publicqu\":\"public\", 'hault':'haut', \"maulv\":\"mauvais\", \"maulvais\":\"mauvais\",\n",
    "    \"mauu\":\"mauvais\", \"fang\":\"sang\", \"pauur\":\"pauvr\", \"noy\":\"roy\", \"paff\":\"pass\", \"fecret\":\"secret\", \"rendr\":\"rend\",\n",
    "    \"veut\":\"veu\", \"scavoir\":\"savoir\", \"vivr\":\"viv\", \"judg\":\"jug\", \"présen\":\"present\", \"longu\":\"long\", \"majest\":\"maiest\",\n",
    "    \"nobleff\":\"nobless\", \"neceffair\":\"necessair\",\"ailles\":\"aile\", \"ailes\":\"aile\", \"verit\":\"vérit\",\n",
    "    \"teneus\":\"tenu\", \"veult\":\"veu\", \"vouloit\":\"veu\", \"jehan\":\"jean\", \"vouleu\":\"veu\", \"voul\":\"veu\", \"veulent\":\"veu\",\n",
    "    \"efleu\":\"elu\", \"esleu\":\"elu\", \"befoin\":\"besoin\", \"affeur\":\"asseur\",\"neceflair\":\"necessair\",\"ariftocrat\":\"aristocrat\",\n",
    "    \"rend\":\"rend\", \"besoing\":\"besoin\", \"courts\":\"cour\"\n",
    "}\n",
    "\n",
    "def custom_stem_or_lemmatize(word, use_lemmatizer):\n",
    "    \"\"\"\n",
    "    Apply custom rules during stemming or lemmatizing on a single token.\n",
    "    \"\"\"\n",
    "    if word in CUSTOM_RULES:\n",
    "        return CUSTOM_RULES[word]\n",
    "    if use_lemmatizer:\n",
    "        lemmatized_word = lemmatizer.lemmatize(word)\n",
    "        return CUSTOM_RULES.get(lemmatized_word, lemmatized_word)\n",
    "    else:\n",
    "        stemmed_word = stemmer.stem(word)\n",
    "        return CUSTOM_RULES.get(stemmed_word, stemmed_word)\n",
    "\n",
    "def return_stem(text, use_lemmatizer=False):\n",
    "    \"\"\"\n",
    "    Replace multi-token sequences first, then process the text token by token.\n",
    "\n",
    "    Multi-token replacement works by scanning the entire text for any key in CUSTOM_RULES\n",
    "    that contains a space. Since these keys represent phrases that should be merged into a single token,\n",
    "    the code replaces each occurrence with its corresponding value (which does not contain the space).\n",
    "    This way, when the text is later split into tokens (using text.split()),\n",
    "    phrases like \"royau me\" (if present in CUSTOM_RULES) will be replaced by \"royaum\" and treated as one token.\n",
    "    \"\"\"\n",
    "    # Replace multi-token sequences before tokenizing.\n",
    "    for phrase, replacement in CUSTOM_RULES.items():\n",
    "        if \" \" in phrase:\n",
    "            text = text.replace(phrase, replacement)\n",
    "    tokens = text.split()\n",
    "    final_processed = [custom_stem_or_lemmatize(token, use_lemmatizer) for token in tokens]\n",
    "    return ' '.join(final_processed)\n",
    "\n",
    "def process_file(file_path, use_lemmatizer=True):\n",
    "    \"\"\"\n",
    "    Process the contents of a file using custom rules.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    processed_content = return_stem(content, use_lemmatizer)\n",
    "    return processed_content\n",
    "\n",
    "def save_processed_content(original_file, processed_content, use_lemmatizer):\n",
    "    \"\"\"\n",
    "    Save processed content to a new file in a 'lemmatized' subdirectory.\n",
    "    \"\"\"\n",
    "    output_dir = os.path.join(os.getcwd(), 'lemmatized')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    suffix = '_lemmatized.txt' if use_lemmatizer else '_stemmed.txt'\n",
    "    new_file_name = os.path.splitext(os.path.basename(original_file))[0] + suffix\n",
    "    new_file_path = os.path.join(output_dir, new_file_name)\n",
    "    with open(new_file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(processed_content)\n",
    "    print(f\"Processed content saved to {new_file_path}\")\n",
    "\n",
    "def select_subdirectory():\n",
    "    \"\"\"\n",
    "    Prompt the user to select a subdirectory or use the current directory.\n",
    "    \"\"\"\n",
    "    current_directory = os.getcwd()\n",
    "    subdirectories = sorted([d for d in os.listdir(current_directory) if os.path.isdir(d)])\n",
    "    if not subdirectories:\n",
    "        print(\"No subdirectories found.\")\n",
    "        return None\n",
    "    print(\"Available subdirectories:\")\n",
    "    for i, subdir in enumerate(subdirectories):\n",
    "        print(f\"{i + 1}. {subdir}\")\n",
    "    while True:\n",
    "        user_input = input(\"Select a subdirectory number for target files (leave empty for current directory): \").strip()\n",
    "        if not user_input:\n",
    "            return current_directory\n",
    "        try:\n",
    "            choice = int(user_input) - 1\n",
    "            if choice < 0 or choice >= len(subdirectories):\n",
    "                print(\"Invalid choice. Please enter a valid number.\")\n",
    "                continue\n",
    "            return os.path.join(current_directory, subdirectories[choice])\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a number.\")\n",
    "\n",
    "def select_files():\n",
    "    \"\"\"\n",
    "    List and allow the user to select text files from a directory.\n",
    "    \"\"\"\n",
    "    directory = select_subdirectory()\n",
    "    if directory is None:\n",
    "        directory = os.getcwd()\n",
    "    txt_files = sorted([f for f in os.listdir(directory) if f.endswith('.txt')])\n",
    "    if not txt_files:\n",
    "        print(\"No text files found in the selected directory.\")\n",
    "        return []\n",
    "    print(\"Available text files:\")\n",
    "    for i, file in enumerate(txt_files):\n",
    "        print(f\"{i + 1}. {file}\")\n",
    "    selected_files = []\n",
    "    while True:\n",
    "        user_input = input(\"Select file numbers (e.g., 1,3-5 or press Enter to select all): \").strip()\n",
    "        if not user_input:\n",
    "            selected_files = txt_files\n",
    "            break\n",
    "        try:\n",
    "            parts = user_input.split(',')\n",
    "            for part in parts:\n",
    "                if '-' in part:\n",
    "                    start, end = map(int, part.split('-'))\n",
    "                    selected_files.extend(txt_files[start - 1:end])\n",
    "                else:\n",
    "                    selected_files.append(txt_files[int(part) - 1])\n",
    "            break\n",
    "        except (ValueError, IndexError):\n",
    "            print(\"Invalid input. Please enter valid numbers or ranges.\")\n",
    "    selected_files = [os.path.join(directory, file) for file in selected_files]\n",
    "    return selected_files\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to handle file processing.\n",
    "    \"\"\"\n",
    "    file_paths = select_files()\n",
    "    if not file_paths:\n",
    "        return\n",
    "    use_lemmatizer = input(\"Use FrenchLefffLemmatizer? (y/n, default is n): \").strip().lower() == 'y'\n",
    "    for file_path in file_paths:\n",
    "        processed_content = process_file(file_path, use_lemmatizer)\n",
    "        save_processed_content(file_path, processed_content, use_lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ac3dc68-3960-4bed-abbc-f3ba61d602f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available subdirectories:\n",
      "1. .ipynb_checkpoints\n",
      "2. lemmatized\n",
      "Available text files:\n",
      "1. Bodin.txt\n",
      "2. L'Hospital.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Corpora/Concatenated/lemmatized/Bodin_stemmed.txt\n",
      "Processed content saved to /workspaces/Jerusalimiec-Dissertation/Text/Corpora/Concatenated/lemmatized/L'Hospital_stemmed.txt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
