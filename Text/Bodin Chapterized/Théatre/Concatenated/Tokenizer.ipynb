{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54bf6974-56fe-490b-9b06-61bd6634a710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fr_FR.UTF-8'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize,wordpunct_tokenize\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures, TrigramCollocationFinder, TrigramAssocMeasures\n",
    "\n",
    "import locale\n",
    "# Set the locale to your desired setting (e.g., 'fr_FR.UTF-8' for French)\n",
    "locale.setlocale(locale.LC_ALL, 'fr_FR.UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d91501f-4ea8-4a51-80e4-5b2c3d87f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/lucas-jerusalimiec/Documents/OCR Text/Notebooks\")\n",
    "from tokenizer_func  import (wordcleaner, write_words_to_file, dictionary_to_file, convert_tuple_bigrams,\n",
    "convert_tuple_trigrams)\n",
    "\n",
    "from extra_token_func import print_first_n_items, remove_keys_from_nested_dict\n",
    "\n",
    "from additional_token_func import convert_strings_to_counts\n",
    "\n",
    "from dict_write import write_dict_to_files_with_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d557ac9-168b-4b35-ac00-28687dd85cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text files in the spellchecked directory: ['final/Théatre I_corrected.txt', 'final/Théatre II_corrected.txt', 'final/Théatre III_corrected.txt', 'final/Théatre IV_corrected.txt', 'final/Théatre summary_corrected.txt', 'final/Théatre V_corrected.txt']\n"
     ]
    }
   ],
   "source": [
    "text_loc = Path(\"./final\")\n",
    "text_files = sorted(glob.glob(f\"{text_loc}/*.txt\"), key=locale.strxfrm)\n",
    "output_folder = './tokenized/'\n",
    "tokenized_folder = Path(output_folder)\n",
    "tokenized_folder.mkdir(exist_ok=True)\n",
    "\n",
    "output_unigram = f'{output_folder}unigram_counts'\n",
    "unigram_folder = Path(output_unigram)\n",
    "unigram_folder.mkdir(exist_ok=True)\n",
    "\n",
    "output_bigram = f'{output_folder}bigram_counts'\n",
    "bigram_folder = Path(output_bigram)\n",
    "bigram_folder.mkdir(exist_ok=True)\n",
    "\n",
    "output_trigram = f'{output_folder}trigram_counts'\n",
    "trigram_folder = Path(output_trigram)\n",
    "trigram_folder.mkdir(exist_ok=True)\n",
    "\n",
    "output_collocation = f'{output_folder}collocation_counts'\n",
    "collocation_folder = Path(output_collocation)\n",
    "collocation_folder.mkdir(exist_ok=True)\n",
    "\n",
    "output_trigram_collocation = f'{output_folder}trigram_collocation_counts'\n",
    "trigram_collocation_folder = Path(output_trigram_collocation)\n",
    "trigram_collocation_folder.mkdir(exist_ok=True)\n",
    "\n",
    "output_underscore = f'{output_folder}underscore_bigrams'\n",
    "underscore_folder = Path(output_underscore)\n",
    "underscore_folder.mkdir(exist_ok=True)\n",
    "\n",
    "output_trigram_underscore = f'{output_folder}underscore_trigrams'\n",
    "trigram_underscore_folder = Path(output_trigram_underscore)\n",
    "trigram_underscore_folder.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Text files in the spellchecked directory:\", text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa6226b-1236-4eb7-b4b3-7b8c79c0a6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v', 'vn', 'vne', 'vnes', 'w', 'x', 'ya', 'encores', 'quele', 'queles']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open stopwords CSV file and list the contents\n",
    "with open('./stop_words.csv', 'r') as f:\n",
    "    stopwords = f.read().strip().split(\",\")\n",
    "stopwords[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b085009a-d824-4bf2-aedc-fd567abf2dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw texts: ['Théatre I_corrected', 'Théatre II_corrected', 'Théatre III_corrected', 'Théatre IV_corrected', 'Théatre summary_corrected', 'Théatre V_corrected']\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = {}\n",
    "for txt in text_files:\n",
    "    with open(txt, 'r') as f:\n",
    "        content = f.read()\n",
    "        file_name = txt.split('\\\\')[-1]\n",
    "        #key = file_name.split('.')[0]\n",
    "        key = os.path.splitext(os.path.basename(file_name))[0]\n",
    "        tokenized_texts[key] = content\n",
    "print(\"Raw texts:\", list(tokenized_texts.keys()))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f8cc71e-5849-4195-8b5c-585cc06d2916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved content for 'Théatre I_corrected' to ./tokenized/Théatre I_corrected.txt\n",
      "Saved content for 'Théatre II_corrected' to ./tokenized/Théatre II_corrected.txt\n",
      "Saved content for 'Théatre III_corrected' to ./tokenized/Théatre III_corrected.txt\n",
      "Saved content for 'Théatre IV_corrected' to ./tokenized/Théatre IV_corrected.txt\n",
      "Saved content for 'Théatre summary_corrected' to ./tokenized/Théatre summary_corrected.txt\n",
      "Saved content for 'Théatre V_corrected' to ./tokenized/Théatre V_corrected.txt\n"
     ]
    }
   ],
   "source": [
    "unigrams = {}\n",
    "\n",
    "for key, value in tokenized_texts.items():\n",
    "    unigram_list = wordpunct_tokenize(value)\n",
    "    cleanwords = [wordcleaner(w) for w in unigram_list]\n",
    "    unigrams[key] = cleanwords\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    filename = f\"./tokenized/{key}.txt\"\n",
    "    write_words_to_file(value, filename, words_per_line=20)\n",
    "    print(f\"Saved content for '{key}' to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d044c3f8-9aab-4362-8b85-a3709e228a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram texts:\n",
      "Théatre I_corrected\n",
      "Théatre II_corrected\n",
      "Théatre III_corrected\n",
      "Théatre IV_corrected\n",
      "Théatre summary_corrected\n",
      "Théatre V_corrected\n"
     ]
    }
   ],
   "source": [
    "print(\"Unigram texts:\")\n",
    "for key in unigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51492bb5-b662-4e41-bf0d-35e2bd3e3e5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Counts:\n",
      "Théatre I_corrected\n",
      "Théatre II_corrected\n",
      "Théatre III_corrected\n",
      "Théatre IV_corrected\n",
      "Théatre summary_corrected\n",
      "Théatre V_corrected\n",
      "First 25 items in Théatre I_corrected:\n",
      ": 7698\n",
      "de: 729\n",
      "la: 606\n",
      "que: 557\n",
      "l: 366\n",
      "il: 363\n",
      "en: 354\n",
      "qu: 346\n",
      "d: 316\n",
      "le: 313\n",
      "à: 308\n",
      "qui: 298\n",
      "les: 278\n",
      "a: 274\n",
      "ne: 272\n",
      "ce: 231\n",
      "n: 229\n",
      "par: 224\n",
      "des: 220\n",
      "eft: 218\n",
      "fe: 189\n",
      "vn: 175\n",
      "pas: 158\n",
      "au: 153\n",
      "du: 147\n",
      "\n",
      "First 25 items in Théatre II_corrected:\n",
      ": 6769\n",
      "de: 812\n",
      "l: 591\n",
      "la: 568\n",
      "que: 505\n",
      "les: 394\n",
      "qui: 365\n",
      "en: 330\n",
      "le: 320\n",
      "à: 318\n",
      "il: 272\n",
      "des: 264\n",
      "qu: 262\n",
      "eft: 250\n",
      "d: 226\n",
      "plus: 202\n",
      "a: 196\n",
      "par: 192\n",
      "ne: 182\n",
      "ce: 163\n",
      "s: 161\n",
      "n: 150\n",
      "m: 144\n",
      "du: 143\n",
      "ou: 141\n",
      "\n",
      "First 25 items in Théatre III_corrected:\n",
      ": 9144\n",
      "de: 953\n",
      "les: 733\n",
      "la: 585\n",
      "que: 553\n",
      "le: 505\n",
      "l: 498\n",
      "qu: 432\n",
      "des: 423\n",
      "en: 408\n",
      "à: 374\n",
      "d: 324\n",
      "qui: 321\n",
      "ne: 261\n",
      "a: 245\n",
      "plus: 239\n",
      "il: 234\n",
      "par: 206\n",
      "s: 203\n",
      "on: 195\n",
      "ce: 187\n",
      "font: 185\n",
      "n: 183\n",
      "du: 180\n",
      "fe: 169\n",
      "\n",
      "First 25 items in Théatre IV_corrected:\n",
      ": 8553\n",
      "de: 718\n",
      "l: 587\n",
      "que: 555\n",
      "la: 453\n",
      "les: 383\n",
      "qu: 347\n",
      "en: 333\n",
      "le: 299\n",
      "qui: 289\n",
      "d: 287\n",
      "à: 283\n",
      "il: 274\n",
      "ne: 273\n",
      "des: 269\n",
      "a: 237\n",
      "par: 220\n",
      "s: 201\n",
      "n: 200\n",
      "eft: 193\n",
      "fe: 161\n",
      "au: 160\n",
      "vn: 159\n",
      "ame: 150\n",
      "du: 147\n",
      "\n",
      "First 25 items in Théatre summary_corrected:\n",
      ": 439\n",
      "de: 84\n",
      "la: 54\n",
      "que: 39\n",
      "les: 38\n",
      "l: 28\n",
      "il: 26\n",
      "des: 26\n",
      "en: 25\n",
      "nous: 25\n",
      "qui: 24\n",
      "qu: 22\n",
      "plus: 21\n",
      "à: 19\n",
      "le: 17\n",
      "nature: 17\n",
      "ne: 15\n",
      "par: 15\n",
      "eft: 15\n",
      "n: 14\n",
      "d: 14\n",
      "choses: 12\n",
      "comme: 12\n",
      "du: 11\n",
      "pas: 11\n",
      "\n",
      "First 25 items in Théatre V_corrected:\n",
      ": 5860\n",
      "de: 747\n",
      "que: 436\n",
      "la: 425\n",
      "les: 349\n",
      "en: 312\n",
      "le: 286\n",
      "l: 281\n",
      "à: 247\n",
      "qu: 238\n",
      "d: 219\n",
      "il: 210\n",
      "plus: 201\n",
      "du: 187\n",
      "par: 184\n",
      "eft: 173\n",
      "des: 171\n",
      "qui: 162\n",
      "s: 158\n",
      "a: 155\n",
      "au: 119\n",
      "ce: 116\n",
      "ne: 116\n",
      "n: 101\n",
      "on: 101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count up the tokens using a Counter() object\n",
    "unigram_counts = {}\n",
    "for key, value in unigrams.items():\n",
    "    unigram_counts_dict = Counter(value)\n",
    "    unigram_counts[key] = unigram_counts_dict\n",
    "\n",
    "print(\"Unigram Counts:\")\n",
    "for key in unigram_counts:\n",
    "    print(key)\n",
    "\n",
    "print_first_n_items(unigram_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1300638a-16da-4c7f-8e9c-1de304b45009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 30 items in Théatre I_corrected:\n",
      ": 7698\n",
      "corps: 106\n",
      "choses: 93\n",
      "chose: 87\n",
      "nature: 83\n",
      "cause: 82\n",
      "monde: 81\n",
      "forme: 79\n",
      "foit: 64\n",
      "matiere: 61\n",
      "rien: 58\n",
      "mouvement: 49\n",
      "quelque: 48\n",
      "dieu: 43\n",
      "causes: 40\n",
      "lieu: 39\n",
      "quand: 39\n",
      "principe: 39\n",
      "dire: 38\n",
      "non: 38\n",
      "premiere: 37\n",
      "faut: 36\n",
      "donc: 36\n",
      "efté: 36\n",
      "fin: 35\n",
      "bien: 35\n",
      "grand: 34\n",
      "faire: 34\n",
      "autant: 34\n",
      "premier: 33\n",
      "\n",
      "First 30 items in Théatre II_corrected:\n",
      ": 6769\n",
      "eau: 104\n",
      "air: 99\n",
      "terre: 92\n",
      "corps: 72\n",
      "feu: 70\n",
      "nature: 63\n",
      "combien: 57\n",
      "grand: 45\n",
      "entre: 45\n",
      "pourquoy: 45\n",
      "fortes: 44\n",
      "foit: 40\n",
      "moins: 36\n",
      "choses: 35\n",
      "chose: 35\n",
      "bien: 33\n",
      "fois: 29\n",
      "fin: 29\n",
      "là: 28\n",
      "froid: 28\n",
      "rien: 28\n",
      "quand: 27\n",
      "autant: 26\n",
      "faut: 26\n",
      "dire: 25\n",
      "fort: 25\n",
      "argent: 25\n",
      "quelque: 24\n",
      "ment: 23\n",
      "\n",
      "First 30 items in Théatre III_corrected:\n",
      ": 9144\n",
      "animaux: 86\n",
      "pourquoy: 76\n",
      "elles: 72\n",
      "grand: 71\n",
      "nature: 68\n",
      "plantes: 52\n",
      "fois: 52\n",
      "moins: 49\n",
      "fort: 42\n",
      "où: 41\n",
      "homme: 41\n",
      "fin: 38\n",
      "là: 36\n",
      "force: 36\n",
      "hommes: 36\n",
      "vient: 35\n",
      "chose: 34\n",
      "ans: 34\n",
      "choses: 33\n",
      "fortes: 33\n",
      "vie: 32\n",
      "quelques: 32\n",
      "terre: 32\n",
      "efté: 31\n",
      "foit: 31\n",
      "quelque: 31\n",
      "combien: 30\n",
      "chaleur: 29\n",
      "corps: 28\n",
      "\n",
      "First 30 items in Théatre IV_corrected:\n",
      ": 8553\n",
      "ame: 150\n",
      "corps: 109\n",
      "chose: 95\n",
      "foit: 70\n",
      "fois: 65\n",
      "choses: 53\n",
      "homme: 47\n",
      "quand: 44\n",
      "moins: 44\n",
      "entendement: 44\n",
      "quelque: 43\n",
      "forme: 40\n",
      "sens: 39\n",
      "bien: 38\n",
      "ames: 37\n",
      "yeux: 37\n",
      "faut: 36\n",
      "non: 35\n",
      "pource: 35\n",
      "rien: 33\n",
      "faire: 32\n",
      "où: 31\n",
      "dire: 31\n",
      "hommes: 30\n",
      "mefine: 27\n",
      "ariftote: 27\n",
      "vient: 26\n",
      "elles: 26\n",
      "cefte: 24\n",
      "\n",
      "First 30 items in Théatre summary_corrected:\n",
      ": 439\n",
      "nature: 17\n",
      "choses: 12\n",
      "causes: 9\n",
      "ordre: 8\n",
      "foit: 8\n",
      "matiere: 7\n",
      "chose: 6\n",
      "faut: 5\n",
      "mouvement: 5\n",
      "hypostase: 5\n",
      "forme: 5\n",
      "doctrine: 4\n",
      "naturelles: 4\n",
      "com: 4\n",
      "generation: 4\n",
      "plantes: 4\n",
      "vie: 4\n",
      "hystoire: 4\n",
      "telle: 3\n",
      "faire: 3\n",
      "femble: 3\n",
      "doit: 3\n",
      "ailleurs: 3\n",
      "queftions: 3\n",
      "cieux: 3\n",
      "animaux: 3\n",
      "lequel: 3\n",
      "combien: 3\n",
      "toutesfois: 3\n",
      "\n",
      "First 30 items in Théatre V_corrected:\n",
      ": 5860\n",
      "terre: 76\n",
      "soleil: 70\n",
      "fois: 65\n",
      "grand: 63\n",
      "mille: 50\n",
      "lune: 46\n",
      "quatre: 42\n",
      "trois: 38\n",
      "quand: 36\n",
      "diametre: 36\n",
      "corps: 35\n",
      "cents: 34\n",
      "monde: 33\n",
      "mouvement: 33\n",
      "partie: 32\n",
      "foit: 32\n",
      "dieu: 30\n",
      "choses: 30\n",
      "vingt: 30\n",
      "ans: 29\n",
      "fept: 28\n",
      "cinq: 27\n",
      "cieux: 26\n",
      "estoiles: 26\n",
      "bien: 25\n",
      "fix: 25\n",
      "dire: 25\n",
      "nature: 24\n",
      "autant: 24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove specified keys from the dictionary\n",
    "stripped_unigrams = remove_keys_from_nested_dict(unigram_counts, stopwords)\n",
    "\n",
    "print_first_n_items(stripped_unigrams, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2d63ded-ea90-4894-af13-c8373b235afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Théatre I_corrected_unigram_counts.csv in tokenized/unigram_counts\n",
      "Saved Théatre II_corrected_unigram_counts.csv in tokenized/unigram_counts\n",
      "Saved Théatre III_corrected_unigram_counts.csv in tokenized/unigram_counts\n",
      "Saved Théatre IV_corrected_unigram_counts.csv in tokenized/unigram_counts\n",
      "Saved Théatre summary_corrected_unigram_counts.csv in tokenized/unigram_counts\n",
      "Saved Théatre V_corrected_unigram_counts.csv in tokenized/unigram_counts\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(stripped_unigrams, unigram_folder, 'unigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d6661b6-baf5-47d8-a58b-49bfedc0a32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams:\n",
      "Théatre I_corrected\n",
      "Théatre II_corrected\n",
      "Théatre III_corrected\n",
      "Théatre IV_corrected\n",
      "Théatre summary_corrected\n",
      "Théatre V_corrected\n"
     ]
    }
   ],
   "source": [
    "bigrams = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    #unigram_list = [word for word in value]\n",
    "    bigrams_list = list(nltk.bigrams(unigram_list))\n",
    "    bigrams[key] = bigrams_list\n",
    "\n",
    "print(\"Bigrams:\")\n",
    "for key in bigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24b278bb-d5b9-436c-8a31-3d626532ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Counts:\n",
      "Théatre I_corrected\n",
      "Théatre II_corrected\n",
      "Théatre III_corrected\n",
      "Théatre IV_corrected\n",
      "Théatre summary_corrected\n",
      "Théatre V_corrected\n",
      "First 30 items in Théatre I_corrected:\n",
      " : 2209\n",
      "nature : 48\n",
      "forme : 45\n",
      "chose : 44\n",
      "matiere : 43\n",
      "monde : 39\n",
      "choses : 39\n",
      " foit: 39\n",
      " quand: 38\n",
      "rien : 34\n",
      " autant: 34\n",
      " pourquoy: 31\n",
      " faut: 31\n",
      " forme: 30\n",
      " corps: 29\n",
      " choses: 28\n",
      " eau: 28\n",
      "corps naturel: 27\n",
      " non: 27\n",
      " cause: 26\n",
      " chose: 25\n",
      "mouvement : 25\n",
      "corps : 25\n",
      "dire : 25\n",
      " rien: 24\n",
      " nature: 24\n",
      " fois: 24\n",
      "lieu : 24\n",
      "cause : 23\n",
      " ment: 23\n",
      "\n",
      "First 30 items in Théatre II_corrected:\n",
      " : 1748\n",
      " eau: 102\n",
      " air: 94\n",
      "air : 60\n",
      "terre : 56\n",
      "feu : 49\n",
      "eau : 48\n",
      " combien: 46\n",
      " pourquoy: 33\n",
      "nature : 32\n",
      "fortes : 31\n",
      " corps: 25\n",
      " foit: 25\n",
      " autant: 24\n",
      " feu: 24\n",
      " fin: 23\n",
      " terre: 23\n",
      " là: 22\n",
      " quand: 22\n",
      "combien fortes: 21\n",
      " parce: 21\n",
      "pourquoy : 21\n",
      " entre: 20\n",
      " argent: 20\n",
      " fois: 19\n",
      "corps : 19\n",
      "entre : 19\n",
      " faut: 19\n",
      " ment: 18\n",
      "dire : 18\n",
      "\n",
      "First 30 items in Théatre III_corrected:\n",
      " : 2444\n",
      " pourquoy: 65\n",
      "animaux : 58\n",
      " elles: 56\n",
      "grand : 41\n",
      "plantes : 39\n",
      " homme: 38\n",
      " où: 36\n",
      " fin: 35\n",
      " fois: 31\n",
      " combien: 30\n",
      "pourquoy : 29\n",
      "nature : 29\n",
      " parce: 26\n",
      " quand: 26\n",
      "hommes : 25\n",
      "homme : 25\n",
      " animaux: 24\n",
      " grand: 24\n",
      "ans : 24\n",
      " là: 23\n",
      " ment: 23\n",
      "fois : 23\n",
      " toutesfois: 22\n",
      " moins: 22\n",
      " eau: 22\n",
      "vie : 20\n",
      " nature: 20\n",
      " autant: 20\n",
      "terre : 19\n",
      "\n",
      "First 30 items in Théatre IV_corrected:\n",
      " : 2856\n",
      " ame: 142\n",
      "ame : 70\n",
      " fois: 59\n",
      "corps : 56\n",
      "chose : 46\n",
      " homme: 43\n",
      " quand: 43\n",
      " entendement: 39\n",
      " foit: 36\n",
      " chose: 35\n",
      " pource: 34\n",
      " où: 28\n",
      " non: 27\n",
      "fois : 26\n",
      " faut: 25\n",
      "homme : 25\n",
      " moins: 25\n",
      "pource : 23\n",
      " corps: 23\n",
      "foit : 23\n",
      "tue : 22\n",
      " combien: 22\n",
      " rien: 21\n",
      " tue: 21\n",
      "sens : 21\n",
      " ariftote: 20\n",
      " elles: 20\n",
      " lequel: 20\n",
      "dire : 20\n",
      "\n",
      "First 30 items in Théatre summary_corrected:\n",
      " : 82\n",
      "nature : 9\n",
      "ordre : 5\n",
      "hypostase nature: 5\n",
      "forme : 5\n",
      " ordre: 4\n",
      "com : 4\n",
      "plantes : 4\n",
      "mouvement : 4\n",
      " foit: 4\n",
      " forme: 4\n",
      "naturelles : 3\n",
      " com: 3\n",
      " nature: 3\n",
      "generation : 3\n",
      "animaux : 3\n",
      " mouvement: 3\n",
      " lequel: 3\n",
      " combien: 3\n",
      "combien : 3\n",
      " air: 3\n",
      "air : 3\n",
      "physicien : 3\n",
      " faut: 3\n",
      " quelle: 3\n",
      "cho : 3\n",
      "matiere : 3\n",
      "elements : 3\n",
      "vie : 3\n",
      "choses : 3\n",
      "\n",
      "First 30 items in Théatre V_corrected:\n",
      " : 1494\n",
      "terre : 51\n",
      " fois: 45\n",
      " quand: 33\n",
      "mille : 33\n",
      "soleil : 30\n",
      " quatre: 30\n",
      "grand : 28\n",
      "vingt : 26\n",
      " trois: 23\n",
      "monde : 21\n",
      " grand: 21\n",
      " combien: 20\n",
      " pource: 20\n",
      " où: 19\n",
      " soleil: 19\n",
      " fin: 19\n",
      " lequel: 19\n",
      "lune : 19\n",
      " foit: 18\n",
      "fois : 18\n",
      "choses : 18\n",
      " fix: 18\n",
      " dire: 18\n",
      " autant: 17\n",
      "trente : 17\n",
      " lune: 17\n",
      "cieux : 16\n",
      " parce: 16\n",
      "ans : 16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bigram_counts = {}\n",
    "\n",
    "for key, value in bigrams.items():\n",
    "    string_bigrams = convert_tuple_bigrams(value)\n",
    "    bigramCount = convert_strings_to_counts(string_bigrams)\n",
    "    bigram_counts[key] = bigramCount\n",
    "\n",
    "print(\"Bigram Counts:\")\n",
    "for key in bigram_counts:\n",
    "    print(key)\n",
    "\n",
    "print_first_n_items(bigram_counts, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c4eb003-3c3c-4d9e-b5e9-1979bd1a3fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Théatre I_corrected_bigram_counts.csv in tokenized/bigram_counts\n",
      "Saved Théatre II_corrected_bigram_counts.csv in tokenized/bigram_counts\n",
      "Saved Théatre III_corrected_bigram_counts.csv in tokenized/bigram_counts\n",
      "Saved Théatre IV_corrected_bigram_counts.csv in tokenized/bigram_counts\n",
      "Saved Théatre summary_corrected_bigram_counts.csv in tokenized/bigram_counts\n",
      "Saved Théatre V_corrected_bigram_counts.csv in tokenized/bigram_counts\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(bigram_counts, bigram_folder, 'bigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfe978cd-c9e2-46c6-9c37-fbb524fbbd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigrams:\n",
      "Théatre I_corrected\n",
      "Théatre II_corrected\n",
      "Théatre III_corrected\n",
      "Théatre IV_corrected\n",
      "Théatre summary_corrected\n",
      "Théatre V_corrected\n"
     ]
    }
   ],
   "source": [
    "trigrams = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    #unigram_list = [word for word in value]\n",
    "    trigrams_list = list(nltk.trigrams(unigram_list))\n",
    "    trigrams[key] = trigrams_list\n",
    "\n",
    "print(\"Trigrams:\")\n",
    "for key in bigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b2a5667-7557-49d9-9904-184526684891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram Counts:\n",
      "Théatre I_corrected\n",
      "Théatre II_corrected\n",
      "Théatre III_corrected\n",
      "Théatre IV_corrected\n",
      "Théatre summary_corrected\n",
      "Théatre V_corrected\n",
      "First 30 items in Théatre I_corrected:\n",
      "  : 665\n",
      "  autant: 31\n",
      " forme : 20\n",
      "monde  : 19\n",
      "corps naturel : 18\n",
      "nature  : 18\n",
      " autant : 17\n",
      " eau : 17\n",
      "  pourquoy: 16\n",
      "choses  : 15\n",
      " chose : 14\n",
      "chose  : 14\n",
      "  fois: 14\n",
      " rien : 13\n",
      " com : 13\n",
      " foit : 13\n",
      "forme  : 13\n",
      "  dire: 13\n",
      "  premier: 12\n",
      "  rien: 12\n",
      " encor : 11\n",
      "naturel  : 11\n",
      " matiere : 11\n",
      "  eau: 11\n",
      " ment : 11\n",
      " dire : 11\n",
      "corps  : 10\n",
      " choses : 10\n",
      "quelque chose : 10\n",
      " corps naturel: 9\n",
      "\n",
      "First 30 items in Théatre II_corrected:\n",
      "  : 455\n",
      " air : 57\n",
      " eau : 47\n",
      "  eau: 28\n",
      "  air: 26\n",
      "terre  : 24\n",
      " combien fortes: 21\n",
      "feu  : 20\n",
      "  pourquoy: 20\n",
      "  combien: 19\n",
      " pourquoy : 19\n",
      "eau  : 19\n",
      "air  : 17\n",
      "combien fortes : 16\n",
      " celles : 16\n",
      "  autant: 15\n",
      " com : 14\n",
      "fortes  : 13\n",
      " feu : 13\n",
      " fin : 13\n",
      "  rien: 12\n",
      " terre : 12\n",
      " ment : 11\n",
      "  parce: 11\n",
      " combien : 10\n",
      " tn : 10\n",
      " argent vif: 10\n",
      " pource : 9\n",
      " metaux : 9\n",
      " ame : 9\n",
      "\n",
      "First 30 items in Théatre III_corrected:\n",
      "  : 769\n",
      "  pourquoy: 35\n",
      " pourquoy : 28\n",
      " homme : 24\n",
      "  où: 22\n",
      " animaux : 20\n",
      " fin : 17\n",
      " où vient: 17\n",
      "  elles: 16\n",
      " eau : 16\n",
      "  fois: 16\n",
      " parce : 14\n",
      "  autant: 14\n",
      " th : 13\n",
      "  parce: 13\n",
      " elles : 12\n",
      " fois : 12\n",
      " autant : 12\n",
      " mv : 11\n",
      " ment : 11\n",
      " my : 11\n",
      "hommes  : 11\n",
      "plantes  : 10\n",
      " combien : 10\n",
      " grand : 10\n",
      "nature  : 10\n",
      "animaux  : 10\n",
      " an : 9\n",
      "  quelle: 9\n",
      " plantes : 9\n",
      "\n",
      "First 30 items in Théatre IV_corrected:\n",
      "  : 1130\n",
      " ame : 65\n",
      "  ame: 52\n",
      "  fois: 26\n",
      " fois : 23\n",
      " homme : 22\n",
      " pource : 22\n",
      "corps  : 22\n",
      " tue : 21\n",
      "  entendement: 20\n",
      "  où: 17\n",
      " où vient: 17\n",
      " foit : 17\n",
      "ame  : 17\n",
      " chose : 16\n",
      "  autant: 15\n",
      "  non: 15\n",
      " com : 14\n",
      " entendement : 14\n",
      "  homme: 14\n",
      "chose  : 13\n",
      " non : 13\n",
      " ariftote : 12\n",
      " combien : 12\n",
      "  pource: 11\n",
      "homme  : 11\n",
      " rien : 11\n",
      "non  : 10\n",
      " cy : 10\n",
      " celuy : 10\n",
      "\n",
      "First 30 items in Théatre summary_corrected:\n",
      "  : 12\n",
      " forme : 4\n",
      " com : 3\n",
      " mouvement : 3\n",
      " combien : 3\n",
      "  air: 3\n",
      " air : 3\n",
      "cho  : 3\n",
      "matiere  forme: 3\n",
      " telle : 2\n",
      " ment : 2\n",
      " veu : 2\n",
      "  ailleurs: 2\n",
      "allez  : 2\n",
      " ordre : 2\n",
      "naturelles  : 2\n",
      " nature : 2\n",
      "nature  : 2\n",
      "  ame: 2\n",
      " ame : 2\n",
      "ame  : 2\n",
      " finalement : 2\n",
      "nature  lequel: 2\n",
      "combien  foit: 2\n",
      "foit propre physicien: 2\n",
      "propre physicien : 2\n",
      " animaux : 2\n",
      "  mis: 2\n",
      " doncques : 2\n",
      "hypostase nature celle: 2\n",
      "\n",
      "First 30 items in Théatre V_corrected:\n",
      "  : 425\n",
      "terre  : 19\n",
      "  dire: 16\n",
      "  où: 14\n",
      " combien : 14\n",
      "  fois: 13\n",
      " demy : 13\n",
      " où vient: 12\n",
      " fois : 12\n",
      "  grand: 12\n",
      " grand : 12\n",
      " pource : 12\n",
      " entendement : 11\n",
      "  autant: 10\n",
      " dire : 10\n",
      " hui : 10\n",
      " parce : 9\n",
      " mv : 9\n",
      " faire : 9\n",
      " forte : 8\n",
      "  soleil: 8\n",
      " mille : 8\n",
      "minutes  : 8\n",
      " f : 8\n",
      " com : 8\n",
      "cieux  : 7\n",
      " cy : 7\n",
      " voilà pourquoy: 7\n",
      " homme : 7\n",
      "  quelle: 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trigram_counts = {}\n",
    "\n",
    "for key, value in trigrams.items():\n",
    "    string_trigrams = convert_tuple_trigrams(value)\n",
    "    trigramCount = convert_strings_to_counts(string_trigrams)\n",
    "    trigram_counts[key] = trigramCount\n",
    "\n",
    "print(\"Trigram Counts:\")\n",
    "for key in trigram_counts:\n",
    "    print(key)\n",
    "    \n",
    "print_first_n_items(trigram_counts, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d36ad6c4-4f5b-4d15-b463-25318d4095b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Théatre I_corrected_trigram_counts.csv in tokenized/trigram_counts\n",
      "Saved Théatre II_corrected_trigram_counts.csv in tokenized/trigram_counts\n",
      "Saved Théatre III_corrected_trigram_counts.csv in tokenized/trigram_counts\n",
      "Saved Théatre IV_corrected_trigram_counts.csv in tokenized/trigram_counts\n",
      "Saved Théatre summary_corrected_trigram_counts.csv in tokenized/trigram_counts\n",
      "Saved Théatre V_corrected_trigram_counts.csv in tokenized/trigram_counts\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(trigram_counts, trigram_folder, 'trigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58fd2be9-d9ed-4c35-b058-5a1f944e992a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collocations:\n",
      "Théatre I_corrected\n",
      "Théatre II_corrected\n",
      "Théatre III_corrected\n",
      "Théatre IV_corrected\n",
      "Théatre summary_corrected\n",
      "Théatre V_corrected\n",
      "Collocation Counts:\n",
      "Théatre I_corrected\n",
      "nature  48\n",
      "forme  45\n",
      "matiere  43\n",
      " foit 39\n",
      " quand 38\n",
      "rien  34\n",
      " autant 34\n",
      " pourquoy 31\n",
      " faut 31\n",
      " eau 28\n",
      "corps naturel 27\n",
      " non 27\n",
      "dire  25\n",
      " fois 24\n",
      "lieu  24\n",
      " ment 23\n",
      "naturel  22\n",
      " bien 21\n",
      "quelque chose 21\n",
      " là 21\n",
      "fin  20\n",
      " efté 20\n",
      " pource 20\n",
      "elements  20\n",
      "foy  19\n",
      "encor  18\n",
      "eau  18\n",
      " toutesfois 16\n",
      "com  16\n",
      " elles 16\n",
      "\n",
      "Théatre II_corrected\n",
      " eau 102\n",
      " air 94\n",
      "air  60\n",
      "terre  56\n",
      "feu  49\n",
      " combien 46\n",
      " pourquoy 33\n",
      "nature  32\n",
      "fortes  31\n",
      " foit 25\n",
      " autant 24\n",
      " fin 23\n",
      " là 22\n",
      " quand 22\n",
      "combien fortes 21\n",
      " parce 21\n",
      " argent 20\n",
      " fois 19\n",
      " faut 19\n",
      " ment 18\n",
      "dire  18\n",
      "froid  18\n",
      "celles  18\n",
      " pource 17\n",
      " cy 17\n",
      "com  16\n",
      "fin  16\n",
      " toutesfois 16\n",
      " rien 16\n",
      " celles 16\n",
      "\n",
      "Théatre III_corrected\n",
      " pourquoy 65\n",
      "animaux  58\n",
      " elles 56\n",
      "plantes  39\n",
      " homme 38\n",
      " où 36\n",
      " fin 35\n",
      " combien 30\n",
      " parce 26\n",
      " quand 26\n",
      "hommes  25\n",
      "homme  25\n",
      "ans  24\n",
      " là 23\n",
      " ment 23\n",
      " toutesfois 22\n",
      " eau 22\n",
      "vie  20\n",
      " autant 20\n",
      " quelle 18\n",
      " cy 18\n",
      "com  18\n",
      " contraire 18\n",
      " lequel 18\n",
      "mer  17\n",
      "où vient 17\n",
      " an 16\n",
      " non 16\n",
      "eau  16\n",
      " finon 15\n",
      "\n",
      "Théatre IV_corrected\n",
      " ame 142\n",
      " fois 59\n",
      " homme 43\n",
      " quand 43\n",
      " entendement 39\n",
      " pource 34\n",
      " où 28\n",
      " non 27\n",
      " faut 25\n",
      "pource  23\n",
      "tue  22\n",
      " combien 22\n",
      " rien 21\n",
      " tue 21\n",
      " ariftote 20\n",
      " elles 20\n",
      " lequel 20\n",
      "dire  20\n",
      "ariftote  18\n",
      "où vient 17\n",
      " quelle 17\n",
      "forte  16\n",
      "enfemble  16\n",
      "com  15\n",
      " autant 15\n",
      "foy  15\n",
      "celuy  15\n",
      " autrement 15\n",
      " ens 15\n",
      " ment 15\n",
      "\n",
      "Théatre summary_corrected\n",
      "  82\n",
      "nature  9\n",
      "ordre  5\n",
      "hypostase nature 5\n",
      "forme  5\n",
      " ordre 4\n",
      "com  4\n",
      "plantes  4\n",
      "mouvement  4\n",
      " foit 4\n",
      " forme 4\n",
      "naturelles  3\n",
      " com 3\n",
      " nature 3\n",
      "generation  3\n",
      "animaux  3\n",
      " mouvement 3\n",
      " lequel 3\n",
      " combien 3\n",
      "combien  3\n",
      " air 3\n",
      "air  3\n",
      "physicien  3\n",
      " faut 3\n",
      " quelle 3\n",
      "cho  3\n",
      "matiere  3\n",
      "elements  3\n",
      "vie  3\n",
      "choses  3\n",
      "\n",
      "Théatre V_corrected\n",
      "terre  51\n",
      " fois 45\n",
      " quand 33\n",
      "mille  33\n",
      "soleil  30\n",
      " quatre 30\n",
      "grand  28\n",
      "vingt  26\n",
      " trois 23\n",
      "monde  21\n",
      " combien 20\n",
      " pource 20\n",
      " où 19\n",
      " fin 19\n",
      " lequel 19\n",
      " foit 18\n",
      "choses  18\n",
      " fix 18\n",
      " dire 18\n",
      " autant 17\n",
      "trente  17\n",
      "cieux  16\n",
      " parce 16\n",
      "ans  16\n",
      "minutes  16\n",
      " cinq 16\n",
      " neuf 15\n",
      "hui  15\n",
      " lors 15\n",
      " là 15\n",
      "\n",
      "Saved Théatre I_corrected_collocation_counts.csv in tokenized/collocation_counts\n",
      "Saved Théatre II_corrected_collocation_counts.csv in tokenized/collocation_counts\n",
      "Saved Théatre III_corrected_collocation_counts.csv in tokenized/collocation_counts\n",
      "Saved Théatre IV_corrected_collocation_counts.csv in tokenized/collocation_counts\n",
      "Saved Théatre summary_corrected_collocation_counts.csv in tokenized/collocation_counts\n",
      "Saved Théatre V_corrected_collocation_counts.csv in tokenized/collocation_counts\n"
     ]
    }
   ],
   "source": [
    "colloc_dict = {}\n",
    "colloc_counts = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    bigram_finder = BigramCollocationFinder.from_words(unigram_list)\n",
    "    bigram_finder.apply_freq_filter(3)  # Make sure all collocations have occurred at least 5 times\n",
    "    collocations = bigram_finder.nbest(BigramAssocMeasures.pmi, 500)\n",
    "    colloc_dict[key] = collocations\n",
    "    \n",
    "    # Initialize Counter for colloc_counts\n",
    "    bigram_count_dict = Counter()\n",
    "\n",
    "    # Count the occurrences of each bigram in the text\n",
    "    bigram_finder = BigramCollocationFinder.from_words(unigram_list)\n",
    "    bigram_freqs = bigram_finder.ngram_fd.items()\n",
    "    \n",
    "    # Filter bigram counts based on collocations\n",
    "    for bigram, count in bigram_freqs:\n",
    "        if bigram in collocations:\n",
    "            bigram_count_dict[bigram] = count\n",
    "\n",
    "    colloc_counts[key] = bigram_count_dict\n",
    "\n",
    "print(\"Collocations:\")\n",
    "for key, value in colloc_dict.items():\n",
    "    print(key)\n",
    "    # for w1, w2 in value:\n",
    "    #     print(' ', w1, w2)\n",
    "\n",
    "print(\"Collocation Counts:\")\n",
    "for key in colloc_counts:\n",
    "    print(key)\n",
    "    # Print first n items, assuming print_first_n_items function is defined elsewhere\n",
    "    for item, count in colloc_counts[key].most_common(30):\n",
    "        bigram = \" \".join(item)\n",
    "        print(f\"{bigram} {count}\")\n",
    "    print()\n",
    "\n",
    "dictionary_to_file(colloc_counts, collocation_folder, 'collocation_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4f5f4c8-a3e2-4e10-9a2f-b3369eced597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram Collocations:\n",
      "Théatre I_corrected\n",
      "Théatre II_corrected\n",
      "Théatre III_corrected\n",
      "Théatre IV_corrected\n",
      "Théatre summary_corrected\n",
      "Théatre V_corrected\n",
      "Trigram Collocation Counts:\n",
      "Théatre I_corrected\n",
      "   665\n",
      "  autant 31\n",
      " forme  20\n",
      "monde   19\n",
      "corps naturel  18\n",
      "nature   18\n",
      " autant  17\n",
      " eau  17\n",
      "  pourquoy 16\n",
      "choses   15\n",
      " chose  14\n",
      "chose   14\n",
      "  fois 14\n",
      " rien  13\n",
      " com  13\n",
      " foit  13\n",
      "forme   13\n",
      "  dire 13\n",
      "  premier 12\n",
      "  rien 12\n",
      " encor  11\n",
      "naturel   11\n",
      " matiere  11\n",
      "  eau 11\n",
      " ment  11\n",
      " dire  11\n",
      "corps   10\n",
      " choses  10\n",
      "quelque chose  10\n",
      " corps naturel 9\n",
      "\n",
      "Théatre II_corrected\n",
      "   455\n",
      " air  57\n",
      " eau  47\n",
      "  eau 28\n",
      "  air 26\n",
      "terre   24\n",
      " combien fortes 21\n",
      "feu   20\n",
      "  pourquoy 20\n",
      "  combien 19\n",
      " pourquoy  19\n",
      "eau   19\n",
      "air   17\n",
      "combien fortes  16\n",
      " celles  16\n",
      "  autant 15\n",
      " com  14\n",
      "fortes   13\n",
      " feu  13\n",
      " fin  13\n",
      "  rien 12\n",
      " terre  12\n",
      " ment  11\n",
      "  parce 11\n",
      " combien  10\n",
      " tn  10\n",
      " argent vif 10\n",
      " pource  9\n",
      " metaux  9\n",
      " ame  9\n",
      "\n",
      "Théatre III_corrected\n",
      "   769\n",
      "  pourquoy 35\n",
      " pourquoy  28\n",
      " homme  24\n",
      "  où 22\n",
      " animaux  20\n",
      " fin  17\n",
      " où vient 17\n",
      "  elles 16\n",
      " eau  16\n",
      "  fois 16\n",
      " parce  14\n",
      "  autant 14\n",
      " th  13\n",
      "  parce 13\n",
      " elles  12\n",
      " fois  12\n",
      " autant  12\n",
      " mv  11\n",
      " ment  11\n",
      " my  11\n",
      "hommes   11\n",
      "plantes   10\n",
      " combien  10\n",
      " grand  10\n",
      "nature   10\n",
      "animaux   10\n",
      " an  9\n",
      "  quelle 9\n",
      " plantes  9\n",
      "\n",
      "Théatre IV_corrected\n",
      "   1130\n",
      " ame  65\n",
      "  ame 52\n",
      "  fois 26\n",
      " fois  23\n",
      " homme  22\n",
      " pource  22\n",
      "corps   22\n",
      " tue  21\n",
      "  entendement 20\n",
      "  où 17\n",
      " où vient 17\n",
      " foit  17\n",
      "ame   17\n",
      " chose  16\n",
      "  autant 15\n",
      "  non 15\n",
      " com  14\n",
      " entendement  14\n",
      "  homme 14\n",
      "chose   13\n",
      " non  13\n",
      " ariftote  12\n",
      " combien  12\n",
      "  pource 11\n",
      "homme   11\n",
      " rien  11\n",
      "non   10\n",
      " cy  10\n",
      " celuy  10\n",
      "\n",
      "Théatre summary_corrected\n",
      "   12\n",
      " forme  4\n",
      " com  3\n",
      " mouvement  3\n",
      " combien  3\n",
      "  air 3\n",
      " air  3\n",
      "cho   3\n",
      "matiere  forme 3\n",
      "\n",
      "Théatre V_corrected\n",
      "   425\n",
      "terre   19\n",
      "  dire 16\n",
      "  où 14\n",
      " combien  14\n",
      "  fois 13\n",
      " demy  13\n",
      " où vient 12\n",
      " fois  12\n",
      "  grand 12\n",
      " grand  12\n",
      " pource  12\n",
      " entendement  11\n",
      "  autant 10\n",
      " dire  10\n",
      " hui  10\n",
      " parce  9\n",
      " mv  9\n",
      " faire  9\n",
      " forte  8\n",
      "  soleil 8\n",
      " mille  8\n",
      "minutes   8\n",
      " f  8\n",
      " com  8\n",
      "cieux   7\n",
      " cy  7\n",
      " voilà pourquoy 7\n",
      " homme  7\n",
      "  quelle 7\n",
      "\n",
      "Saved Théatre I_corrected_trigram_collocation_counts.csv in tokenized/trigram_collocation_counts\n",
      "Saved Théatre II_corrected_trigram_collocation_counts.csv in tokenized/trigram_collocation_counts\n",
      "Saved Théatre III_corrected_trigram_collocation_counts.csv in tokenized/trigram_collocation_counts\n",
      "Saved Théatre IV_corrected_trigram_collocation_counts.csv in tokenized/trigram_collocation_counts\n",
      "Saved Théatre summary_corrected_trigram_collocation_counts.csv in tokenized/trigram_collocation_counts\n",
      "Saved Théatre V_corrected_trigram_collocation_counts.csv in tokenized/trigram_collocation_counts\n"
     ]
    }
   ],
   "source": [
    "trigram_colloc_dict = {}\n",
    "trigram_colloc_counts = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    trigram_finder = TrigramCollocationFinder.from_words(unigram_list)\n",
    "    trigram_finder.apply_freq_filter(3)  # Ensure all collocations have occurred at least 5 times\n",
    "    collocations = trigram_finder.nbest(TrigramAssocMeasures.pmi, 500)\n",
    "    trigram_colloc_dict[key] = collocations\n",
    "    \n",
    "    # Initialize Counter for trigram_colloc_counts\n",
    "    trigram_count_dict = Counter()\n",
    "\n",
    "    # Count the occurrences of each trigram in the text\n",
    "    trigram_freqs = trigram_finder.ngram_fd.items()\n",
    "    \n",
    "    # Filter trigram counts based on collocations\n",
    "    for trigram, count in trigram_freqs:\n",
    "        if trigram in collocations:\n",
    "            trigram_count_dict[trigram] = count\n",
    "\n",
    "    trigram_colloc_counts[key] = trigram_count_dict\n",
    "\n",
    "print(\"Trigram Collocations:\")\n",
    "for key, value in trigram_colloc_dict.items():\n",
    "    print(key)\n",
    "    #for w1, w2, w3 in value:\n",
    "    #    print(' ', w1, w2, w3)\n",
    "\n",
    "print(\"Trigram Collocation Counts:\")\n",
    "for key in trigram_colloc_counts:\n",
    "    print(key)\n",
    "    # Print first n items, assuming print_first_n_items function is defined elsewhere\n",
    "    for item, count in trigram_colloc_counts[key].most_common(30):\n",
    "        trigram = \" \".join(item)\n",
    "        print(f\"{trigram} {count}\")\n",
    "    print()\n",
    "\n",
    "dictionary_to_file(trigram_colloc_counts, trigram_collocation_folder, 'trigram_collocation_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b890221-5827-4d01-a9ab-9726fde00e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underscore Dictionary:\n",
      "Théatre I_corrected\n",
      "Théatre II_corrected\n",
      "Théatre III_corrected\n",
      "Théatre IV_corrected\n",
      "Théatre summary_corrected\n",
      "Théatre V_corrected\n",
      "Théatre I_corrected_underscore_bigrams.txt in tokenized/underscore_bigrams\n",
      "Théatre II_corrected_underscore_bigrams.txt in tokenized/underscore_bigrams\n",
      "Théatre III_corrected_underscore_bigrams.txt in tokenized/underscore_bigrams\n",
      "Théatre IV_corrected_underscore_bigrams.txt in tokenized/underscore_bigrams\n",
      "Théatre summary_corrected_underscore_bigrams.txt in tokenized/underscore_bigrams\n",
      "Théatre V_corrected_underscore_bigrams.txt in tokenized/underscore_bigrams\n"
     ]
    }
   ],
   "source": [
    "underscore_dict = {}\n",
    "for key, value in unigrams.items():\n",
    "\n",
    "    tokenized_words = unigrams.get(key)\n",
    "    collocations = colloc_dict.get(key)\n",
    "    \n",
    "    colloc_words = []\n",
    "    \n",
    "    # Iterate through the words making new versions combining collocations\n",
    "    i = 0\n",
    "    while i < len(tokenized_words) - 1:\n",
    "        # If we find a collocation, add and advance by two words\n",
    "        if (tokenized_words[i], tokenized_words[i + 1]) in collocations:\n",
    "            colloc_words.append('_'.join((tokenized_words[i], tokenized_words[i + 1])))\n",
    "            i += 2\n",
    "        # Otherwise, advance by one word\n",
    "        else:\n",
    "            colloc_words.append(tokenized_words[i])\n",
    "            i += 1\n",
    "\n",
    "    # Add the last word (if any)\n",
    "    if i == len(tokenized_words) - 1:\n",
    "        colloc_words.append(tokenized_words[i])\n",
    "    underscore_dict[key] = colloc_words\n",
    "\n",
    "print(\"Underscore Dictionary:\")\n",
    "for key in underscore_dict:\n",
    "    print(key)\n",
    "\n",
    "write_dict_to_files_with_suffix(underscore_dict, underscore_folder, 'underscore_bigrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f0b3b4c-c6df-4bdf-84c2-fb152e0b68e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram underscore Dictionary:\n",
      "Théatre I_corrected\n",
      "Théatre II_corrected\n",
      "Théatre III_corrected\n",
      "Théatre IV_corrected\n",
      "Théatre summary_corrected\n",
      "Théatre V_corrected\n",
      "Théatre I_corrected_underscore_trigrams.txt in tokenized/underscore_trigrams\n",
      "Théatre II_corrected_underscore_trigrams.txt in tokenized/underscore_trigrams\n",
      "Théatre III_corrected_underscore_trigrams.txt in tokenized/underscore_trigrams\n",
      "Théatre IV_corrected_underscore_trigrams.txt in tokenized/underscore_trigrams\n",
      "Théatre summary_corrected_underscore_trigrams.txt in tokenized/underscore_trigrams\n",
      "Théatre V_corrected_underscore_trigrams.txt in tokenized/underscore_trigrams\n"
     ]
    }
   ],
   "source": [
    "trigram_underscore_dict = {}\n",
    "\n",
    "for key, tokenized_words in unigrams.items():\n",
    "    collocations = trigram_colloc_dict.get(key, [])\n",
    "    colloc_words = []\n",
    "    i = 0\n",
    "    while i < len(tokenized_words) - 2:\n",
    "        # If we find a trigram collocation, add and advance by three words\n",
    "        trigram = (tokenized_words[i], tokenized_words[i + 1], tokenized_words[i + 2])\n",
    "        if trigram in collocations:\n",
    "            colloc_words.append('_'.join(trigram))\n",
    "            i += 3\n",
    "        else:\n",
    "            colloc_words.append(tokenized_words[i])\n",
    "            i += 1\n",
    "    # Add the last words (if any)\n",
    "    while i < len(tokenized_words):\n",
    "        colloc_words.append(tokenized_words[i])\n",
    "        i += 1\n",
    "    trigram_underscore_dict[key] = colloc_words\n",
    "\n",
    "print(\"Trigram underscore Dictionary:\")\n",
    "for key in trigram_underscore_dict:\n",
    "    print(key)\n",
    "\n",
    "write_dict_to_files_with_suffix(trigram_underscore_dict, trigram_underscore_folder, 'underscore_trigrams')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
