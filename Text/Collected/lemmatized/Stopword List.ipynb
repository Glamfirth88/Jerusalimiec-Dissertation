{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af8ff0ef-2f70-485a-a86e-91aa4ebeca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dfe3392-8fdb-46c5-b153-c6757e0de887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arabic', 'azerbaijani', 'basque', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'turkish']\n"
     ]
    }
   ],
   "source": [
    "# Creating a stop_words list from the NLTK.\n",
    "import csv # Import the csv module to work with csv files\n",
    "from nltk.corpus import stopwords # Import stopwords from nltk.corpus\n",
    "print(stopwords.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85c15f95-5054-4169-993b-d7851712a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('french') # Create a list `stop_words` that contains the French stop words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aaa6138-2105-42f1-a9cd-a7941201d24c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ai',\n",
       " 'aie',\n",
       " 'aient',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'as',\n",
       " 'au',\n",
       " 'aura',\n",
       " 'aurai',\n",
       " 'auraient',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'auras',\n",
       " 'aurez',\n",
       " 'auriez',\n",
       " 'aurions',\n",
       " 'aurons',\n",
       " 'auront',\n",
       " 'aux',\n",
       " 'avaient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avec',\n",
       " 'avez',\n",
       " 'aviez',\n",
       " 'avions',\n",
       " 'avons',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'ayez',\n",
       " 'ayons',\n",
       " 'c',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'd',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'es',\n",
       " 'est',\n",
       " 'et',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eurent',\n",
       " 'eus',\n",
       " 'eusse',\n",
       " 'eussent',\n",
       " 'eusses',\n",
       " 'eussiez',\n",
       " 'eussions',\n",
       " 'eut',\n",
       " 'eux',\n",
       " 'eûmes',\n",
       " 'eût',\n",
       " 'eûtes',\n",
       " 'furent',\n",
       " 'fus',\n",
       " 'fusse',\n",
       " 'fussent',\n",
       " 'fusses',\n",
       " 'fussiez',\n",
       " 'fussions',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fût',\n",
       " 'fûtes',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'j',\n",
       " 'je',\n",
       " 'l',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'même',\n",
       " 'n',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ont',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 's',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'sera',\n",
       " 'serai',\n",
       " 'seraient',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'seras',\n",
       " 'serez',\n",
       " 'seriez',\n",
       " 'serions',\n",
       " 'serons',\n",
       " 'seront',\n",
       " 'ses',\n",
       " 'soient',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'sommes',\n",
       " 'son',\n",
       " 'sont',\n",
       " 'soyez',\n",
       " 'soyons',\n",
       " 'suis',\n",
       " 'sur',\n",
       " 't',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'y',\n",
       " 'à',\n",
       " 'étaient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étant',\n",
       " 'étante',\n",
       " 'étantes',\n",
       " 'étants',\n",
       " 'étiez',\n",
       " 'étions',\n",
       " 'été',\n",
       " 'étée',\n",
       " 'étées',\n",
       " 'étés',\n",
       " 'êtes']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sorted(stop_words)) # Show each string in our stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9316e4-f5c7-4f12-8b87-ee10ccdd1cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vn', 'vne', 'vnes', 'votr', 'voz', 'w', 'x', 'y', 'ya', 'ycel']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "middle_french_stopwords =  [\n",
    "\n",
    "'a', 'aa', 'aaa', 'ains', 'ainsi', 'ainsy', 'aist', 'am', 'ans', 'apres',\n",
    "'ar', 'ara', 'aultr', 'aujourd', 'audict', 'auoit', 'auoir', 'aultre', 'auec', 'aufi',\n",
    "'auffi', 'aussi', 'aussy', 'autre', 'autres', 'autr', 'avecqu', 'avecque', 'avoyent', 'avoient', 'avoit',\n",
    "'ay', 'b', 'bl', 'car', 'cc', 'celuy', 'certes', 'cet', 'ceste', 'cest',\n",
    "'ceulx', 'ceux', 'cf', 'cg', 'chap', 'chacun', 'cft', 'chose', 'comme', 'comm',\n",
    "'co', 'cn', 'contr', 'dan', 'dc', 'de', 'del', 'dela', 'den', 'depuis',\n",
    "'deux', 'di', 'dict', 'dift', 'dixiem', 'dixieme', 'dom', 'dud', 'dudict', 'dudit',\n",
    "'e', 'ee', 'ef', 'eft', 'eftoit', 'eftre', 'ellas', 'elles', 'enl', 'encore',\n",
    "'etoient', 'etoit', 'estre', 'estoit', 'estoy', 'étre', 'étoient', 'étoit', 'étoient', 'étre',\n",
    "'este', 'esté', 'eulx', 'eust', 'fa', 'fait', 'faict', 'fai', 'fair', 'fan', 'faut',\n",
    "'fault', 'fe', 'fc', 'feut', 'fes', 'fi', 'fift', 'fon', 'font', 'fur',\n",
    "'fust', 'g', 'grand', 'i', 'iamais', 'ia', 'ie', 'iij', 'iir', 'ilz',\n",
    "'in', 'ion', 'laquelle', 'ladict', 'ladicte', 'ladit', 'ladite', 'lc', 'ledict', 'ledit',\n",
    "'leurs', 'li', 'lib', 'livr', 'livre', 'livres', 'luy', 'lx', 'lzs', 'm',\n",
    "'mefme', 'mefmes', 'mesme', 'mil', 'million', 'mp', 'mv', 'ni', 'non', 'nostr',\n",
    "'noz', 'nw', 'ny', 'o', 'or', 'ores', 'où', 'p', 'pe', 'peut',\n",
    "'plus', 'poinct', 'point', 'pre', 'puis', 'q', 'quatre', 'quatriesme', 'quele', 'queles',\n",
    "'quelque', 'quel', 'quatr', 'quatre', 'qut', 'rar', 're', 'r', 'rr', 'san',\n",
    "'section', 'second', 'seroit', 'si', 'sixiesme', 'soubs', 'soub', 'sr', 'tant', 'tett',\n",
    "'tout', 'toutes', 'touts', 'tous', 'trait', 'tr', 'trois', 'troisieme', 'troisiesme', 'tt',\n",
    "'u', 'ua', 'ue', 'ung', 'v', 'vingt', 'vn', 'vne', 'vnes', 'votr',\n",
    "'voz', 'w', 'x', 'y', 'ya', 'ycel'\n",
    "\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "combined_stopwords = stop_words + middle_french_stopwords\n",
    "\n",
    "list(combined_stopwords)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caaa1991-aaf9-4ed2-936b-0c39bd700fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./stop_words.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(combined_stopwords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
