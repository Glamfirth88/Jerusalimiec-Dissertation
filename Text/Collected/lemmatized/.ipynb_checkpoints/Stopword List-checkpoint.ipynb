{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af8ff0ef-2f70-485a-a86e-91aa4ebeca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dfe3392-8fdb-46c5-b153-c6757e0de887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arabic', 'azerbaijani', 'basque', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'turkish']\n"
     ]
    }
   ],
   "source": [
    "# Creating a stop_words list from the NLTK.\n",
    "import csv # Import the csv module to work with csv files\n",
    "from nltk.corpus import stopwords # Import stopwords from nltk.corpus\n",
    "print(stopwords.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85c15f95-5054-4169-993b-d7851712a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('french') # Create a list `stop_words` that contains the French stop words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aaa6138-2105-42f1-a9cd-a7941201d24c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ai',\n",
       " 'aie',\n",
       " 'aient',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'as',\n",
       " 'au',\n",
       " 'aura',\n",
       " 'aurai',\n",
       " 'auraient',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'auras',\n",
       " 'aurez',\n",
       " 'auriez',\n",
       " 'aurions',\n",
       " 'aurons',\n",
       " 'auront',\n",
       " 'aux',\n",
       " 'avaient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avec',\n",
       " 'avez',\n",
       " 'aviez',\n",
       " 'avions',\n",
       " 'avons',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'ayez',\n",
       " 'ayons',\n",
       " 'c',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'd',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'es',\n",
       " 'est',\n",
       " 'et',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eurent',\n",
       " 'eus',\n",
       " 'eusse',\n",
       " 'eussent',\n",
       " 'eusses',\n",
       " 'eussiez',\n",
       " 'eussions',\n",
       " 'eut',\n",
       " 'eux',\n",
       " 'eûmes',\n",
       " 'eût',\n",
       " 'eûtes',\n",
       " 'furent',\n",
       " 'fus',\n",
       " 'fusse',\n",
       " 'fussent',\n",
       " 'fusses',\n",
       " 'fussiez',\n",
       " 'fussions',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fût',\n",
       " 'fûtes',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'j',\n",
       " 'je',\n",
       " 'l',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'même',\n",
       " 'n',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ont',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 's',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'sera',\n",
       " 'serai',\n",
       " 'seraient',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'seras',\n",
       " 'serez',\n",
       " 'seriez',\n",
       " 'serions',\n",
       " 'serons',\n",
       " 'seront',\n",
       " 'ses',\n",
       " 'soient',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'sommes',\n",
       " 'son',\n",
       " 'sont',\n",
       " 'soyez',\n",
       " 'soyons',\n",
       " 'suis',\n",
       " 'sur',\n",
       " 't',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'y',\n",
       " 'à',\n",
       " 'étaient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étant',\n",
       " 'étante',\n",
       " 'étantes',\n",
       " 'étants',\n",
       " 'étiez',\n",
       " 'étions',\n",
       " 'été',\n",
       " 'étée',\n",
       " 'étées',\n",
       " 'étés',\n",
       " 'êtes']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sorted(stop_words)) # Show each string in our stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9316e4-f5c7-4f12-8b87-ee10ccdd1cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vnes', 'vostr', 'votr', 'voz', 'w', 'x', 'xx', 'y', 'ya', 'ycel']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "middle_french_stopwords = [\n",
    "'a', 'aa', 'aaa', 'ae', 'ain', 'ains', 'ainsi', 'ainsy', 'aist', 'al', 'am', 'an', 'ans', 'apre', 'apres',\n",
    "'ar', 'ara', 'at', 'aucun', 'aucung', 'aulcung', 'aultr', 'aujourd', 'audict', 'auoit', 'auoir', 'aultre', 'auec',\n",
    "'aufi', 'auffi', 'auss', 'aussi', 'aussy', 'aut', 'autre', 'autres', 'autr', 'auxdict', 'avoir', 'avoyent',\n",
    "'avecqu', 'avecque', 'avoyent', 'avoient', 'avoit', 'ay', 'b', 'bi', 'bl', 'car', 'cc', 'cel', 'celuy', 'cen',\n",
    "'cent', 'certes', 'cet', 'ceste', 'cest', 'ceulx', 'ceux', 'cf', 'cg', 'chap', 'chacun', 'chaqu', 'chascung',\n",
    "'cinq', 'cft', 'co', 'com', 'comb', 'comme', 'comm', 'constituendá', 'cn', 'contr', 'da', 'dan', 'dc', 'de',\n",
    "'dé', 'del', 'dela', 'den', 'depuis', 'deux', 'di', 'dict', 'dift', 'dit', 'dix', 'dixiem', 'dixieme', 'do',\n",
    "'dom', 'douz', 'dud', 'dudict', 'dudit', 'e', 'é', 'ee', 'ec', 'ef', 'eft', 'eftoit', 'eftre', 'ellas',\n",
    "'elles', 'enl', 'encore', 'ena', 'er', 'estant', 'estre', 'estoit', 'estoient', 'estoy', 'estoyent', 'este', 'esté',\n",
    "'etoient', 'étoient', 'etoit', 'étoit', 'étre', 'étre', 'eulx', 'eust', 'ex', 'f', 'fa', 'fait', 'faict',\n",
    "'fai', 'fair', 'fan', 'fault', 'faut', 'fc', 'fe', 'feut', 'fes', 'ff', 'fi', 'fil', 'fift', 'firent',\n",
    "'fit', 'fon', 'font', 'ft', 'fur', 'fust', 'g', 'grand', 'h', 'he', 'ho', 'i', 'ia', 'iam', 'iamais',\n",
    "'ic', 'ie', 'iij', 'iir', 'ilz', 'im', 'in', 'ion', 'it', 'iusqu', 'iv', 'ix', 'jam', 'laquelle', 'ladict',\n",
    "'ladicte', 'ladit', 'ladite', 'laquel', 'lc', 'led', 'ledict', 'ledit', 'lesdict', 'lesdictz', 'lesdit', 'leurs', 'lib',\n",
    "'livre', 'livres', 'll', 'lu', 'luy', 'lx', 'lzs', 'm', 'memoir', 'mesm', 'mesme', 'mefme', 'mefmes', 'mil',\n",
    "'million', 'même', 'moy', 'mp', 'mv', 'nc', 'neantmoin', 'ni', 'no', 'non', 'nostr', 'noz', 'nu', 'ny', 'nw',\n",
    "'o', 'op', 'or', 'ores', 'où', 'oy', 'p', 'parl', 'pa', 'pe', 'peult', 'peulvent', 'peut', 'plus', 'poinct',\n",
    "'point', 'pourc', 'pourl', 'pourt', 'pre', 'puis', 'q', 'quand', 'quatr', 'quatre', 'quatriesme', 'quele', 'queles', 'quelqu',\n",
    "'quelque', 'quelquesfois', 'quel', 'quil', 'qut', 'rar', 're', 'r', 'rr', 'rien', 'ri', 'san', 'section', 'second',\n",
    "'ser', 'serois', 'seroit', 'seul', 'si', 'sil', 'six', 'sixiesme', 'soubs', 'soub', 'sr', 'tant', 'tel', 'tett',\n",
    "'tout', 'touts', 'tous', 'tousjour', 'toutes', 'toutesfois', 'trait', 'tr', 'tré', 'tre', 'trois', 'troisieme', 'troisiesme', 'trop',\n",
    "'tt', 'u', 'ua', 'ue', 'ung', 'ur', 'v', 'vingt', 'vn', 'vnc', 'vne', 'vnes', 'vostr', 'votr',\n",
    "'voz', 'w', 'x', 'xx', 'y', 'ya', 'ycel', 'ure'\n",
    "]\n",
    "\n",
    "\n",
    "combined_stopwords = stop_words + middle_french_stopwords\n",
    "\n",
    "list(combined_stopwords)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caaa1991-aaf9-4ed2-936b-0c39bd700fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./stop_words.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(combined_stopwords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
