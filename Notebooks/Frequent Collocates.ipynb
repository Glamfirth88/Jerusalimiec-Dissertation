{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf0d5463-1552-4dd3-9f0c-63c156fb508a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. tokenized\n",
      "2. concordances\n",
      "3. final\n",
      "4. .ipynb_checkpoints\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select a subfolder by number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Démonomanie Repair_corrected_underscore_bigrams.txt\n",
      "2. Démonomanie Repair_corrected.txt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select a text file by number:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of 'text': <class 'nltk.text.Text'>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter words to find their concordance (separated by spaces):  malade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a directory for the stopwords csv file:\n",
      "1. .\n",
      "2. tokenized\n",
      "3. concordances\n",
      "4. final\n",
      "5. .ipynb_checkpoints\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. spellcheck_data.csv\n",
      "2. stop_words.csv\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select a text file by number:  2\n",
      "Exclude target term 'malade' from concordance (yes/no)?  no\n",
      "Enter the window size for concordance for 'malade':  8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance for the token \"malade\" has been saved to concordances/malade.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import csv\n",
    "\n",
    "# Function to list subfolders in the current directory\n",
    "def list_subfolders():\n",
    "    return [f.name for f in os.scandir() if f.is_dir()]\n",
    "\n",
    "# Function to prompt the user to select a subfolder\n",
    "def prompt_subfolder(subfolders):\n",
    "    for index, folder in enumerate(subfolders, start=1):\n",
    "        print(f\"{index}. {folder}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Select a subfolder by number: \"))\n",
    "            if 1 <= choice <= len(subfolders):\n",
    "                return subfolders[choice - 1]\n",
    "            else:\n",
    "                print(\"Invalid selection. Please try again.\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a number.\")\n",
    "\n",
    "# Function to find text files in a folder\n",
    "def find_text_files(folder):\n",
    "    text_files = [f for f in os.listdir(folder) if f.endswith('.txt')]\n",
    "    return text_files\n",
    "\n",
    "# Function to find csv files in a folder\n",
    "def find_csv_files(folder):\n",
    "    csv_files = [f for f in os.listdir(folder) if f.endswith('.csv')]\n",
    "    return csv_files\n",
    "\n",
    "# Function to prompt the user to select a text file\n",
    "def prompt_text_file(text_files):\n",
    "    for index, file in enumerate(text_files, start=1):\n",
    "        print(f\"{index}. {file}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Select a text file by number: \"))\n",
    "            if 1 <= choice <= len(text_files):\n",
    "                return text_files[choice - 1]\n",
    "            else:\n",
    "                print(\"Invalid selection. Please try again.\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a number.\")\n",
    "\n",
    "# Function to process the selected text file\n",
    "def process_text_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        file_contents = f.read().lower()\n",
    "        tokens = nltk.wordpunct_tokenize(file_contents)\n",
    "        text = nltk.Text(tokens)\n",
    "        return text\n",
    "\n",
    "subfolders = list_subfolders()\n",
    "if subfolders:\n",
    "    selected_subfolder = prompt_subfolder(subfolders)\n",
    "    subfolder_path = os.path.join(os.getcwd(), selected_subfolder)\n",
    "    text_files = find_text_files(subfolder_path)\n",
    "    if text_files:\n",
    "        selected_file = prompt_text_file(text_files)\n",
    "        full_file_path = os.path.join(subfolder_path, selected_file)\n",
    "        text_data = process_text_file(full_file_path)\n",
    "        print(f\"Type of 'text': {type(text_data)}\")\n",
    "    else:\n",
    "        print(f\"No text files found in '{selected_subfolder}'.\")\n",
    "else:\n",
    "    print(\"No subfolders found in the current directory.\")\n",
    "\n",
    "def get_kwic(sometargetterm, somelistofwords, window=10, excl_target=True):\n",
    "    kwics = []\n",
    "    for n, w in enumerate(somelistofwords):\n",
    "        if w == sometargetterm:\n",
    "            start = max(0, n - window)\n",
    "            end = min(n + window + 1, len(somelistofwords))\n",
    "            if excl_target:\n",
    "                k = somelistofwords[start:n] + somelistofwords[n + 1:end]\n",
    "            else:\n",
    "                k = somelistofwords[start:end]\n",
    "            kwics.append(k)\n",
    "    return kwics\n",
    "\n",
    "def add_to_count_dict(word, count_dict):\n",
    "    if word in count_dict:\n",
    "        count_dict[word] += 1\n",
    "    else:\n",
    "        count_dict[word] = 1\n",
    "\n",
    "def search_concordance(text_data, tokens):\n",
    "    for token in tokens:\n",
    "        # Create the directory if it does not exist\n",
    "        directory = 'concordances'\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        # Create a filename for each token\n",
    "        filename = f\"{token}.csv\"\n",
    "        file_path = os.path.join(directory, filename)\n",
    "\n",
    "        excl_target = input(f\"Exclude target term '{token}' from concordance (yes/no)? \").strip().lower() == 'yes'\n",
    "        window = int(input(f\"Enter the window size for concordance for '{token}': \").strip())\n",
    "\n",
    "        with open(file_path, 'w', newline='') as csvfile:\n",
    "            fieldnames = ['Collocate', 'Count', 'Frequency']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "\n",
    "            words = text_data.tokens\n",
    "            kwics = get_kwic(token, words, window, excl_target)\n",
    "            counts = {}\n",
    "            for k in kwics:\n",
    "                for w in k:\n",
    "                    add_to_count_dict(w, counts)\n",
    "            total_wc = sum(counts.values())\n",
    "            for word, count in sorted(counts.items(), key=lambda item: item[1], reverse=True):\n",
    "                if word not in stops:\n",
    "                    frequency = count / total_wc\n",
    "                    writer.writerow({'Collocate': word, 'Count': count, 'Frequency': frequency})\n",
    "\n",
    "        print(f'Concordance for the token \"{token}\" has been saved to {file_path}')\n",
    "\n",
    "def choose_directory(directories):\n",
    "    print(\"Select a directory for the stopwords csv file:\")\n",
    "    for i, directory in enumerate(directories):\n",
    "        print(f\"{i + 1}. {directory}\")\n",
    "    choice = int(input(\"Enter your choice: \"))\n",
    "    return directories[choice - 1]\n",
    "\n",
    "def read_stopwords(filepath):\n",
    "    with open(filepath, 'r', encoding='latin-1') as file:\n",
    "        reader = csv.reader(file)\n",
    "        stopwords = []\n",
    "        for row in reader:\n",
    "            for word in row:\n",
    "                stopwords.extend(word.split(','))\n",
    "        return [word.strip() for word in stopwords]\n",
    "\n",
    "# Example usage\n",
    "user_input = input(\"Enter words to find their concordance (separated by spaces): \").lower()\n",
    "tokens = [word.strip() for word in user_input.split(' ')]  # Split the input into a list of tokens\n",
    "\n",
    "# List subfolders and current directory\n",
    "directories = ['.'] + list_subfolders()\n",
    "selected_directory = choose_directory(directories)\n",
    "stopwords_files = find_csv_files(selected_directory)\n",
    "if stopwords_files:\n",
    "    chosen_stopwords_file = prompt_text_file(stopwords_files)\n",
    "    chosen_csv_file_path = os.path.join(selected_directory, chosen_stopwords_file)\n",
    "    stops = read_stopwords(chosen_csv_file_path)\n",
    "    search_concordance(text_data, tokens)\n",
    "else:\n",
    "    print(f\"No stopwords files found in '{selected_directory}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
