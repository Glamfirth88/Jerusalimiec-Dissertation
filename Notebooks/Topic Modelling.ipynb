{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "483a7fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-11 02:54:30--  http://mallet.cs.umass.edu/dist/mallet-2.0.8RC3.zip\n",
      "Resolving mallet.cs.umass.edu (mallet.cs.umass.edu)... 128.119.246.70\n",
      "Connecting to mallet.cs.umass.edu (mallet.cs.umass.edu)|128.119.246.70|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://mallet.cs.umass.edu/dist/mallet-2.0.8RC3.zip [following]\n",
      "--2025-06-11 02:54:30--  https://mallet.cs.umass.edu/dist/mallet-2.0.8RC3.zip\n",
      "Connecting to mallet.cs.umass.edu (mallet.cs.umass.edu)|128.119.246.70|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16179018 (15M) [application/zip]\n",
      "Saving to: ‘/home/codespace/mallet-2.0.8RC3.zip’\n",
      "\n",
      "/home/codespace/mal 100%[===================>]  15.43M  81.2MB/s    in 0.2s    \n",
      "\n",
      "2025-06-11 02:54:30 (81.2 MB/s) - ‘/home/codespace/mallet-2.0.8RC3.zip’ saved [16179018/16179018]\n",
      "\n",
      "Archive:  /home/codespace/mallet-2.0.8RC3.zip\n",
      "replace /home/codespace/mallet-2.0.8RC3/bin/classifier2info? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n",
      "mv: cannot move '/home/codespace/mallet-2.0.8RC3' to '/home/codespace/mallet-2.0.8/mallet-2.0.8RC3': Directory not empty\n",
      "Path to MALLET: /home/codespace/mallet-2.0.8/bin/mallet\n",
      "openjdk version \"21.0.6\" 2025-01-21 LTS\n",
      "OpenJDK Runtime Environment Microsoft-10800198 (build 21.0.6+7-LTS)\n",
      "OpenJDK 64-Bit Server VM Microsoft-10800198 (build 21.0.6+7-LTS, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "# Install MALLET 2.0.8RC3 from the official site\n",
    "!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8RC3.zip -O ~/mallet-2.0.8RC3.zip\n",
    "\n",
    "# Unzip MALLET\n",
    "!unzip ~/mallet-2.0.8RC3.zip -d ~/\n",
    "!rm ~/mallet-2.0.8RC3.zip\n",
    "\n",
    "# Rename the folder for convenience\n",
    "!mv ~/mallet-2.0.8RC3 ~/mallet-2.0.8\n",
    "\n",
    "# Define the path to the \"mallet\" binary\n",
    "import os\n",
    "mallet_dir = os.path.expanduser('~/mallet-2.0.8')\n",
    "path_to_mallet = os.path.join(mallet_dir, 'bin', 'mallet')\n",
    "print(f\"Path to MALLET: {path_to_mallet}\")\n",
    "\n",
    "# Optionally check Java version\n",
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0d4ef14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: little_mallet_wrapper in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.5.0)\n",
      "Requirement already satisfied: openpyxl in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install little_mallet_wrapper openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb7473b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select your stopwords CSV:\n",
      "1. lemmatized/stop_words.csv\n",
      "Select reference text directory:\n",
      "1. lemmatized/6TopicsB\n",
      "2. lemmatized\n",
      "Available files:\n",
      "1. Bodin_stemmed.txt\n",
      "2. L'Hospital_stemmed.txt\n",
      "Select target text directory:\n",
      "1. lemmatized/6TopicsB\n",
      "2. lemmatized\n",
      "Available files:\n",
      "1. Bodin_stemmed.txt\n",
      "2. L'Hospital_stemmed.txt\n",
      "[1/2] ⏳ Processing 'Bodin_stemmed.txt'... done in 308.3s – kept 35152/753572 tokens (4.7%).\n",
      "[2/2] ⏳ Processing 'L'Hospital_stemmed.txt'... done in 34.1s – kept 48753/263789 tokens (18.5%).\n",
      "[Done] Prepared 2 documents in 342.4s.\n",
      "\n",
      "Importing data...\n",
      "Complete\n",
      "Training topic model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mallet LDA: 6 topics, 3 topic bits, 111 topic mask\n",
      "Data loaded.\n",
      "max tokens: 48243\n",
      "total tokens: 82077\n",
      "<10> LL/token: -6.15306\n",
      "<20> LL/token: -6.03812\n",
      "<30> LL/token: -5.97885\n",
      "<40> LL/token: -5.94515\n",
      "\n",
      "0\t0.83333\tbien roy gard sag gen pouvoir siecl vent compaign francois obeyss côté désordr occas veoi rapport couraig passion déliber observ \n",
      "1\t0.83333\tchos fort republ corp part puissanc natur veu fois fin sorci jug form ame eau naturel magistrat fer populair animal \n",
      "2\t0.83333\tjustic roy homm estat réform caus party public vertu harangu temp royaum rend mémoir raison sort bon affair droit procès \n",
      "3\t0.83333\tfranc comt offic paix duc praticqu mal dur provinc jour procès pun raison disciplin vray effect assembl puiss duch royn \n",
      "4\t0.83333\tlun feu pierr magistrat grec aristot part chaud cóme grád chaleur execut fcienc orient neceflair general veniz entrel merit philofoph \n",
      "5\t0.83333\tbien roy bon justic don judg conseil honneur charg estat temp ordon injustic court sainct gen charl jour duc person \n",
      "\n",
      "<50> LL/token: -5.90934\n",
      "<60> LL/token: -5.89625\n",
      "<70> LL/token: -5.87534\n",
      "<80> LL/token: -5.86191\n",
      "<90> LL/token: -5.86514\n",
      "\n",
      "0\t0.83333\troy gard bien gen sag couron pouvoir siecl compaign vent francois advocat observ franc côté obeyss piet désordr occas dign \n",
      "1\t0.83333\tchos fort republ corp part puissanc natur veu fin magistrat fois sorci jug form ame eau naturel fer populair animal \n",
      "2\t0.83333\tjustic roy estat réform caus temp royaum comt raison party public procès vertu harangu sort rend affair lettr demeur homm \n",
      "3\t0.83333\tmal offic paix jour gen praticqu franc dur assembl duch just pun disciplin effect duc royn conven nation fruict provinc \n",
      "4\t0.83333\tgrec lun chos feu aristot mour part chaud general cóme grád efleu execut fcienc orient neceflair veniz avantag entrel fer \n",
      "5\t0.83333\tbien bon roy justic don judg homm conseil charg honneur ordon mémoir court duc droit injustic estat person vray sainct \n",
      "\n",
      "<100> LL/token: -5.8544\n",
      "<110> LL/token: -5.85287\n",
      "<120> LL/token: -5.83766\n",
      "<130> LL/token: -5.83826\n",
      "<140> LL/token: -5.83187\n",
      "\n",
      "0\t0.83333\troy gard bien sag couron pouvoir siecl vent francois observ obeyss piet désordr dign justic rang occas veoi auparav miser \n",
      "1\t0.83333\tchos fort republ part corp puissanc veu natur magistrat fin fois sorci jug form ame eau naturel fer populair animal \n",
      "2\t0.83333\troy estat justic temp réform caus comt royaum raison party homm public procès vertu harangu sort rend affair lettr demeur \n",
      "3\t0.83333\tmal gen offic paix praticqu assembl dur provinc duch besoing disciplin pun effect nécess royn conven nation fruict victoir lorsqu \n",
      "4\t0.83333\taristot lun grec feu chaud avantag merit mour cóme grád efleu execut fcienc orient neceflair veniz entrel philofoph voit fer \n",
      "5\t0.83333\tbien bon roy justic don judg homm conseil charg honneur duc ordon droit court franc jour mémoir injustic person vray \n",
      "\n",
      "<150> LL/token: -5.81903\n",
      "<160> LL/token: -5.81645\n",
      "<170> LL/token: -5.81212\n",
      "<180> LL/token: -5.80761\n",
      "<190> LL/token: -5.81121\n",
      "\n",
      "0\t0.83333\troy gard sag couron pouvoir sieur siecl vent francois observ faveur côté désordr dign rang occas royn veoi auparav miser \n",
      "1\t0.83333\tchos fort republ part corp puissanc veu natur magistrat fin fois sorci jug form ame eau naturel populair animal soleil \n",
      "2\t0.83333\tjustic estat réform caus roy temp homm royaum raison comt mémoir party public procès vertu harangu sort rend affair lettr \n",
      "3\t0.83333\tmal gen offic paix argent vray long praticqu assembl dur présen provinc duch demand estat besoing pun effect nécess mani \n",
      "4\t0.83333\tfer feu aristot grec lun chaud mour avantag merit grád efleu execut fcienc orient neceflair veniz entrel philofoph dif ainf \n",
      "5\t0.83333\tbien roy bon justic don judg conseil honneur charg duc ordon droit jour court franc injustic person sainct homm charl \n",
      "\n",
      "<200> LL/token: -5.81252\n",
      "[beta: 0.04087] \n",
      "<210> LL/token: -5.81144\n",
      "[beta: 0.05201] \n",
      "<220> LL/token: -5.8551\n",
      "[beta: 0.05715] \n",
      "<230> LL/token: -5.8827\n",
      "[beta: 0.05931] \n",
      "<240> LL/token: -5.89143\n",
      "\n",
      "0\t0.15759\tgard sag offici faveur pouvoir sieur vent duch couron francois siecl côté offic honor dign occas royn miser rapport couraig \n",
      "1\t0.22124\tchos fort republ part corp puissanc veu natur magistrat fin fois sorci jug form ame eau naturel populair animal soleil \n",
      "2\t0.19118\troy estat judg réform justic caus homm royaum raison party public procès temp vertu rend comt affair sort mémoir lettr \n",
      "3\t0.16249\tmal gen estat argent paix offic long vray dur présen provinc polic assembl demand pun disciplin effect nécess lev doivent \n",
      "4\t0.13869\tfer feu grec lun plant mour dif avantag merit grád confess efleu aristot execut fcienc orient neceflair esclav veniz entrel \n",
      "5\t0.20272\tbien roy bon justic don conseil honneur charg duc droit ordon jour court franc temp injustic person mémoir sainct ordre \n",
      "\n",
      "[beta: 0.06071] \n",
      "<250> LL/token: -5.89843\n",
      "[beta: 0.06181] \n",
      "<260> LL/token: -5.89979\n",
      "[beta: 0.06214] \n",
      "<270> LL/token: -5.89701\n",
      "[beta: 0.06418] \n",
      "<280> LL/token: -5.91109\n",
      "[beta: 0.0638] \n",
      "<290> LL/token: -5.90717\n",
      "\n",
      "0\t0.07648\tgard faveur afin sag offici siecl pouvoir nomm vent besoing sieur francois occas heureux royn serv auparav administr distribu ferm \n",
      "1\t0.09071\tchos fort republ part corp puissanc veu natur magistrat fin fois jug sorci form ame eau naturel populair animal soleil \n",
      "2\t0.08332\thomm estat roy justic réform caus judg royaum party public procès vertu temp rend raison comt harangu affair lettr religion \n",
      "3\t0.07751\tmal gen estat offic argent paix puiss raison praticqu assembl présen provinc polic demand personnaig bon dur lev disciplin quitt \n",
      "4\t0.07115\tfer grec lun chaud avantag merit grád efleu execut fcienc maisil orient veniz entrel dif philofoph lesautr orbe detest sais \n",
      "5\t0.08617\tbien roy bon justic don mémoir conseil honneur duc charg ordon droit jour temp court injustic sainct franc sort person \n",
      "\n",
      "[beta: 0.06488] \n",
      "<300> LL/token: -5.91109\n",
      "[beta: 0.06362] \n",
      "<310> LL/token: -5.90919\n",
      "[beta: 0.0645] \n",
      "<320> LL/token: -5.90365\n",
      "[beta: 0.06325] \n",
      "<330> LL/token: -5.88667\n",
      "[beta: 0.06333] \n",
      "<340> LL/token: -5.89757\n",
      "\n",
      "0\t0.06924\tgard sort sag faveur just charg façon priv siecl sieur nomm heureux violenc offens asseur nécess occas francois manier royn \n",
      "1\t0.07808\tchos fort republ part corp puissanc veu natur magistrat fin fois sorci jug form ame eau naturel fer populair animal \n",
      "2\t0.07324\thomm estat réform caus roy judg raison party public comt procès justic vertu charg rend gen temp demeur harangu propos \n",
      "3\t0.06993\tmal offic paix gen estat argent mémoir long assembl dur procureur présen conscienc demand majest praticqu envoi puiss personnaig besoing \n",
      "4\t0.06436\tgrec lun avantag grád orbe efleu execut fcienc maisil veniz entrel philofoph chaud neceflair leu fois tenu fort yeux lesautr \n",
      "5\t0.07527\troy bien justic bon don temp conseil honneur duc ordon droit mémoir franc court royaum person vray jour injustic judg \n",
      "\n",
      "[beta: 0.06465] \n",
      "<350> LL/token: -5.9028\n",
      "[beta: 0.06561] \n",
      "<360> LL/token: -5.9044\n",
      "[beta: 0.06532] \n",
      "<370> LL/token: -5.8918\n",
      "[beta: 0.06566] \n",
      "<380> LL/token: -5.88219\n",
      "[beta: 0.06578] \n",
      "<390> LL/token: -5.88437\n",
      "\n",
      "0\t0.06774\tgard faveur sag just façon priv asseur afin francois offens violenc nomm huict royn quitt integr mariaig ferm sien conscienc \n",
      "1\t0.07574\tchos fort republ part corp puissanc veu natur magistrat fin fois sorci jug form ame eau naturel fer populair animal \n",
      "2\t0.07124\testat homm justic judg réform comt charg caus raison vertu party public rend procès vérit gen affair demeur général religion \n",
      "3\t0.06827\tmal gen paix argent offic mémoir puiss bel caus praticqu procureur présen dur envoi content majest besoing pun personnaig sieur \n",
      "4\t0.06132\tgrec lun avantag grád orbe fcienc maisil veniz philofoph efleu lesautr souverainet auant def cognoiftr void mouv defens leu douc \n",
      "5\t0.07301\troy bien bon justic don temp royaum duc ordon conseil honneur droit jour franc mémoir court person vray sainct sort \n",
      "\n",
      "[beta: 0.06473] \n",
      "<400> LL/token: -5.87287\n",
      "[beta: 0.06655] \n",
      "<410> LL/token: -5.88199\n",
      "[beta: 0.06609] \n",
      "<420> LL/token: -5.87984\n",
      "[beta: 0.06656] \n",
      "<430> LL/token: -5.88352\n",
      "[beta: 0.06646] \n",
      "<440> LL/token: -5.8883\n",
      "\n",
      "0\t0.06729\tgard franc long faveur asseur conserv conscienc sag teneu nécessair général violenc longu rest huict sainct adviz manier nécess mariaig \n",
      "1\t0.07541\tchos fort republ part corp puissanc veu natur magistrat fin fois sorci jug form ame eau naturel fer populair animal \n",
      "2\t0.07103\testat homm réform judg caus comt raison justic party charg vertu procès rend injustic vérit affair public gen regard afin \n",
      "3\t0.06826\tmal mémoir offic gen paix bel offici puiss praticqu procureur présen argent volont dignit envoi crainct sieur content majest nomm \n",
      "4\t0.06043\tgrec grád orbe fcienc lun philofoph onque avantag mieux ila befoin diametr cost carl senateur fem lesautr proport veniz voulu \n",
      "5\t0.07259\troy bien justic bon temp don royaum conseil honneur duc ordon droit jour court vray harangu charl traict laiss ordre \n",
      "\n",
      "[beta: 0.06809] \n",
      "<450> LL/token: -5.88728\n",
      "[beta: 0.06883] \n",
      "<460> LL/token: -5.88211\n",
      "[beta: 0.06942] \n",
      "<470> LL/token: -5.87008\n",
      "[beta: 0.07077] \n",
      "<480> LL/token: -5.8769\n",
      "[beta: 0.07368] \n",
      "<490> LL/token: -5.88042\n",
      "\n",
      "0\t0.06707\tgard propos général vertu faveur long sag conscienc just conserv longu priv envoi teneu rest violenc conseil côté richess huict \n",
      "1\t0.07531\tchos fort republ part corp puissanc veu natur magistrat fin fois sorci jug form ame eau naturel fer populair animal \n",
      "2\t0.07099\testat homm judg réform caus comt raison justic party procès gen injustic charg person rend public affair sort bien vérit \n",
      "3\t0.06814\tmal mémoir paix bel puiss gen procureur consider présen pouvoir crainct sieur dur trent offic majest besoing plainct praticqu fortun \n",
      "4\t0.0562\t\n",
      "5\t0.07224\troy bien justic bon temp don royaum duc honneur droit jour ordon court conseil harangu franc vray sainct charl traict \n",
      "\n",
      "[beta: 0.07809] \n",
      "<500> LL/token: -5.86998\n",
      "[beta: 0.07938] \n",
      "<510> LL/token: -5.86867\n",
      "[beta: 0.08275] \n",
      "<520> LL/token: -5.87269\n",
      "[beta: 0.08379] \n",
      "<530> LL/token: -5.88202\n",
      "[beta: 0.08531] \n",
      "<540> LL/token: -5.89026\n",
      "\n",
      "0\t0.06196\tgard vertu sag empesch long conscienc guer assembl teneu priv rest faveur chambr huict conseil vérit longu compaign auparav integr \n",
      "1\t0.06872\tchos fort republ part corp puissanc veu natur magistrat fin fois sorci jug form ame eau naturel fer populair animal \n",
      "2\t0.06458\testat homm judg réform caus comt gen charg procès person raison offic rend sort injustic bien demeur affair religion hommag \n",
      "3\t0.06226\tmémoir mal paix bel puiss profict avaric présen raison consider sieur majest crainct nomm trent dignit général injustic plainct vénal \n",
      "4\t0\t\n",
      "5\t0.06625\troy bien justic bon temp don royaum honneur ordon duc droit jour court conseil party public vray sainct charl traict \n",
      "\n",
      "[beta: 0.08604] \n",
      "<550> LL/token: -5.8902\n",
      "[beta: 0.08435] \n",
      "<560> LL/token: -5.89102\n",
      "[beta: 0.08411] \n",
      "<570> LL/token: -5.8881\n",
      "[beta: 0.0846] \n",
      "<580> LL/token: -5.89261\n",
      "[beta: 0.08518] \n",
      "<590> LL/token: -5.90404\n",
      "\n",
      "0\t0.06145\tvertu gard bien royaum sag propos mal empesch long chanceli faveur chambr injur priv volont général conserv compaign siecl longu \n",
      "1\t0.06723\tchos fort republ part corp puissanc veu natur magistrat fin fois sorci jug form ame eau naturel fer populair animal \n",
      "2\t0.06311\testat homm caus réform judg comt gen charg procès injustic person raison offic franc affair demeur hommag couron sort tort \n",
      "3\t0.06125\tmémoir mal paix baill profict puiss avaric devoir gouvern mérit rich rend duc polic dignit bel majest nomm amy outraig \n",
      "4\t0\t\n",
      "5\t0.06477\troy justic bien bon temp don conseil honneur ordon droit jour court party public harangu judg duc vray charl royaum \n",
      "\n",
      "[beta: 0.08505] \n",
      "<600> LL/token: -5.90449\n",
      "[beta: 0.08266] \n",
      "<610> LL/token: -5.90123\n",
      "[beta: 0.08224] \n",
      "<620> LL/token: -5.89778\n",
      "[beta: 0.08329] \n",
      "<630> LL/token: -5.89812\n",
      "[beta: 0.08478] \n",
      "<640> LL/token: -5.90243\n",
      "\n",
      "0\t0.06136\tbien vertu gard sag assembl mal injur procureur long faveur façon vivr volont priv chanceli longu conserv grac plainct compaign \n",
      "1\t0.06704\tchos fort republ part corp puissanc veu natur magistrat fin fois sorci jug form ame eau naturel fer populair animal \n",
      "2\t0.06285\testat homm caus réform judg gen comt charg franc injustic person rend offic procès affair demeur just hommag couron tort \n",
      "3\t0.06111\traison mal paix devoir ordre gouvern compt baill consider veneu polic majest profict sieur observ obeyss asseur disciplin désordr richess \n",
      "4\t0\t\n",
      "5\t0.06467\troy justic bien bon temp don mémoir conseil honneur royaum duc ordon jour court droit party public sort vray sainct \n",
      "\n",
      "[beta: 0.08724] \n",
      "<650> LL/token: -5.90211\n",
      "[beta: 0.08644] \n",
      "<660> LL/token: -5.90452\n",
      "[beta: 0.08275] \n",
      "<670> LL/token: -5.90017\n",
      "[beta: 0.0852] \n",
      "<680> LL/token: -5.90341\n",
      "[beta: 0.0835] \n",
      "<690> LL/token: -5.89605\n",
      "\n",
      "0\t0.06086\tvertu gard traict royaum long procureur volont vivr conserv compaign général siecl longu pouvoir majest priv gaig vérit chanceli mal \n",
      "1\t0.067\tchos fort republ part corp puissanc veu natur magistrat fin fois sorci jug form ame eau naturel fer populair animal \n",
      "2\t0.06277\testat homm caus réform charg judg gen procès franc rend injustic offic person comt demeur royaum paris just propos hommag \n",
      "3\t0.06124\traison mal harangu paix faveur affair devoir mérit homm consider polic compt dignit gouvern crainct titr ordre plainct sieur vénal \n",
      "4\t0\t\n",
      "5\t0.06478\troy bien justic bon temp don mémoir conseil honneur duc ordon jour droit court party public sort sainct judg vray \n",
      "\n",
      "[beta: 0.08379] \n",
      "<700> LL/token: -5.89327\n",
      "[beta: 0.08523] \n",
      "<710> LL/token: -5.89889\n",
      "[beta: 0.08457] \n",
      "<720> LL/token: -5.89747\n",
      "[beta: 0.08566] \n",
      "<730> LL/token: -5.89849\n",
      "[beta: 0.08576] \n",
      "<740> LL/token: -5.90245\n",
      "\n",
      "0\t0.06098\tvertu gard traict jeun estim chambr procureur long pouvoir priv général conserv sieur injur majest assembl violenc amour compaign repos \n",
      "1\t0.06699\tchos fort republ part corp puissanc veu natur magistrat fin fois sorci jug form ame eau naturel fer populair animal \n",
      "2\t0.0624\testat judg caus gen charg réform franc procès injustic homm person rend offic comt sag hommag paris provinc rich façon \n",
      "3\t0.06147\tmal raison harangu affair conseil faveur profict empesch honneur mérit gouvern consider dignit crainct propos trent titr plainct vénal just \n",
      "4\t0\t\n",
      "5\t0.06484\troy bien justic bon temp don mémoir homm duc ordon droit jour court public party royaum sainct sort honneur vray \n",
      "\n",
      "[beta: 0.08674] \n",
      "<750> LL/token: -5.90202\n",
      "[beta: 0.08821] \n",
      "<760> LL/token: -5.91387\n",
      "[beta: 0.08672] \n",
      "<770> LL/token: -5.91206\n",
      "[beta: 0.08619] \n",
      "<780> LL/token: -5.90785\n",
      "[beta: 0.08637] \n",
      "<790> LL/token: -5.91388\n",
      "\n",
      "0\t0.061\ttraict harangu vertu ordre baill assembl devoir procureur jeun chambr priv conserv siecl majest pouvoir vent caus sieur rest amour \n",
      "1\t0.06699\tchos fort republ part corp puissanc veu natur magistrat fin fois sorci jug form ame eau naturel fer populair animal \n",
      "2\t0.06226\testat caus judg réform homm charg gen franc injustic procès rend comt sag propos paris hommag couron empesch gouvern guer \n",
      "3\t0.06162\tmal raison conseil affair faveur profict court person pauvr frer volont dignit crainct veneu façon trent heureux titr général corrupt \n",
      "4\t0\t\n",
      "5\t0.06484\troy bien justic bon temp don mémoir royaum honneur duc droit ordon jour party public homm sort sainct judg gard \n",
      "\n",
      "[beta: 0.0849] \n",
      "<800> LL/token: -5.89596\n",
      "[beta: 0.08414] \n",
      "<810> LL/token: -5.88989\n",
      "[beta: 0.08445] \n",
      "<820> LL/token: -5.89844\n",
      "[beta: 0.08482] \n",
      "<830> LL/token: -5.90334\n",
      "[beta: 0.08183] \n",
      "<840> LL/token: -5.89208\n",
      "\n",
      "0\t0.0613\tgard traict ordre harangu vertu baill religion devoir jeun conserv siecl priv assembl chambr vent roy regn pouvoir remonstr majest \n",
      "1\t0.06701\tchos fort republ part corp puissanc veu natur magistrat fin fois sorci jug form ame eau naturel fer populair animal \n",
      "2\t0.06216\thomm estat réform caus conseil gen comt franc procès injustic rend judg charg sag propos paris hommag estim couron empesch \n",
      "3\t0.06158\tmal court raison person charg affair demeur faveur profict général frer dur afin façon dignit justic sieur titr pun francois \n",
      "4\t0\t\n",
      "5\t0.06482\troy bien justic bon temp don mémoir royaum honneur duc ordon judg droit jour estat public vray party sainct offic \n",
      "\n",
      "[beta: 0.08145] \n",
      "<850> LL/token: -5.89336\n",
      "[beta: 0.08315] \n",
      "<860> LL/token: -5.89435\n",
      "[beta: 0.08286] \n",
      "<870> LL/token: -5.90869\n",
      "[beta: 0.08301] \n",
      "<880> LL/token: -5.90473\n",
      "[beta: 0.08312] \n",
      "<890> LL/token: -5.90213\n",
      "\n",
      "0\t0.06124\tvertu traict ordre party gen argent hommag devoir homm chambr priv majest siecl jeun trent pouvoir faveur advocat religion teneu \n",
      "1\t0.06703\tchos fort republ part corp puissanc veu natur magistrat fin fois sorci jug form ame eau naturel fer populair animal \n",
      "2\t0.06247\testat réform caus conseil harangu franc judg gen rend comt charg procès homm paris empesch estim bel tort guer volont \n",
      "3\t0.06162\tmal raison court injustic affair charg demeur pauvr général afin baill profict nécessair procès don compt provinc long façon dignit \n",
      "4\t0\t\n",
      "5\t0.06469\troy bien justic bon temp don mémoir homm honneur duc royaum judg droit jour public gard vray ordon sainct sort \n",
      "\n",
      "[beta: 0.08431] \n",
      "<900> LL/token: -5.90864\n",
      "[beta: 0.08591] \n",
      "<910> LL/token: -5.91164\n",
      "[beta: 0.08469] \n",
      "<920> LL/token: -5.8958\n",
      "[beta: 0.08684] \n",
      "<930> LL/token: -5.89916\n",
      "[beta: 0.08581] \n",
      "<940> LL/token: -5.90203\n",
      "\n",
      "0\t0.06107\tgen vertu traict ordre ordon présen chambr priv content heureux faveur asseur rest teneu majest conscienc disciplin viv just richess \n",
      "1\t0.06702\tchos fort republ part corp puissanc veu natur magistrat fin fois sorci jug form ame eau naturel fer populair animal \n",
      "2\t0.06231\testat réform caus conseil franc procès harangu charg rend comt sag estim frer nom gouvern couron gen rich églis tort \n",
      "3\t0.06172\tmal raison court injustic affair pauvr afin demeur baill général mauvais grac nécessair compt ruin envoi dignit sieur esper party \n",
      "4\t0\t\n",
      "5\t0.0648\troy bien justic bon homm temp judg don mémoir royaum honneur duc droit jour person sainct public vray comt gard \n",
      "\n",
      "[beta: 0.08648] \n",
      "<950> LL/token: -5.90145\n",
      "[beta: 0.08659] \n",
      "<960> LL/token: -5.9125\n",
      "[beta: 0.08454] \n",
      "<970> LL/token: -5.89632\n",
      "[beta: 0.08431] \n",
      "<980> LL/token: -5.90171\n",
      "[beta: 0.08293] \n",
      "<990> LL/token: -5.89557\n",
      "\n",
      "0\t0.06093\tgen ordon ordre traict vertu paris devoir jeun dur chambr priv author asseur titr teneu façon demand advocat corrupt viv \n",
      "1\t0.06701\tchos fort republ part corp puissanc veu natur magistrat fin fois sorci jug form ame eau naturel fer populair animal \n",
      "2\t0.06243\testat charg réform franc conseil harangu comt procès rend nom sag hommag roy estim couron empesch assembl tort mérit rich \n",
      "3\t0.06163\traison mal court injustic affair honneur afin demeur gard baill pauvr général grac mauvais public procureur compt vivr long esper \n",
      "4\t0\t\n",
      "5\t0.0648\troy bien justic bon judg homm temp caus don mémoir royaum estat duc jour droit party vray person sainct sort \n",
      "\n",
      "[beta: 0.085] \n",
      "<1000> LL/token: -5.89769\n",
      "\n",
      "Total time: 3 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n",
      "✅ Topic modeling pipeline completed successfully!\n",
      "ℹ️  No plots were generated. To create heatmaps or boxplots,\n",
      "    import and run plotting_helpers.generate_heatmap() or generate_boxplots().\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Integrated script for MALLET-based topic modeling with per-file Fisher’s Exact\n",
    "filtering and stopword exclusion. UTF-8 friendly.\n",
    "Outputs:\n",
    "  - Topic keys\n",
    "  - Per-document topic distributions\n",
    "  - Excel workbook with:\n",
    "      • Topic tokens\n",
    "      • Token counts per document\n",
    "      • Topic probabilities per document\n",
    "  - Separate Excel workbook with top-document titles per topic\n",
    "\n",
    "Graphical output (heatmap & boxplots) is disabled in this pipeline.\n",
    "See plotting_helpers.py for on-demand plotting.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import fisher_exact\n",
    "import little_mallet_wrapper\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "# Change this path to point to the local MALLET binary in the current directory.\n",
    "# For example, place the mallet-2.0.8 folder in the same directory as this script.\n",
    "# Then use os.path.join(...) relative to the current working directory (codespace).\n",
    "mallet_dir = os.path.expanduser('~/mallet-2.0.8')\n",
    "path_to_mallet = os.path.join(mallet_dir, 'bin', 'mallet')\n",
    "\n",
    "# These will be set by main() and picked up by plotting_helpers.py\n",
    "OUTPUT_DIR = None\n",
    "NUM_TOPICS = None\n",
    "\n",
    "def tokenize_file(filepath):\n",
    "    \"\"\"Load a UTF-8 text file and split on whitespace (preserves accents).\"\"\"\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read().split()\n",
    "\n",
    "def list_txt_files(directory):\n",
    "    \"\"\"Return a sorted list of all .txt filenames in a directory.\"\"\"\n",
    "    return sorted(fn for fn in os.listdir(directory) if fn.endswith(\".txt\"))\n",
    "\n",
    "def list_csv_files(directory):\n",
    "    \"\"\"\n",
    "    Recursively find all .csv files under a directory, skipping\n",
    "    any .ipynb_checkpoints folders.\n",
    "    \"\"\"\n",
    "    csv_paths = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if \".ipynb_checkpoints\" in dirs:\n",
    "            dirs.remove(\".ipynb_checkpoints\")\n",
    "        for fn in files:\n",
    "            if fn.lower().endswith(\".csv\"):\n",
    "                csv_paths.append(os.path.join(root, fn))\n",
    "    return csv_paths\n",
    "\n",
    "def choose_directory(prompt):\n",
    "    \"\"\"\n",
    "    Display a numbered list of immediate subdirectories (plus current dir)\n",
    "    and return the full path selected by the user.\n",
    "    \"\"\"\n",
    "    cwd = os.getcwd()\n",
    "    base = Path(cwd).name\n",
    "    subdirs = [\n",
    "        d for d in os.listdir(cwd)\n",
    "        if os.path.isdir(os.path.join(cwd, d)) and d != \".ipynb_checkpoints\"\n",
    "    ]\n",
    "    options = [(os.path.join(cwd, d), f\"{base}/{d}\") for d in subdirs]\n",
    "    options.append((cwd, base))\n",
    "\n",
    "    print(prompt)\n",
    "    for i, (_, label) in enumerate(options, start=1):\n",
    "        print(f\"{i}. {label}\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter number: \").strip())\n",
    "            if 1 <= choice <= len(options):\n",
    "                return options[choice - 1][0]\n",
    "        except ValueError:\n",
    "            pass\n",
    "        print(\"Invalid choice, please try again.\")\n",
    "\n",
    "def choose_files(filenames):\n",
    "    \"\"\"\n",
    "    Let user pick one or more filenames by:\n",
    "      - indices (\"2\" or \"1,3\")\n",
    "      - index ranges (\"1-4\")\n",
    "      - prefix matching (\"report\")\n",
    "      - or the keyword \"all\" to select every file.\n",
    "    Returns a sorted, unique list of chosen filenames.\n",
    "    \"\"\"\n",
    "    print(\"Available files:\")\n",
    "    for i, fn in enumerate(filenames, start=1):\n",
    "        print(f\"{i}. {fn}\")\n",
    "    choice = input(\"Select files (indices, ranges, prefix, or 'all'): \").strip().lower()\n",
    "\n",
    "    if choice == \"all\":\n",
    "        return filenames.copy()\n",
    "\n",
    "    selected = []\n",
    "    for part in choice.split(\",\"):\n",
    "        part = part.strip()\n",
    "        if part == \"all\":\n",
    "            return filenames.copy()\n",
    "        if \"-\" in part:\n",
    "            a, b = map(int, part.split(\"-\"))\n",
    "            selected.extend(filenames[a - 1:b])\n",
    "        elif part.isdigit():\n",
    "            selected.append(filenames[int(part) - 1])\n",
    "        else:\n",
    "            selected.extend(fn for fn in filenames if fn.startswith(part))\n",
    "    return sorted(set(selected))\n",
    "\n",
    "def choose_csv_file(csv_paths):\n",
    "    \"\"\"\n",
    "    Prompt the user to select one CSV from a list of paths.\n",
    "    Returns the chosen filepath.\n",
    "    \"\"\"\n",
    "    cwd = os.getcwd()\n",
    "    base = Path(cwd).name\n",
    "    print(\"Select your stopwords CSV:\")\n",
    "    for i, full in enumerate(csv_paths, start=1):\n",
    "        rel = os.path.relpath(full, cwd)\n",
    "        print(f\"{i}. {base}/{rel}\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter number: \").strip())\n",
    "            if 1 <= choice <= len(csv_paths):\n",
    "                return csv_paths[choice - 1]\n",
    "        except ValueError:\n",
    "            pass\n",
    "        print(\"Invalid choice, please try again.\")\n",
    "\n",
    "def read_stopwords(filepath):\n",
    "    \"\"\"Load stopwords from a CSV, splitting on commas and trimming whitespace.\"\"\"\n",
    "    sw = []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for row in csv.reader(f):\n",
    "            for cell in row:\n",
    "                sw.extend(cell.split(\",\"))\n",
    "    return [w.strip() for w in sw if w.strip()]\n",
    "\n",
    "def get_fishers(word, freq_dict, rate_dict, alternative=\"greater\"):\n",
    "    \"\"\"\n",
    "    Perform Fisher’s Exact Test on one token:\n",
    "        [[observed, total-observed],\n",
    "         [expected, total-expected]]\n",
    "    Returns the p-value.\n",
    "    \"\"\"\n",
    "    observed = freq_dict.get(word, 0)\n",
    "    total = sum(freq_dict.values())\n",
    "    expected = round(rate_dict.get(word, 0) * total)\n",
    "    table = [\n",
    "        [observed, total - observed],\n",
    "        [expected, total - expected]\n",
    "    ]\n",
    "    _, pval = fisher_exact(table, alternative=alternative)\n",
    "    return pval\n",
    "\n",
    "def calculate_rate_dictionary(rate_files, rate_dir):\n",
    "    \"\"\"\n",
    "    Build a background rate dictionary from reference documents.\n",
    "    Returns a mapping { token: relative_frequency }.\n",
    "    \"\"\"\n",
    "    counter = Counter()\n",
    "    total_tokens = 0\n",
    "    for fn in rate_files:\n",
    "        tokens = tokenize_file(os.path.join(rate_dir, fn))\n",
    "        counter.update(tokens)\n",
    "        total_tokens += len(tokens)\n",
    "    return {tok: cnt / total_tokens for tok, cnt in counter.items()}\n",
    "\n",
    "def prepare_training_data(files, directory, stopwords, rate_dict, alpha):\n",
    "    \"\"\"\n",
    "    For each file:\n",
    "      1. Tokenize and count every token.\n",
    "      2. Exclude stopwords and tokens with Fisher p-value ≥ alpha.\n",
    "      3. Collect filtered document text and raw token counts.\n",
    "    Prints per-file progress with elapsed time.\n",
    "    Returns:\n",
    "      - docs: list of filtered document strings for MALLET input\n",
    "      - distributions: list of Counter objects of raw token counts\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    distributions = []\n",
    "    total = len(files)\n",
    "    overall_start = time.time()\n",
    "\n",
    "    for idx, fn in enumerate(files, start=1):\n",
    "        file_start = time.time()\n",
    "        print(f\"[{idx}/{total}] ⏳ Processing '{fn}'... \", end=\"\", flush=True)\n",
    "\n",
    "        path = os.path.join(directory, fn)\n",
    "        tokens = tokenize_file(path)\n",
    "        freq = Counter(tokens)\n",
    "\n",
    "        filtered = [\n",
    "            w for w in tokens\n",
    "            if w not in stopwords and get_fishers(w, freq, rate_dict) < alpha\n",
    "        ]\n",
    "        docs.append(\" \".join(filtered))\n",
    "        distributions.append(freq)\n",
    "\n",
    "        elapsed = time.time() - file_start\n",
    "        kept = len(filtered)\n",
    "        before = len(tokens)\n",
    "        pct = (kept / before * 100) if before else 0\n",
    "        print(f\"done in {elapsed:.1f}s – kept {kept}/{before} tokens ({pct:.1f}%).\")\n",
    "\n",
    "    total_elapsed = time.time() - overall_start\n",
    "    print(f\"[Done] Prepared {total} documents in {total_elapsed:.1f}s.\\n\")\n",
    "    return docs, distributions\n",
    "\n",
    "def train_topic_model(training_docs, num_topics, output_dir):\n",
    "    \"\"\"\n",
    "    Train a MALLET model via little_mallet_wrapper\n",
    "    Returns:\n",
    "      - topics: list of token lists (topic keys)\n",
    "      - doc_topics: list of probability lists (per-document topic distributions)\n",
    "    \"\"\"\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Make sure MALLET is installed and that path_to_mallet points to the local file in the codespace.\n",
    "    little_mallet_wrapper.quick_train_topic_model(\n",
    "        path_to_mallet,\n",
    "        output_dir,\n",
    "        num_topics,\n",
    "        training_docs\n",
    "    )\n",
    "\n",
    "    key_file = os.path.join(output_dir, f\"mallet.topic_keys.{num_topics}\")\n",
    "    topics = little_mallet_wrapper.load_topic_keys(key_file)\n",
    "\n",
    "    dist_file = os.path.join(output_dir, f\"mallet.topic_distributions.{num_topics}\")\n",
    "    doc_topics = little_mallet_wrapper.load_topic_distributions(dist_file)\n",
    "\n",
    "    return topics, doc_topics\n",
    "\n",
    "def save_results_to_excel(excel_path, topics, token_distributions, doc_topics, files):\n",
    "    \"\"\"\n",
    "    Create an Excel workbook with:\n",
    "      1) 'Topics' sheet: one row per topic (Topic#, top tokens...)\n",
    "      2) One sheet per document: raw token counts (removing '_stemmed' suffix)\n",
    "      3) 'DocTopicDist' sheet: topic probabilities per document\n",
    "    \"\"\"\n",
    "    wb = Workbook()\n",
    "    ws0 = wb.active\n",
    "    ws0.title = \"Topics\"\n",
    "    for idx, topic in enumerate(topics):\n",
    "        ws0.append([f\"Topic {idx}\"] + topic)\n",
    "\n",
    "    for fn, dist in zip(files, token_distributions):\n",
    "        sheet_name = Path(fn).stem.replace(\"_stemmed\", \"\")\n",
    "        sheet = wb.create_sheet(title=sheet_name)\n",
    "        df = pd.DataFrame.from_dict(dist, orient=\"index\", columns=[\"count\"])\n",
    "        for row in dataframe_to_rows(df, index=True, header=True):\n",
    "            sheet.append(row)\n",
    "\n",
    "    ws3 = wb.create_sheet(title=\"DocTopicDist\")\n",
    "    header = [\"Document\"] + [f\"Topic{t}\" for t in range(len(topics))]\n",
    "    ws3.append(header)\n",
    "    for fn, probs in zip(files, doc_topics):\n",
    "        doc_name = Path(fn).stem.replace(\"_stemmed\", \"\")\n",
    "        ws3.append([doc_name] + [round(p, 4) for p in probs])\n",
    "\n",
    "    wb.save(excel_path)\n",
    "\n",
    "def save_top_titles_excel(xlsx_path, topics, training_docs, doc_topics, doc_titles, n_docs):\n",
    "    \"\"\"\n",
    "    Save the top n_docs document titles per topic into an Excel file,\n",
    "    one sheet per topic named 'Topic{#}', and remove the default blank sheet.\n",
    "    \"\"\"\n",
    "    wb = Workbook()\n",
    "    default_sheet = wb.active\n",
    "    wb.remove(default_sheet)\n",
    "\n",
    "    for t_idx in range(len(topics)):\n",
    "        ws = wb.create_sheet(title=f\"Topic{t_idx}\")\n",
    "        ws.append([\"Probability\", \"Document Title\"])\n",
    "        for prob, doc in little_mallet_wrapper.get_top_docs(\n",
    "            training_docs, doc_topics, t_idx, n=n_docs\n",
    "        ):\n",
    "            title = doc_titles.get(doc, Path(doc).stem)\n",
    "            ws.append([round(prob, 4), title])\n",
    "\n",
    "    wb.save(xlsx_path)\n",
    "\n",
    "def input_float(prompt, min_val=None, max_val=None):\n",
    "    \"\"\"Prompt until the user enters a valid float (and optionally within range).\"\"\"\n",
    "    while True:\n",
    "        resp = input(prompt).strip()\n",
    "        try:\n",
    "            val = float(resp)\n",
    "            if min_val is not None and val < min_val:\n",
    "                print(f\"Value must be at least {min_val}.\")\n",
    "                continue\n",
    "            if max_val is not None and val > max_val:\n",
    "                print(f\"Value must be at most {max_val}.\")\n",
    "                continue\n",
    "            return val\n",
    "        except ValueError:\n",
    "            print(\"Invalid input, please enter a valid number.\")\n",
    "\n",
    "def input_int(prompt, min_val=None, max_val=None):\n",
    "    \"\"\"Prompt until the user enters a valid integer (and optionally within range).\"\"\"\n",
    "    while True:\n",
    "        resp = input(prompt).strip()\n",
    "        try:\n",
    "            val = int(resp)\n",
    "            if min_val is not None and val < min_val:\n",
    "                print(f\"Value must be at least {min_val}.\")\n",
    "                continue\n",
    "            if max_val is not None and val > max_val:\n",
    "                print(f\"Value must be at most {max_val}.\")\n",
    "                continue\n",
    "            return val\n",
    "        except ValueError:\n",
    "            print(\"Invalid input, please enter a valid integer.\")\n",
    "\n",
    "def main():\n",
    "    global OUTPUT_DIR, NUM_TOPICS\n",
    "\n",
    "    # 1) Choose and load stopwords CSV\n",
    "    stop_csv = choose_csv_file(list_csv_files(os.getcwd()))\n",
    "    stopwords = read_stopwords(stop_csv)\n",
    "\n",
    "    # 2) Build background rate dictionary\n",
    "    rate_dir = choose_directory(\"Select reference text directory:\")\n",
    "    rate_files = choose_files(list_txt_files(rate_dir))\n",
    "    rate_dict = calculate_rate_dictionary(rate_files, rate_dir)\n",
    "\n",
    "    # 3) Select target files\n",
    "    target_dir = choose_directory(\"Select target text directory:\")\n",
    "    target_files = choose_files(list_txt_files(target_dir))\n",
    "\n",
    "    # 4) Fisher’s Exact threshold\n",
    "    alpha = input_float(\n",
    "        \"Enter Fisher’s Exact alpha threshold (e.g. 0.05): \",\n",
    "        min_val=0.0, max_val=1.0\n",
    "    )\n",
    "\n",
    "    # 5) Prepare filtered training data\n",
    "    training_docs, token_distributions = prepare_training_data(\n",
    "        target_files, target_dir, stopwords, rate_dict, alpha\n",
    "    )\n",
    "\n",
    "    # 6) Number of topics\n",
    "    num_topics = input_int(\"Enter number of topics to generate: \", min_val=1)\n",
    "\n",
    "    # 7) How many top documents per topic\n",
    "    n_top_docs = input_int(\"Enter number of top documents per topic: \", min_val=1)\n",
    "\n",
    "    # 8) Output folder\n",
    "    while True:\n",
    "        out_sub = input(\"Enter name for output folder: \").strip()\n",
    "        if out_sub:\n",
    "            break\n",
    "        print(\"Output folder name cannot be empty.\")\n",
    "    OUTPUT_DIR = os.path.join(os.getcwd(), out_sub)\n",
    "    NUM_TOPICS = num_topics\n",
    "    Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 9) Train model and load topic keys + doc-topic distributions\n",
    "    topics, doc_topics = train_topic_model(training_docs, NUM_TOPICS, OUTPUT_DIR)\n",
    "\n",
    "    # Save the list of processed files for plotting_helpers\n",
    "    fn_list_path = os.path.join(OUTPUT_DIR, \"input_filenames.txt\")\n",
    "    with open(fn_list_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for fn in target_files:\n",
    "            f.write(fn + \"\\n\")\n",
    "\n",
    "    # 10) Save combined results to Excel\n",
    "    excel_results = os.path.join(OUTPUT_DIR, \"topic_model_results.xlsx\")\n",
    "    save_results_to_excel(excel_results, topics, token_distributions, doc_topics, target_files)\n",
    "\n",
    "    # 11) Save top titles per topic to separate workbook\n",
    "    doc_titles = {doc: Path(fn).stem for doc, fn in zip(training_docs, target_files)}\n",
    "    top_titles_path = os.path.join(OUTPUT_DIR, \"top_titles.xlsx\")\n",
    "    save_top_titles_excel(\n",
    "        top_titles_path, topics, training_docs, doc_topics, doc_titles, n_top_docs\n",
    "    )\n",
    "\n",
    "    print(\"✅ Topic modeling pipeline completed successfully!\")\n",
    "    print(\"ℹ️  No plots were generated. To create heatmaps or boxplots,\")\n",
    "    print(\"    import and run plotting_helpers.generate_heatmap() or generate_boxplots().\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a91d7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 192\u001b[39m\n\u001b[32m    189\u001b[39m             generate_lmw_boxplots()\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 169\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    167\u001b[39m OUTPUT_DIR = os.path.abspath(output_dir_name)\n\u001b[32m    168\u001b[39m num_topics_str = \u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEnter the number of topics: \u001b[39m\u001b[33m\"\u001b[39m).strip()\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m NUM_TOPICS = \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_topics_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[38;5;66;03m# Prompt user to select which plots to generate\u001b[39;00m\n\u001b[32m    172\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSelect which plots to generate:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import little_mallet_wrapper\n",
    "\n",
    "# Defaults\n",
    "DEFAULT_DPI = 300\n",
    "DEFAULT_DIM_INCHES = (13, 9)  # (width in inches, height in inches)\n",
    "OUTPUT_DIR = None\n",
    "NUM_TOPICS = None\n",
    "\n",
    "def _load_model_results():\n",
    "    \"\"\"\n",
    "    Load topic keys, distributions, and filenames from the last pipeline run.\n",
    "    \"\"\"\n",
    "    if not OUTPUT_DIR or not NUM_TOPICS:\n",
    "        raise RuntimeError(\n",
    "            \"OUTPUT_DIR and NUM_TOPICS must be set at module level. \"\n",
    "            \"Define them before calling plotting functions.\"\n",
    "        )\n",
    "\n",
    "    key_file = os.path.join(OUTPUT_DIR, f\"mallet.topic_keys.{NUM_TOPICS}\")\n",
    "    dist_file = os.path.join(OUTPUT_DIR, f\"mallet.topic_distributions.{NUM_TOPICS}\")\n",
    "    topics = little_mallet_wrapper.load_topic_keys(key_file)\n",
    "    doc_topics = little_mallet_wrapper.load_topic_distributions(dist_file)\n",
    "\n",
    "    fn_list = os.path.join(OUTPUT_DIR, \"input_filenames.txt\")\n",
    "    with open(fn_list, \"r\", encoding=\"utf-8\") as f:\n",
    "        files = [line.strip() for line in f]\n",
    "\n",
    "    return files, topics, doc_topics\n",
    "\n",
    "def generate_heatmap():\n",
    "    \"\"\"\n",
    "    Prompt for a desired chart width in pixels, then generate and save a\n",
    "    topic-by-document heatmap. Exports only PDF + PNG.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        width_px = int(input(\"Enter heatmap width in pixels (e.g. 1600): \").strip())\n",
    "    except ValueError:\n",
    "        width_px = int(DEFAULT_DIM_INCHES[0] * DEFAULT_DPI)\n",
    "        print(f\"Invalid input, defaulting to {width_px} px width ({DEFAULT_DPI} DPI).\")\n",
    "\n",
    "    dpi_value = DEFAULT_DPI\n",
    "    aspect = DEFAULT_DIM_INCHES[1] / DEFAULT_DIM_INCHES[0]\n",
    "    height_px = int(width_px * aspect)\n",
    "    figsize = (width_px / dpi_value, height_px / dpi_value)\n",
    "\n",
    "    files, topics, doc_topics = _load_model_results()\n",
    "    labels = [Path(fn).stem for fn in files]\n",
    "\n",
    "    plt.close('all')\n",
    "    pdf_out = os.path.join(OUTPUT_DIR, \"categories_by_topics.pdf\")\n",
    "    fig = little_mallet_wrapper.plot_categories_by_topics_heatmap(\n",
    "        labels,\n",
    "        doc_topics,\n",
    "        topics,\n",
    "        pdf_out,\n",
    "        target_labels=labels,\n",
    "        dim=figsize\n",
    "    )\n",
    "\n",
    "    if fig is None:\n",
    "        fig = plt.gcf()\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Heatmap saved: {pdf_out}\")\n",
    "\n",
    "def generate_boxplot_grid():\n",
    "    \"\"\"\n",
    "    Prompt for a desired chart width in pixels, then draw a grid of boxplots\n",
    "    (one subplot per topic) and save as a single PDF + PNG.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        width_px = int(input(\"Enter boxplot-grid width in pixels (e.g. 1600): \").strip())\n",
    "    except ValueError:\n",
    "        width_px = int(DEFAULT_DIM_INCHES[0] * DEFAULT_DPI)\n",
    "        print(f\"Invalid input, defaulting to {width_px} px width ({DEFAULT_DPI} DPI).\")\n",
    "\n",
    "    dpi_value = DEFAULT_DPI\n",
    "    aspect = DEFAULT_DIM_INCHES[1] / DEFAULT_DIM_INCHES[0]\n",
    "    height_px = int(width_px * aspect)\n",
    "    figsize = (width_px / dpi_value, height_px / dpi_value)\n",
    "\n",
    "    files, topics, doc_topics = _load_model_results()\n",
    "    labels = [Path(fn).stem for fn in files]\n",
    "    n_topics = len(topics)\n",
    "\n",
    "    cols = 2\n",
    "    rows = (n_topics + cols - 1) // cols\n",
    "\n",
    "    plt.close('all')\n",
    "    fig, axes = plt.subplots(rows, cols,\n",
    "                             figsize=figsize,\n",
    "                             dpi=dpi_value,\n",
    "                             sharex=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for t_idx in range(n_topics):\n",
    "        ax = axes[t_idx]\n",
    "        data = [doc_topics[i][t_idx] for i in range(len(doc_topics))]\n",
    "        ax.boxplot(data, vert=False)\n",
    "        ax.set_title(f\"Topic {t_idx}\")\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    for ax in axes[n_topics:]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    png_path = os.path.join(OUTPUT_DIR, \"all_topic_boxplots.jpg\")\n",
    "    fig.savefig(png_path, dpi=dpi_value)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Boxplot grid saved: {png_path}\")\n",
    "\n",
    "def generate_lmw_boxplots():\n",
    "    \"\"\"\n",
    "    Prompt for a desired chart width in pixels, then generate and save\n",
    "    boxplots for each topic using lmw's plot_categories_by_topic_boxplots.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        width_px = int(input(\"Enter LMW boxplot width in pixels (e.g. 1600): \").strip())\n",
    "    except ValueError:\n",
    "        width_px = int(DEFAULT_DIM_INCHES[0] * DEFAULT_DPI)\n",
    "        print(f\"Invalid input, defaulting to {width_px} px width ({DEFAULT_DPI} DPI).\")\n",
    "\n",
    "    dpi_value = DEFAULT_DPI\n",
    "    aspect = DEFAULT_DIM_INCHES[1] / DEFAULT_DIM_INCHES[0]\n",
    "    height_px = int(width_px * aspect)\n",
    "    figsize = (width_px / dpi_value, height_px / dpi_value)\n",
    "\n",
    "    files, topics, doc_topics = _load_model_results()\n",
    "    labels = [Path(fn).stem for fn in files]\n",
    "    n_topics = len(topics)\n",
    "\n",
    "    plt.close('all')\n",
    "    out_paths = []\n",
    "    for topic_idx in range(n_topics):\n",
    "        out_path = os.path.join(\n",
    "            OUTPUT_DIR, f\"lmw_topic_boxplots_topic_{topic_idx}.pdf\"\n",
    "        )\n",
    "        fig = little_mallet_wrapper.plot_categories_by_topic_boxplots(\n",
    "            labels,\n",
    "            doc_topics,\n",
    "            topics,\n",
    "            topic_idx,  # <--- This is the missing argument!\n",
    "            output_path=out_path,\n",
    "            target_labels=None,\n",
    "            dim=figsize\n",
    "        )\n",
    "        if fig is None:\n",
    "            fig = plt.gcf()\n",
    "        fig.canvas.draw()\n",
    "        plt.close(fig)\n",
    "        out_paths.append(out_path)\n",
    "\n",
    "    print(f\"LMW boxplots saved: {', '.join(out_paths)}\")\n",
    "    \n",
    "def main():\n",
    "    global OUTPUT_DIR, NUM_TOPICS\n",
    "\n",
    "    # Prompt user for output directory and number of topics\n",
    "    output_dir_name = input(\"Enter the output folder name: \").strip()\n",
    "    OUTPUT_DIR = os.path.abspath(output_dir_name)\n",
    "    num_topics_str = input(\"Enter the number of topics: \").strip()\n",
    "    NUM_TOPICS = int(num_topics_str)\n",
    "\n",
    "    # Prompt user to select which plots to generate\n",
    "    print(\"Select which plots to generate:\")\n",
    "    print(\"1) Heatmap (PDF)\")\n",
    "    print(\"2) Boxplot grid (JPG)\")\n",
    "    print(\"3) LMW boxplots (PDF, label-based)\")\n",
    "    print(\"Type any combination of these numbers separated by commas (e.g. 1,2,3), or 'all' for all:\")\n",
    "    choice = input(\"Your choice: \").lower()\n",
    "\n",
    "    if \"all\" in choice:\n",
    "        generate_heatmap()\n",
    "        generate_boxplot_grid()\n",
    "        generate_lmw_boxplots()\n",
    "    else:\n",
    "        if '1' in choice:\n",
    "            generate_heatmap()\n",
    "        if '2' in choice:\n",
    "            generate_boxplot_grid()\n",
    "        if '3' in choice:\n",
    "            generate_lmw_boxplots()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7595d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a MALLET run folder that contains 'input_filenames.txt' and distributions files:\n",
      "[1] 6TopicsB\n",
      "[2] 6TopicsC\n",
      "\n",
      "Select indices for Group 1. Possible choices:\n",
      "[1] Bodin_stemmed.txt\n",
      "[2] L'Hospital_stemmed.txt\n",
      "\n",
      "Select indices for Group 2. Possible choices:\n",
      "[1] Bodin_stemmed.txt\n",
      "[2] L'Hospital_stemmed.txt\n",
      "\n",
      "Which file from Group 1 would you like to compare?\n",
      "[1] Bodin_stemmed.txt\n",
      "\n",
      "Selected file from Group 1: Bodin_stemmed.txt\n",
      "\n",
      "Ranking by similarity (ascending distance):\n",
      "1. L'Hospital_stemmed.txt (distance=0.3333)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def choose_mallet_run(prompt=\"Select a MALLET run folder that contains 'input_filenames.txt' and distributions files:\"):\n",
    "    \"\"\"\n",
    "    Let the user pick a subfolder containing 'input_filenames.txt'.\n",
    "    Returns the full path to that folder.\n",
    "    \"\"\"\n",
    "    cwd = os.getcwd()\n",
    "    subdirs = [\n",
    "        d for d in os.listdir(cwd)\n",
    "        if os.path.isdir(os.path.join(cwd, d)) and d != \".ipynb_checkpoints\"\n",
    "    ]\n",
    "    if not subdirs:\n",
    "        print(\"No subfolders found.\")\n",
    "        return cwd\n",
    "\n",
    "    print(prompt)\n",
    "    for i, fn in enumerate(subdirs, start=1):\n",
    "        print(f\"[{i}] {fn}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter number: \").strip())\n",
    "            if 1 <= choice <= len(subdirs):\n",
    "                return os.path.join(cwd, subdirs[choice - 1])\n",
    "        except ValueError:\n",
    "            pass\n",
    "        print(\"Invalid choice, please try again.\")\n",
    "\n",
    "def load_model_data(run_dir, num_topics):\n",
    "    \"\"\"\n",
    "    Load the file list (input_filenames.txt) and the doc-topic distributions\n",
    "    for the specified number of topics from 'run_dir'.\n",
    "    Ensures that the order of files matches how they were used in modeling.\n",
    "    \"\"\"\n",
    "    fn_list_path = os.path.join(run_dir, \"input_filenames.txt\")\n",
    "    if not os.path.exists(fn_list_path):\n",
    "        raise FileNotFoundError(f\"'input_filenames.txt' not found in {run_dir}.\")\n",
    "\n",
    "    with open(fn_list_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        files = [line.strip() for line in f]\n",
    "\n",
    "    dist_file = os.path.join(run_dir, f\"mallet.topic_distributions.{num_topics}\")\n",
    "    if not os.path.exists(dist_file):\n",
    "        raise FileNotFoundError(f\"No doc-topic distribution file for {num_topics} topics in {run_dir}.\")\n",
    "\n",
    "    import little_mallet_wrapper\n",
    "    doc_topics = little_mallet_wrapper.load_topic_distributions(dist_file)\n",
    "    return files, doc_topics\n",
    "\n",
    "def select_indices_in_files(file_list, group_name):\n",
    "    \"\"\"\n",
    "    Prompt the user to pick indices or 'all' for the specified group_name.\n",
    "    Returns a list of chosen indices in ascending order.\n",
    "    \"\"\"\n",
    "    print(f\"\\nSelect indices for {group_name}. Possible choices:\")\n",
    "    for i, f in enumerate(file_list, start=1):\n",
    "        print(f\"[{i}] {f}\")\n",
    "    user_input = input(f\"Enter comma-separated indices or 'all' for {group_name}: \").strip()\n",
    "    if user_input.lower() == \"all\":\n",
    "        return list(range(len(file_list)))\n",
    "\n",
    "    chosen = []\n",
    "    for part in user_input.split(\",\"):\n",
    "        part = part.strip()\n",
    "        if \"-\" in part:\n",
    "            start, end = map(int, part.split(\"-\"))\n",
    "            chosen.extend(range(start - 1, end))\n",
    "        else:\n",
    "            chosen.append(int(part) - 1)\n",
    "    return sorted(set(chosen))\n",
    "\n",
    "def average_topic_distance(dist_a, dist_b):\n",
    "    \"\"\"\n",
    "    Calculate the average distance between two topic distributions\n",
    "    by summing absolute differences and dividing by the number of topics.\n",
    "    \"\"\"\n",
    "    return sum(abs(a - b) for a, b in zip(dist_a, dist_b)) / len(dist_a)\n",
    "\n",
    "def compare_two_groups(files, doc_topics):\n",
    "    \"\"\"\n",
    "    1) Divide files into two groups, picking indices from 'files'.\n",
    "    2) Select one file from Group 1.\n",
    "    3) Compare to every file in Group 2 and rank by average topic distance.\n",
    "    \"\"\"\n",
    "    # 1) Split into two groups\n",
    "    group1_indices = select_indices_in_files(files, \"Group 1\")\n",
    "    group2_indices = select_indices_in_files(files, \"Group 2\")\n",
    "\n",
    "    # 2) Pick one file from Group 1\n",
    "    print(\"\\nWhich file from Group 1 would you like to compare?\")\n",
    "    for i, idx in enumerate(group1_indices, start=1):\n",
    "        print(f\"[{i}] {files[idx]}\")\n",
    "    choice = int(input(\"Enter the number: \")) - 1\n",
    "    chosen_idx = group1_indices[choice]\n",
    "\n",
    "    chosen_dist = doc_topics[chosen_idx]\n",
    "    print(f\"\\nSelected file from Group 1: {files[chosen_idx]}\")\n",
    "\n",
    "    # 3) For each file in Group 2, compute average topic distance, then sort\n",
    "    distances = []\n",
    "    for idx in group2_indices:\n",
    "        dist = average_topic_distance(chosen_dist, doc_topics[idx])\n",
    "        distances.append((files[idx], dist))\n",
    "\n",
    "    # Sort by ascending distance (most similar = smallest distance)\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "\n",
    "    print(\"\\nRanking by similarity (ascending distance):\")\n",
    "    for rank, (fname, distval) in enumerate(distances, start=1):\n",
    "        print(f\"{rank}. {fname} (distance={distval:.4f})\")\n",
    "\n",
    "def start_comparison():\n",
    "    \"\"\"\n",
    "    Guide the user to pick a MALLET run folder, specify the number of topics,\n",
    "    then load files and doc_topic distributions and compare two groups.\n",
    "    \"\"\"\n",
    "    run_dir = choose_mallet_run()\n",
    "    num_topics = int(input(\"Enter the number of topics used for that run: \").strip())\n",
    "    files, doc_topics = load_model_data(run_dir, num_topics)\n",
    "    compare_two_groups(files, doc_topics)\n",
    "\n",
    "start_comparison()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
