{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54bf6974-56fe-490b-9b06-61bd6634a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize,wordpunct_tokenize\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures, TrigramCollocationFinder, TrigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d91501f-4ea8-4a51-80e4-5b2c3d87f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/lucas-jerusalimiec/Documents/OCR Text/Notebooks\")\n",
    "from tokenizer_func  import (wordcleaner, write_words_to_file, dictionary_to_file, convert_tuple_bigrams,\n",
    "convert_tuple_trigrams)\n",
    "\n",
    "from extra_token_func import print_first_n_items, remove_keys_from_nested_dict\n",
    "\n",
    "from additional_token_func import convert_strings_to_counts\n",
    "\n",
    "from dict_write import write_dict_to_files_with_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d557ac9-168b-4b35-ac00-28687dd85cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tokenized/\n",
      "Text files in the spellchecked directory: ['final/République_corrected.txt']\n"
     ]
    }
   ],
   "source": [
    "text_loc = Path(\"./final\")\n",
    "text_files = glob.glob(f\"{text_loc}/*.txt\")\n",
    "output_folder = './tokenized/'\n",
    "tokenized_folder = Path(output_folder)\n",
    "tokenized_folder.mkdir(exist_ok=True)\n",
    "print(output_folder)\n",
    "print(\"Text files in the spellchecked directory:\", text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa6226b-1236-4eb7-b4b3-7b8c79c0a6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ie', 'fc', 'del', 'o', 'dé', 'dela', 'ay', 'w', 'iij', 'enl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open stopwords CSV file and list the contents\n",
    "with open('./stop_words.csv', 'r') as f:\n",
    "    stopwords = f.read().strip().split(\",\")\n",
    "stopwords[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b085009a-d824-4bf2-aedc-fd567abf2dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw texts: ['République_corrected']\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = {}\n",
    "for txt in text_files:\n",
    "    with open(txt, 'r') as f:\n",
    "        content = f.read()\n",
    "        file_name = txt.split('\\\\')[-1]\n",
    "        #key = file_name.split('.')[0]\n",
    "        key = os.path.splitext(os.path.basename(file_name))[0]\n",
    "        tokenized_texts[key] = content\n",
    "print(\"Raw texts:\", list(tokenized_texts.keys()))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f8cc71e-5849-4195-8b5c-585cc06d2916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved content for 'République_corrected' to ./tokenized/République_corrected.txt\n"
     ]
    }
   ],
   "source": [
    "unigrams = {}\n",
    "\n",
    "for key, value in tokenized_texts.items():\n",
    "    unigram_list = wordpunct_tokenize(value)\n",
    "    cleanwords = [wordcleaner(w) for w in unigram_list]\n",
    "    unigrams[key] = cleanwords\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    filename = f\"./tokenized/{key}.txt\"\n",
    "    write_words_to_file(value, filename, words_per_line=20)\n",
    "    print(f\"Saved content for '{key}' to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d044c3f8-9aab-4362-8b85-a3709e228a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram texts:\n",
      "République_corrected\n"
     ]
    }
   ],
   "source": [
    "print(\"Unigram texts:\")\n",
    "for key in unigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51492bb5-b662-4e41-bf0d-35e2bd3e3e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Counts:\n",
      "République_corrected\n",
      "First 25 items in République_corrected:\n",
      ": 110281\n",
      "de: 13322\n",
      "les: 7127\n",
      "la: 6794\n",
      "que: 6167\n",
      "en: 5978\n",
      "il: 4959\n",
      "d: 4959\n",
      "qui: 4934\n",
      "l: 4929\n",
      "le: 4928\n",
      "qu: 4723\n",
      "des: 4337\n",
      "à: 4133\n",
      "eft: 3062\n",
      "n: 2867\n",
      "pour: 2771\n",
      "du: 2747\n",
      "par: 2453\n",
      "ne: 2368\n",
      "au: 2331\n",
      "plus: 2294\n",
      "ce: 2109\n",
      "ou: 1971\n",
      "vn: 1932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count up the tokens using a Counter() object\n",
    "unigram_counts = {}\n",
    "for key, value in unigrams.items():\n",
    "    unigram_counts_dict = Counter(value)\n",
    "    unigram_counts[key] = unigram_counts_dict\n",
    "\n",
    "print(\"Unigram Counts:\")\n",
    "for key in unigram_counts:\n",
    "    print(key)\n",
    "\n",
    "print_first_n_items(unigram_counts, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1300638a-16da-4c7f-8e9c-1de304b45009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 items in République_corrected:\n",
      "plus: 2294\n",
      "comme: 1521\n",
      "roy: 1372\n",
      "bien: 1333\n",
      "peuple: 895\n",
      "dit: 831\n",
      "eftat: 829\n",
      "peut: 803\n",
      "prince: 790\n",
      "fait: 753\n",
      "faire: 747\n",
      "autres: 739\n",
      "fans: 719\n",
      "point: 711\n",
      "auffi: 658\n",
      "tous: 621\n",
      "tout: 616\n",
      "autre: 616\n",
      "foit: 583\n",
      "fugets: 579\n",
      "deux: 557\n",
      "princes: 545\n",
      "fes: 532\n",
      "apres: 509\n",
      "republique: 503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove specified keys from the dictionary\n",
    "stripped_unigrams = remove_keys_from_nested_dict(unigram_counts, stopwords)\n",
    "\n",
    "print_first_n_items(stripped_unigrams, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2d63ded-ea90-4894-af13-c8373b235afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved République_corrected_unigram_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(stripped_unigrams, output_folder, 'unigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d6661b6-baf5-47d8-a58b-49bfedc0a32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams:\n",
      "République_corrected\n"
     ]
    }
   ],
   "source": [
    "bigrams = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    #unigram_list = [word for word in value]\n",
    "    bigrams_list = list(nltk.bigrams(unigram_list))\n",
    "    bigrams[key] = bigrams_list\n",
    "\n",
    "print(\"Bigrams:\")\n",
    "for key in bigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24b278bb-d5b9-436c-8a31-3d626532ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Counts:\n",
      "République_corrected\n",
      "First 30 items in République_corrected:\n",
      "eftat populaire: 163\n",
      "comme dit: 132\n",
      "prince fouuerain: 98\n",
      "plus grand: 90\n",
      "plus grands: 90\n",
      "roy france: 86\n",
      "cy deffus: 83\n",
      "peut faire: 80\n",
      "menu peuple: 80\n",
      "peut voir: 77\n",
      "livre premier: 71\n",
      "ains auffi: 70\n",
      "peut dire: 69\n",
      "bien fouuent: 68\n",
      "tout ainfi: 63\n",
      "beaucoup plus: 63\n",
      "fes fugets: 61\n",
      "non feulement: 59\n",
      "non plus: 58\n",
      "comme fift: 58\n",
      "corps colleges: 56\n",
      "peu peu: 55\n",
      "plus grande: 53\n",
      "quele roy: 50\n",
      "foy hommage: 49\n",
      "cens mil: 48\n",
      "deux cens: 47\n",
      "livre sixiesme: 47\n",
      "comme peut: 46\n",
      "autres princes: 45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bigram_counts = {}\n",
    "\n",
    "for key, value in bigrams.items():\n",
    "    string_bigrams = convert_tuple_bigrams(value)\n",
    "    bigramCount = convert_strings_to_counts(string_bigrams)\n",
    "    bigram_counts[key] = bigramCount\n",
    "\n",
    "print(\"Bigram Counts:\")\n",
    "for key in bigram_counts:\n",
    "    print(key)\n",
    "\n",
    "print_first_n_items(bigram_counts, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c4eb003-3c3c-4d9e-b5e9-1979bd1a3fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved République_corrected_bigram_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(bigram_counts, output_folder, 'bigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfe978cd-c9e2-46c6-9c37-fbb524fbbd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigrams:\n",
      "République_corrected\n"
     ]
    }
   ],
   "source": [
    "trigrams = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    #unigram_list = [word for word in value]\n",
    "    trigrams_list = list(nltk.trigrams(unigram_list))\n",
    "    trigrams[key] = trigrams_list\n",
    "\n",
    "print(\"Trigrams:\")\n",
    "for key in bigrams:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b2a5667-7557-49d9-9904-184526684891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram Counts:\n",
      "République_corrected\n",
      "First 30 items in République_corrected:\n",
      "comme peut voir: 33\n",
      "dit cy deffus: 24\n",
      "monftré cy deffus: 21\n",
      "dit tite liue: 18\n",
      "tire apres foy: 17\n",
      "comme auons dit: 14\n",
      "comme cas pareil: 13\n",
      "cens mil efcus: 13\n",
      "cens mil liures: 13\n",
      "auons monftré cy: 13\n",
      "mil cinq cens: 13\n",
      "fept cens ans: 11\n",
      "comme dit plutarque: 10\n",
      "quatre cens mil: 10\n",
      "plus grand nombre: 10\n",
      "trois hautes planettes: 10\n",
      "quel eftat populaire: 9\n",
      "quelque forte foit: 8\n",
      "feditions guerres ciuiles: 8\n",
      "loüys roy france: 8\n",
      "foy hommage lige: 8\n",
      "tant foit peu: 7\n",
      "plus haut point: 7\n",
      "ferons mefme iugement: 7\n",
      "ainfi peut voir: 7\n",
      "traité fait entre: 7\n",
      "fans aller plus: 7\n",
      "deux cens mil: 7\n",
      "deux cens ans: 7\n",
      "trois cens mil: 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trigram_counts = {}\n",
    "\n",
    "for key, value in trigrams.items():\n",
    "    string_trigrams = convert_tuple_trigrams(value)\n",
    "    trigramCount = convert_strings_to_counts(string_trigrams)\n",
    "    trigram_counts[key] = trigramCount\n",
    "\n",
    "print(\"Trigram Counts:\")\n",
    "for key in trigram_counts:\n",
    "    print(key)\n",
    "    \n",
    "print_first_n_items(trigram_counts, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d36ad6c4-4f5b-4d15-b463-25318d4095b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved République_corrected_trigram_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "dictionary_to_file(trigram_counts, output_folder, 'trigram_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58fd2be9-d9ed-4c35-b058-5a1f944e992a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collocations:\n",
      "République_corrected\n",
      "Collocation Counts:\n",
      "République_corrected\n",
      "tite liue 45\n",
      "guerres ciuiles 43\n",
      "lettres patentes 25\n",
      "deflors auant 18\n",
      "grecs latins 16\n",
      "marc antoine 16\n",
      "hautes planettes 16\n",
      "voix deliberatiue 15\n",
      "philippe valois 14\n",
      "dira quelqu 13\n",
      "proportion geometrique 13\n",
      "marc varron 11\n",
      "offenfiue defenfiue 11\n",
      "chambre comptes 11\n",
      "places fortes 10\n",
      "naples sicile 10\n",
      "leon afrique 10\n",
      "di ateur 10\n",
      "difcipline militaire 10\n",
      "cours fouueraines 9\n",
      "attaint conuaincu 9\n",
      "caton cenfeur 8\n",
      "thomas more 8\n",
      "diuines humaines 8\n",
      "nom collectif 8\n",
      "prefenter requefte 8\n",
      "venir bout 8\n",
      "scipion africain 7\n",
      "bonnes meurs 7\n",
      "don ner 7\n",
      "\n",
      "Saved République_corrected_collocation_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "colloc_dict = {}\n",
    "colloc_counts = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    bigram_finder = BigramCollocationFinder.from_words(unigram_list)\n",
    "    bigram_finder.apply_freq_filter(3)  # Make sure all collocations have occurred at least 5 times\n",
    "    collocations = bigram_finder.nbest(BigramAssocMeasures.pmi, 500)\n",
    "    colloc_dict[key] = collocations\n",
    "    \n",
    "    # Initialize Counter for colloc_counts\n",
    "    bigram_count_dict = Counter()\n",
    "\n",
    "    # Count the occurrences of each bigram in the text\n",
    "    bigram_finder = BigramCollocationFinder.from_words(unigram_list)\n",
    "    bigram_freqs = bigram_finder.ngram_fd.items()\n",
    "    \n",
    "    # Filter bigram counts based on collocations\n",
    "    for bigram, count in bigram_freqs:\n",
    "        if bigram in collocations:\n",
    "            bigram_count_dict[bigram] = count\n",
    "\n",
    "    colloc_counts[key] = bigram_count_dict\n",
    "\n",
    "print(\"Collocations:\")\n",
    "for key, value in colloc_dict.items():\n",
    "    print(key)\n",
    "    # for w1, w2 in value:\n",
    "    #     print(' ', w1, w2)\n",
    "\n",
    "print(\"Collocation Counts:\")\n",
    "for key in colloc_counts:\n",
    "    print(key)\n",
    "    # Print first n items, assuming print_first_n_items function is defined elsewhere\n",
    "    for item, count in colloc_counts[key].most_common(30):\n",
    "        bigram = \" \".join(item)\n",
    "        print(f\"{bigram} {count}\")\n",
    "    print()\n",
    "\n",
    "dictionary_to_file(colloc_counts, output_folder, 'collocation_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4f5f4c8-a3e2-4e10-9a2f-b3369eced597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram Collocations:\n",
      "République_corrected\n",
      "Trigram Collocation Counts:\n",
      "République_corrected\n",
      "comme peut voir 33\n",
      "dit cy deffus 24\n",
      "monftré cy deffus 21\n",
      "dit tite liue 18\n",
      "tire apres foy 17\n",
      "comme auons dit 14\n",
      "comme cas pareil 13\n",
      "cens mil efcus 13\n",
      "cens mil liures 13\n",
      "auons monftré cy 13\n",
      "mil cinq cens 13\n",
      "fept cens ans 11\n",
      "comme dit plutarque 10\n",
      "quatre cens mil 10\n",
      "plus grand nombre 10\n",
      "trois hautes planettes 10\n",
      "quel eftat populaire 9\n",
      "quelque forte foit 8\n",
      "feditions guerres ciuiles 8\n",
      "loüys roy france 8\n",
      "foy hommage lige 8\n",
      "tant foit peu 7\n",
      "plus haut point 7\n",
      "ferons mefme iugement 7\n",
      "ainfi peut voir 7\n",
      "traité fait entre 7\n",
      "fans aller plus 7\n",
      "deux cens mil 7\n",
      "deux cens ans 7\n",
      "trois cens mil 7\n",
      "\n",
      "Saved République_corrected_trigram_collocation_counts.csv in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "trigram_colloc_dict = {}\n",
    "trigram_colloc_counts = {}\n",
    "\n",
    "for key, value in unigrams.items():\n",
    "    unigram_list = [word for word in value if word.lower() not in stopwords]\n",
    "    trigram_finder = TrigramCollocationFinder.from_words(unigram_list)\n",
    "    trigram_finder.apply_freq_filter(3)  # Ensure all collocations have occurred at least 5 times\n",
    "    collocations = trigram_finder.nbest(TrigramAssocMeasures.pmi, 500)\n",
    "    trigram_colloc_dict[key] = collocations\n",
    "    \n",
    "    # Initialize Counter for trigram_colloc_counts\n",
    "    trigram_count_dict = Counter()\n",
    "\n",
    "    # Count the occurrences of each trigram in the text\n",
    "    trigram_freqs = trigram_finder.ngram_fd.items()\n",
    "    \n",
    "    # Filter trigram counts based on collocations\n",
    "    for trigram, count in trigram_freqs:\n",
    "        if trigram in collocations:\n",
    "            trigram_count_dict[trigram] = count\n",
    "\n",
    "    trigram_colloc_counts[key] = trigram_count_dict\n",
    "\n",
    "print(\"Trigram Collocations:\")\n",
    "for key, value in trigram_colloc_dict.items():\n",
    "    print(key)\n",
    "    #for w1, w2, w3 in value:\n",
    "    #    print(' ', w1, w2, w3)\n",
    "\n",
    "print(\"Trigram Collocation Counts:\")\n",
    "for key in trigram_colloc_counts:\n",
    "    print(key)\n",
    "    # Print first n items, assuming print_first_n_items function is defined elsewhere\n",
    "    for item, count in trigram_colloc_counts[key].most_common(30):\n",
    "        trigram = \" \".join(item)\n",
    "        print(f\"{trigram} {count}\")\n",
    "    print()\n",
    "\n",
    "dictionary_to_file(trigram_colloc_counts, output_folder, 'trigram_collocation_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b890221-5827-4d01-a9ab-9726fde00e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underscore Dictionary:\n",
      "République_corrected\n",
      "République_corrected_underscore_bigrams.txt in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "underscore_dict = {}\n",
    "for key, value in unigrams.items():\n",
    "\n",
    "    tokenized_words = unigrams.get(key)\n",
    "    collocations = colloc_dict.get(key)\n",
    "    \n",
    "    colloc_words = []\n",
    "    \n",
    "    # Iterate through the words making new versions combining collocations\n",
    "    i = 0\n",
    "    while i < len(tokenized_words) - 1:\n",
    "        # If we find a collocation, add and advance by two words\n",
    "        if (tokenized_words[i], tokenized_words[i + 1]) in collocations:\n",
    "            colloc_words.append('_'.join((tokenized_words[i], tokenized_words[i + 1])))\n",
    "            i += 2\n",
    "        # Otherwise, advance by one word\n",
    "        else:\n",
    "            colloc_words.append(tokenized_words[i])\n",
    "            i += 1\n",
    "\n",
    "    # Add the last word (if any)\n",
    "    if i == len(tokenized_words) - 1:\n",
    "        colloc_words.append(tokenized_words[i])\n",
    "    underscore_dict[key] = colloc_words\n",
    "\n",
    "print(\"Underscore Dictionary:\")\n",
    "for key in underscore_dict:\n",
    "    print(key)\n",
    "\n",
    "write_dict_to_files_with_suffix(underscore_dict, output_folder, 'underscore_bigrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f0b3b4c-c6df-4bdf-84c2-fb152e0b68e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram underscore Dictionary:\n",
      "République_corrected\n",
      "République_corrected_underscore_trigrams.txt in ./tokenized/\n"
     ]
    }
   ],
   "source": [
    "trigram_underscore_dict = {}\n",
    "\n",
    "for key, tokenized_words in unigrams.items():\n",
    "    collocations = trigram_colloc_dict.get(key, [])\n",
    "    colloc_words = []\n",
    "    i = 0\n",
    "    while i < len(tokenized_words) - 2:\n",
    "        # If we find a trigram collocation, add and advance by three words\n",
    "        trigram = (tokenized_words[i], tokenized_words[i + 1], tokenized_words[i + 2])\n",
    "        if trigram in collocations:\n",
    "            colloc_words.append('_'.join(trigram))\n",
    "            i += 3\n",
    "        else:\n",
    "            colloc_words.append(tokenized_words[i])\n",
    "            i += 1\n",
    "    # Add the last words (if any)\n",
    "    while i < len(tokenized_words):\n",
    "        colloc_words.append(tokenized_words[i])\n",
    "        i += 1\n",
    "    trigram_underscore_dict[key] = colloc_words\n",
    "\n",
    "print(\"Trigram underscore Dictionary:\")\n",
    "for key in trigram_underscore_dict:\n",
    "    print(key)\n",
    "\n",
    "write_dict_to_files_with_suffix(trigram_underscore_dict, output_folder, 'underscore_trigrams')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
