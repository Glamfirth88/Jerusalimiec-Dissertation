{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af8ff0ef-2f70-485a-a86e-91aa4ebeca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dfe3392-8fdb-46c5-b153-c6757e0de887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arabic', 'azerbaijani', 'basque', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'turkish']\n"
     ]
    }
   ],
   "source": [
    "# Creating a stop_words list from the NLTK.\n",
    "import csv # Import the csv module to work with csv files\n",
    "from nltk.corpus import stopwords # Import stopwords from nltk.corpus\n",
    "print(stopwords.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85c15f95-5054-4169-993b-d7851712a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('french') # Create a list `stop_words` that contains the French stop words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aaa6138-2105-42f1-a9cd-a7941201d24c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ai',\n",
       " 'aie',\n",
       " 'aient',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'as',\n",
       " 'au',\n",
       " 'aura',\n",
       " 'aurai',\n",
       " 'auraient',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'auras',\n",
       " 'aurez',\n",
       " 'auriez',\n",
       " 'aurions',\n",
       " 'aurons',\n",
       " 'auront',\n",
       " 'aux',\n",
       " 'avaient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avec',\n",
       " 'avez',\n",
       " 'aviez',\n",
       " 'avions',\n",
       " 'avons',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'ayez',\n",
       " 'ayons',\n",
       " 'c',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'd',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'es',\n",
       " 'est',\n",
       " 'et',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eurent',\n",
       " 'eus',\n",
       " 'eusse',\n",
       " 'eussent',\n",
       " 'eusses',\n",
       " 'eussiez',\n",
       " 'eussions',\n",
       " 'eut',\n",
       " 'eux',\n",
       " 'eûmes',\n",
       " 'eût',\n",
       " 'eûtes',\n",
       " 'furent',\n",
       " 'fus',\n",
       " 'fusse',\n",
       " 'fussent',\n",
       " 'fusses',\n",
       " 'fussiez',\n",
       " 'fussions',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fût',\n",
       " 'fûtes',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'j',\n",
       " 'je',\n",
       " 'l',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'même',\n",
       " 'n',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ont',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 's',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'sera',\n",
       " 'serai',\n",
       " 'seraient',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'seras',\n",
       " 'serez',\n",
       " 'seriez',\n",
       " 'serions',\n",
       " 'serons',\n",
       " 'seront',\n",
       " 'ses',\n",
       " 'soient',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'sommes',\n",
       " 'son',\n",
       " 'sont',\n",
       " 'soyez',\n",
       " 'soyons',\n",
       " 'suis',\n",
       " 'sur',\n",
       " 't',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'y',\n",
       " 'à',\n",
       " 'étaient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étant',\n",
       " 'étante',\n",
       " 'étantes',\n",
       " 'étants',\n",
       " 'étiez',\n",
       " 'étions',\n",
       " 'été',\n",
       " 'étée',\n",
       " 'étées',\n",
       " 'étés',\n",
       " 'êtes']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sorted(stop_words)) # Show each string in our stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9316e4-f5c7-4f12-8b87-ee10ccdd1cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['votr', 'voz', 'w', 'x', 'xx', 'y', 'ya', 'ycel', 'ure', 'z']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "middle_french_stopwords = [\n",
    "'a', 'aa', 'aaa', 'aag', 'ae', 'ag', 'ain', 'ains', 'ainsi', 'ainsy',\n",
    "'aist', 'al', 'am', 'an', 'ans', 'apre', 'apres', 'ar', 'ara', 'at',\n",
    "'aucun', 'aucung', 'aulcung', 'aultr', 'aucc', 'aujourd', 'audict', 'auoit', 'auoir', 'aultre',\n",
    "'auec', 'aufi', 'auffi', 'auss', 'aussi', 'aussy', 'aut', 'autre', 'autres', 'autr',\n",
    "'auxdict', 'avoir', 'avoyent', 'avecqu', 'avecque', 'avoient', 'avoit', 'ay', 'ayt', 'b',\n",
    "'bi', 'bl', 'car', 'cc', 'cel', 'celuy', 'cen', 'cent', 'certes', 'cet',\n",
    "'ceste', 'cest', 'ceulx', 'ceux', 'cf', 'cft', 'cftoit', 'cg', 'chap', 'chacun',\n",
    "'chaqu', 'chascung', 'cinq', 'cinquiesm', 'clle', 'co', 'com', 'comb', 'comme', 'comm',\n",
    "'constituendá', 'cn', 'contr', 'cr', 'cy', 'da', 'dan', 'dc', 'de', 'dé',\n",
    "'del', 'dela', 'den', 'depuis', 'deux', 'di', 'dict', 'dift', 'dit', 'dix',\n",
    "'dixiem', 'dixieme', 'do', 'dom', 'douz', 'dud', 'dudict', 'dudit', 'duquel', 'e',\n",
    "'é', 'ee', 'ec', 'ef', 'efl', 'eft', 'eftoit', 'eftre', 'el', 'ellas',\n",
    "'elles', 'enl', 'encor', 'encore', 'ena', 'er', 'estant', 'estre', 'estoit', 'estoient',\n",
    "'estoy', 'estoyent', 'este', 'esté', 'etoient', 'étoient', 'etoit', 'étoit', 'étre', 'étre',\n",
    "'euffent', 'eulx', 'eust', 'ex', 'f', 'fa', 'faifoyent', 'fait', 'faict', 'fai',\n",
    "'fair', 'fan', 'fault', 'faut', 'fc', 'fe', 'feroyent', 'feut', 'fes', 'ff',\n",
    "'fi', 'fil', 'fift', 'firent', 'fit', 'foit', 'fon', 'font', 'ft', 'foub',\n",
    "'fur', 'fuffent', 'fust', 'g', 'ge', 'grand', 'h', 'he', 'ho', 'i',\n",
    "'ia', 'iam', 'iamais', 'ic', 'ie', 'iij', 'iir', 'ilz', 'im', 'in',\n",
    "'ion', 'it', 'iusqu', 'iv', 'ix', 'jam', 'k', 'laquelle', 'ladict', 'ladicte',\n",
    "'ladit', 'ladite', 'laquel', 'lc', 'led', 'ledict', 'ledit', 'lesdict', 'lesdictz', 'lesdit',\n",
    "'leurs', 'li', 'lib', 'livr', 'livre', 'livres', 'll', 'lu', 'luy', 'lx',\n",
    "'lzs', 'm', 'memoir', 'mesm', 'mesme', 'mefme', 'mefmes', 'mil', 'million', 'même',\n",
    "'moy', 'mp', 'mv', 'nc', 'neantmoin', 'ni', 'no', 'non', 'nostr', 'noz',\n",
    "'nu', 'ny', 'nw', 'o', 'op', 'or', 'ores', 'où', 'oy', 'p',\n",
    "'pa', 'parl', 'pe', 'peult', 'peulvent', 'peut', 'plus', 'poinct', 'point', 'pourc',\n",
    "'pourl', 'pourt', 'pre', 'premi', 'pr', 'puis', 'q', 'quand', 'quatr', 'quatre',\n",
    "'quatriesm', 'quatriesme', 'quele', 'queles', 'quelqu', 'quelque', 'quelquesfois', 'quel', 'quiatellementdifpo', 'quil', 'qut',\n",
    "'rar', 're', 'r', 'ri', 'rien', 'ro', 'rr', 'san', 'section', 'second', 'ser',\n",
    "'serois', 'seroit', 'seul', 'si', 'sil', 'six', 'sixiesm', 'sixiesme', 'soubs', 'soub',\n",
    "'sr', 'tant', 'tel', 'tett', 'tout', 'touts', 'tous', 'tousjour', 'toutes', 'toutesfois',\n",
    "'trait', 'tr', 'tré', 'tre', 'trois', 'troisieme', 'troisiesm', 'troisiesme', 'trop', 'tt',\n",
    "'u', 'ua', 'ue', 'ung', 'ur', 'v', 'vingt', 'vi', 'vn', 'vnc',\n",
    "'vne', 'vnes', 'vostr', 'votr', 'voz', 'w', 'x', 'xx', 'y', 'ya',\n",
    "'ycel', 'ure', 'z'\n",
    "]\n",
    "\n",
    "\n",
    "combined_stopwords = stop_words + middle_french_stopwords\n",
    "\n",
    "list(combined_stopwords)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caaa1991-aaf9-4ed2-936b-0c39bd700fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./stop_words.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(combined_stopwords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
