{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "036d5f34-4bf4-41bb-8df0-34b802145739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to use predefined target word lists (yes/no)?  yes\n",
      "Enter the value for alpha:  0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords file selection\n",
      "Select a subdirectory:\n",
      "0. Current Working Directory\n",
      "1. .ipynb_checkpoints\n",
      "2. concordances\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a stopwords file from the following list:\n",
      "Select the files for stopwords file:\n",
      "1. stop_words.csv\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of the file, a range (e.g., 1-3), multiple ranges (e.g., 1-3,5-7), a text pattern to select files, or type 'all' to select all files:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected files:\n",
      "stop_words.csv\n",
      "Rate dictionary file selection\n",
      "Select a subdirectory:\n",
      "0. Current Working Directory\n",
      "1. .ipynb_checkpoints\n",
      "2. concordances\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select one or more rate dictionary files from the following list:\n",
      "Select the files for rate dictionary:\n",
      "1. Démonomanie preface Repair_corrected_stemmed.txt\n",
      "2. République preface_corrected_stemmed.txt\n",
      "3. Discours des raisons_corrected_stemmed.txt\n",
      "4. Démonomanie I.1_corrected_stemmed.txt\n",
      "5. Démonomanie I.2_corrected_stemmed.txt\n",
      "6. Démonomanie I.3_corrected_stemmed.txt\n",
      "7. Démonomanie I.4_corrected_stemmed.txt\n",
      "8. Démonomanie I.5_corrected_stemmed.txt\n",
      "9. Démonomanie I.6_corrected_stemmed.txt\n",
      "10. Démonomanie I.7_corrected_stemmed.txt\n",
      "11. Démonomanie II.1_corrected_stemmed.txt\n",
      "12. Démonomanie II.2_corrected_stemmed.txt\n",
      "13. Démonomanie II.3_corrected_stemmed.txt\n",
      "14. Démonomanie II.4_corrected_stemmed.txt\n",
      "15. Démonomanie II.5_corrected_stemmed.txt\n",
      "16. Démonomanie II.6_corrected_stemmed.txt\n",
      "17. Démonomanie II.7_corrected_stemmed.txt\n",
      "18. Démonomanie II.8_corrected_stemmed.txt\n",
      "19. Démonomanie III.1_corrected_stemmed.txt\n",
      "20. Démonomanie III.2_corrected_stemmed.txt\n",
      "21. Démonomanie III.3_corrected_stemmed.txt\n",
      "22. Démonomanie III.4_corrected_stemmed.txt\n",
      "23. Démonomanie III.5_corrected_stemmed.txt\n",
      "24. Démonomanie III.6_corrected_stemmed.txt\n",
      "25. Démonomanie IV.1_corrected_stemmed.txt\n",
      "26. Démonomanie IV.2_corrected_stemmed.txt\n",
      "27. Démonomanie IV.3_corrected_stemmed.txt\n",
      "28. Démonomanie IV.4_corrected_stemmed.txt\n",
      "29. Démonomanie IV.5_corrected_stemmed.txt\n",
      "30. Harangue - Fontainebleau_corrected_stemmed.txt\n",
      "31. Harangue - lit de justice_corrected_stemmed.txt\n",
      "32. Harangue - Orléans 2_corrected_stemmed.txt\n",
      "33. Harangue - Orléans_corrected_stemmed.txt\n",
      "34. Harangue - ouverture de parlement_corrected_stemmed.txt\n",
      "35. Harangue - parlement 2_corrected_stemmed.txt\n",
      "36. Harangue - parlement 3_corrected_stemmed.txt\n",
      "37. Harangue - parlement_corrected_stemmed.txt\n",
      "38. Harangue - Poissy_corrected_stemmed.txt\n",
      "39. Harangue - religion_corrected_stemmed.txt\n",
      "40. Harangue - Rouen_corrected_stemmed.txt\n",
      "41. Harangue - Saint Germain_corrected_stemmed.txt\n",
      "42. Harangue - septembre_corrected_stemmed.txt\n",
      "43. La réponse_corrected_stemmed.txt\n",
      "44. Le paradoxe_corrected_stemmed.txt\n",
      "45. Lettre_corrected_stemmed.txt\n",
      "46. Lit de justice_corrected_stemmed.txt\n",
      "47. Memoire - le but_corrected_stemmed.txt\n",
      "48. Memoire - Namur_corrected_stemmed.txt\n",
      "49. Memoire au roi_corrected_stemmed.txt\n",
      "50. Memoires d'État Refuge_corrected_stemmed.txt\n",
      "51. Memoires d'état_corrected_stemmed.txt\n",
      "52. Recueil_corrected_stemmed.txt\n",
      "53. Remonstrances - parlement_corrected_stemmed.txt\n",
      "54. Remonstrances - Royaume_corrected_stemmed.txt\n",
      "55. République I.1_corrected_stemmed.txt\n",
      "56. République I.2_corrected_stemmed.txt\n",
      "57. République I.3_corrected_stemmed.txt\n",
      "58. République I.4_corrected_stemmed.txt\n",
      "59. République I.5_corrected_stemmed.txt\n",
      "60. République I.6_corrected_stemmed.txt\n",
      "61. République I.7_corrected_stemmed.txt\n",
      "62. République I.8_corrected_stemmed.txt\n",
      "63. République I.910_corrected_stemmed.txt\n",
      "64. République I.911_corrected_stemmed.txt\n",
      "65. République I.9_corrected_stemmed.txt\n",
      "66. République II.1_corrected_stemmed.txt\n",
      "67. République II.2_corrected_stemmed.txt\n",
      "68. République II.3_corrected_stemmed.txt\n",
      "69. République II.4_corrected_stemmed.txt\n",
      "70. République II.5_corrected_stemmed.txt\n",
      "71. République II.6_corrected_stemmed.txt\n",
      "72. République II.7_corrected_stemmed.txt\n",
      "73. République III.1_corrected_stemmed.txt\n",
      "74. République III.2_corrected_stemmed.txt\n",
      "75. République III.3_corrected_stemmed.txt\n",
      "76. République III.4_corrected_stemmed.txt\n",
      "77. République III.5_corrected_stemmed.txt\n",
      "78. République III.6_corrected_stemmed.txt\n",
      "79. République III.7_corrected_stemmed.txt\n",
      "80. République IV.1_corrected_stemmed.txt\n",
      "81. République IV.2_corrected_stemmed.txt\n",
      "82. République IV.3_corrected_stemmed.txt\n",
      "83. République IV.4_corrected_stemmed.txt\n",
      "84. République IV.5_corrected_stemmed.txt\n",
      "85. République IV.6_corrected_stemmed.txt\n",
      "86. République IV.7_corrected_stemmed.txt\n",
      "87. République V.1_corrected_stemmed.txt\n",
      "88. République V.2_corrected_stemmed.txt\n",
      "89. République V.3_corrected_stemmed.txt\n",
      "90. République V.4_corrected_stemmed.txt\n",
      "91. République V.5_corrected_stemmed.txt\n",
      "92. République VI.1_corrected_stemmed.txt\n",
      "93. République VI.2_corrected_stemmed.txt\n",
      "94. République VI.3_corrected_stemmed.txt\n",
      "95. République VI.4_corrected_stemmed.txt\n",
      "96. République VI.5_corrected_stemmed.txt\n",
      "97. République VI.6_corrected_stemmed.txt\n",
      "98. Théatre I_corrected_stemmed.txt\n",
      "99. Théatre II_corrected_stemmed.txt\n",
      "100. Théatre III_corrected_stemmed.txt\n",
      "101. Théatre IV_corrected_stemmed.txt\n",
      "102. Théatre summary_corrected_stemmed.txt\n",
      "103. Théatre V_corrected_stemmed.txt\n",
      "104. Traite Justice V_corrected_stemmed.txt\n",
      "105. Traite Justice VI_corrected_stemmed.txt\n",
      "106. Traite Justice VII_corrected_stemmed.txt\n",
      "107. Traité Justice I_corrected_stemmed.txt\n",
      "108. Traité Justice II_corrected_stemmed.txt\n",
      "109. Traité Justice III_corrected_stemmed.txt\n",
      "110. Traité Justice IV_corrected_stemmed.txt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of the file, a range (e.g., 1-3), multiple ranges (e.g., 1-3,5-7), a text pattern to select files, or type 'all' to select all files:  all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected files:\n",
      "Démonomanie preface Repair_corrected_stemmed.txt\n",
      "République preface_corrected_stemmed.txt\n",
      "Discours des raisons_corrected_stemmed.txt\n",
      "Démonomanie I.1_corrected_stemmed.txt\n",
      "Démonomanie I.2_corrected_stemmed.txt\n",
      "Démonomanie I.3_corrected_stemmed.txt\n",
      "Démonomanie I.4_corrected_stemmed.txt\n",
      "Démonomanie I.5_corrected_stemmed.txt\n",
      "Démonomanie I.6_corrected_stemmed.txt\n",
      "Démonomanie I.7_corrected_stemmed.txt\n",
      "Démonomanie II.1_corrected_stemmed.txt\n",
      "Démonomanie II.2_corrected_stemmed.txt\n",
      "Démonomanie II.3_corrected_stemmed.txt\n",
      "Démonomanie II.4_corrected_stemmed.txt\n",
      "Démonomanie II.5_corrected_stemmed.txt\n",
      "Démonomanie II.6_corrected_stemmed.txt\n",
      "Démonomanie II.7_corrected_stemmed.txt\n",
      "Démonomanie II.8_corrected_stemmed.txt\n",
      "Démonomanie III.1_corrected_stemmed.txt\n",
      "Démonomanie III.2_corrected_stemmed.txt\n",
      "Démonomanie III.3_corrected_stemmed.txt\n",
      "Démonomanie III.4_corrected_stemmed.txt\n",
      "Démonomanie III.5_corrected_stemmed.txt\n",
      "Démonomanie III.6_corrected_stemmed.txt\n",
      "Démonomanie IV.1_corrected_stemmed.txt\n",
      "Démonomanie IV.2_corrected_stemmed.txt\n",
      "Démonomanie IV.3_corrected_stemmed.txt\n",
      "Démonomanie IV.4_corrected_stemmed.txt\n",
      "Démonomanie IV.5_corrected_stemmed.txt\n",
      "Harangue - Fontainebleau_corrected_stemmed.txt\n",
      "Harangue - lit de justice_corrected_stemmed.txt\n",
      "Harangue - Orléans 2_corrected_stemmed.txt\n",
      "Harangue - Orléans_corrected_stemmed.txt\n",
      "Harangue - ouverture de parlement_corrected_stemmed.txt\n",
      "Harangue - parlement 2_corrected_stemmed.txt\n",
      "Harangue - parlement 3_corrected_stemmed.txt\n",
      "Harangue - parlement_corrected_stemmed.txt\n",
      "Harangue - Poissy_corrected_stemmed.txt\n",
      "Harangue - religion_corrected_stemmed.txt\n",
      "Harangue - Rouen_corrected_stemmed.txt\n",
      "Harangue - Saint Germain_corrected_stemmed.txt\n",
      "Harangue - septembre_corrected_stemmed.txt\n",
      "La réponse_corrected_stemmed.txt\n",
      "Le paradoxe_corrected_stemmed.txt\n",
      "Lettre_corrected_stemmed.txt\n",
      "Lit de justice_corrected_stemmed.txt\n",
      "Memoire - le but_corrected_stemmed.txt\n",
      "Memoire - Namur_corrected_stemmed.txt\n",
      "Memoire au roi_corrected_stemmed.txt\n",
      "Memoires d'État Refuge_corrected_stemmed.txt\n",
      "Memoires d'état_corrected_stemmed.txt\n",
      "Recueil_corrected_stemmed.txt\n",
      "Remonstrances - parlement_corrected_stemmed.txt\n",
      "Remonstrances - Royaume_corrected_stemmed.txt\n",
      "République I.1_corrected_stemmed.txt\n",
      "République I.2_corrected_stemmed.txt\n",
      "République I.3_corrected_stemmed.txt\n",
      "République I.4_corrected_stemmed.txt\n",
      "République I.5_corrected_stemmed.txt\n",
      "République I.6_corrected_stemmed.txt\n",
      "République I.7_corrected_stemmed.txt\n",
      "République I.8_corrected_stemmed.txt\n",
      "République I.910_corrected_stemmed.txt\n",
      "République I.911_corrected_stemmed.txt\n",
      "République I.9_corrected_stemmed.txt\n",
      "République II.1_corrected_stemmed.txt\n",
      "République II.2_corrected_stemmed.txt\n",
      "République II.3_corrected_stemmed.txt\n",
      "République II.4_corrected_stemmed.txt\n",
      "République II.5_corrected_stemmed.txt\n",
      "République II.6_corrected_stemmed.txt\n",
      "République II.7_corrected_stemmed.txt\n",
      "République III.1_corrected_stemmed.txt\n",
      "République III.2_corrected_stemmed.txt\n",
      "République III.3_corrected_stemmed.txt\n",
      "République III.4_corrected_stemmed.txt\n",
      "République III.5_corrected_stemmed.txt\n",
      "République III.6_corrected_stemmed.txt\n",
      "République III.7_corrected_stemmed.txt\n",
      "République IV.1_corrected_stemmed.txt\n",
      "République IV.2_corrected_stemmed.txt\n",
      "République IV.3_corrected_stemmed.txt\n",
      "République IV.4_corrected_stemmed.txt\n",
      "République IV.5_corrected_stemmed.txt\n",
      "République IV.6_corrected_stemmed.txt\n",
      "République IV.7_corrected_stemmed.txt\n",
      "République V.1_corrected_stemmed.txt\n",
      "République V.2_corrected_stemmed.txt\n",
      "République V.3_corrected_stemmed.txt\n",
      "République V.4_corrected_stemmed.txt\n",
      "République V.5_corrected_stemmed.txt\n",
      "République VI.1_corrected_stemmed.txt\n",
      "République VI.2_corrected_stemmed.txt\n",
      "République VI.3_corrected_stemmed.txt\n",
      "République VI.4_corrected_stemmed.txt\n",
      "République VI.5_corrected_stemmed.txt\n",
      "République VI.6_corrected_stemmed.txt\n",
      "Théatre I_corrected_stemmed.txt\n",
      "Théatre II_corrected_stemmed.txt\n",
      "Théatre III_corrected_stemmed.txt\n",
      "Théatre IV_corrected_stemmed.txt\n",
      "Théatre summary_corrected_stemmed.txt\n",
      "Théatre V_corrected_stemmed.txt\n",
      "Traite Justice V_corrected_stemmed.txt\n",
      "Traite Justice VI_corrected_stemmed.txt\n",
      "Traite Justice VII_corrected_stemmed.txt\n",
      "Traité Justice I_corrected_stemmed.txt\n",
      "Traité Justice II_corrected_stemmed.txt\n",
      "Traité Justice III_corrected_stemmed.txt\n",
      "Traité Justice IV_corrected_stemmed.txt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the window size for concordance:  15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the files for KWIC and key word counts:\n",
      "1. Démonomanie preface Repair_corrected_stemmed.txt\n",
      "2. République preface_corrected_stemmed.txt\n",
      "3. Discours des raisons_corrected_stemmed.txt\n",
      "4. Démonomanie I.1_corrected_stemmed.txt\n",
      "5. Démonomanie I.2_corrected_stemmed.txt\n",
      "6. Démonomanie I.3_corrected_stemmed.txt\n",
      "7. Démonomanie I.4_corrected_stemmed.txt\n",
      "8. Démonomanie I.5_corrected_stemmed.txt\n",
      "9. Démonomanie I.6_corrected_stemmed.txt\n",
      "10. Démonomanie I.7_corrected_stemmed.txt\n",
      "11. Démonomanie II.1_corrected_stemmed.txt\n",
      "12. Démonomanie II.2_corrected_stemmed.txt\n",
      "13. Démonomanie II.3_corrected_stemmed.txt\n",
      "14. Démonomanie II.4_corrected_stemmed.txt\n",
      "15. Démonomanie II.5_corrected_stemmed.txt\n",
      "16. Démonomanie II.6_corrected_stemmed.txt\n",
      "17. Démonomanie II.7_corrected_stemmed.txt\n",
      "18. Démonomanie II.8_corrected_stemmed.txt\n",
      "19. Démonomanie III.1_corrected_stemmed.txt\n",
      "20. Démonomanie III.2_corrected_stemmed.txt\n",
      "21. Démonomanie III.3_corrected_stemmed.txt\n",
      "22. Démonomanie III.4_corrected_stemmed.txt\n",
      "23. Démonomanie III.5_corrected_stemmed.txt\n",
      "24. Démonomanie III.6_corrected_stemmed.txt\n",
      "25. Démonomanie IV.1_corrected_stemmed.txt\n",
      "26. Démonomanie IV.2_corrected_stemmed.txt\n",
      "27. Démonomanie IV.3_corrected_stemmed.txt\n",
      "28. Démonomanie IV.4_corrected_stemmed.txt\n",
      "29. Démonomanie IV.5_corrected_stemmed.txt\n",
      "30. Harangue - Fontainebleau_corrected_stemmed.txt\n",
      "31. Harangue - lit de justice_corrected_stemmed.txt\n",
      "32. Harangue - Orléans 2_corrected_stemmed.txt\n",
      "33. Harangue - Orléans_corrected_stemmed.txt\n",
      "34. Harangue - ouverture de parlement_corrected_stemmed.txt\n",
      "35. Harangue - parlement 2_corrected_stemmed.txt\n",
      "36. Harangue - parlement 3_corrected_stemmed.txt\n",
      "37. Harangue - parlement_corrected_stemmed.txt\n",
      "38. Harangue - Poissy_corrected_stemmed.txt\n",
      "39. Harangue - religion_corrected_stemmed.txt\n",
      "40. Harangue - Rouen_corrected_stemmed.txt\n",
      "41. Harangue - Saint Germain_corrected_stemmed.txt\n",
      "42. Harangue - septembre_corrected_stemmed.txt\n",
      "43. La réponse_corrected_stemmed.txt\n",
      "44. Le paradoxe_corrected_stemmed.txt\n",
      "45. Lettre_corrected_stemmed.txt\n",
      "46. Lit de justice_corrected_stemmed.txt\n",
      "47. Memoire - le but_corrected_stemmed.txt\n",
      "48. Memoire - Namur_corrected_stemmed.txt\n",
      "49. Memoire au roi_corrected_stemmed.txt\n",
      "50. Memoires d'État Refuge_corrected_stemmed.txt\n",
      "51. Memoires d'état_corrected_stemmed.txt\n",
      "52. Recueil_corrected_stemmed.txt\n",
      "53. Remonstrances - parlement_corrected_stemmed.txt\n",
      "54. Remonstrances - Royaume_corrected_stemmed.txt\n",
      "55. République I.1_corrected_stemmed.txt\n",
      "56. République I.2_corrected_stemmed.txt\n",
      "57. République I.3_corrected_stemmed.txt\n",
      "58. République I.4_corrected_stemmed.txt\n",
      "59. République I.5_corrected_stemmed.txt\n",
      "60. République I.6_corrected_stemmed.txt\n",
      "61. République I.7_corrected_stemmed.txt\n",
      "62. République I.8_corrected_stemmed.txt\n",
      "63. République I.910_corrected_stemmed.txt\n",
      "64. République I.911_corrected_stemmed.txt\n",
      "65. République I.9_corrected_stemmed.txt\n",
      "66. République II.1_corrected_stemmed.txt\n",
      "67. République II.2_corrected_stemmed.txt\n",
      "68. République II.3_corrected_stemmed.txt\n",
      "69. République II.4_corrected_stemmed.txt\n",
      "70. République II.5_corrected_stemmed.txt\n",
      "71. République II.6_corrected_stemmed.txt\n",
      "72. République II.7_corrected_stemmed.txt\n",
      "73. République III.1_corrected_stemmed.txt\n",
      "74. République III.2_corrected_stemmed.txt\n",
      "75. République III.3_corrected_stemmed.txt\n",
      "76. République III.4_corrected_stemmed.txt\n",
      "77. République III.5_corrected_stemmed.txt\n",
      "78. République III.6_corrected_stemmed.txt\n",
      "79. République III.7_corrected_stemmed.txt\n",
      "80. République IV.1_corrected_stemmed.txt\n",
      "81. République IV.2_corrected_stemmed.txt\n",
      "82. République IV.3_corrected_stemmed.txt\n",
      "83. République IV.4_corrected_stemmed.txt\n",
      "84. République IV.5_corrected_stemmed.txt\n",
      "85. République IV.6_corrected_stemmed.txt\n",
      "86. République IV.7_corrected_stemmed.txt\n",
      "87. République V.1_corrected_stemmed.txt\n",
      "88. République V.2_corrected_stemmed.txt\n",
      "89. République V.3_corrected_stemmed.txt\n",
      "90. République V.4_corrected_stemmed.txt\n",
      "91. République V.5_corrected_stemmed.txt\n",
      "92. République VI.1_corrected_stemmed.txt\n",
      "93. République VI.2_corrected_stemmed.txt\n",
      "94. République VI.3_corrected_stemmed.txt\n",
      "95. République VI.4_corrected_stemmed.txt\n",
      "96. République VI.5_corrected_stemmed.txt\n",
      "97. République VI.6_corrected_stemmed.txt\n",
      "98. Théatre I_corrected_stemmed.txt\n",
      "99. Théatre II_corrected_stemmed.txt\n",
      "100. Théatre III_corrected_stemmed.txt\n",
      "101. Théatre IV_corrected_stemmed.txt\n",
      "102. Théatre summary_corrected_stemmed.txt\n",
      "103. Théatre V_corrected_stemmed.txt\n",
      "104. Traite Justice V_corrected_stemmed.txt\n",
      "105. Traite Justice VI_corrected_stemmed.txt\n",
      "106. Traite Justice VII_corrected_stemmed.txt\n",
      "107. Traité Justice I_corrected_stemmed.txt\n",
      "108. Traité Justice II_corrected_stemmed.txt\n",
      "109. Traité Justice III_corrected_stemmed.txt\n",
      "110. Traité Justice IV_corrected_stemmed.txt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of the file, a range (e.g., 1-3), multiple ranges (e.g., 1-3,5-7), a text pattern to select files, or type 'all' to select all files:  Dém,Rép\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected files:\n",
      "Démonomanie preface Repair_corrected_stemmed.txt\n",
      "République preface_corrected_stemmed.txt\n",
      "Démonomanie I.1_corrected_stemmed.txt\n",
      "Démonomanie I.2_corrected_stemmed.txt\n",
      "Démonomanie I.3_corrected_stemmed.txt\n",
      "Démonomanie I.4_corrected_stemmed.txt\n",
      "Démonomanie I.5_corrected_stemmed.txt\n",
      "Démonomanie I.6_corrected_stemmed.txt\n",
      "Démonomanie I.7_corrected_stemmed.txt\n",
      "Démonomanie II.1_corrected_stemmed.txt\n",
      "Démonomanie II.2_corrected_stemmed.txt\n",
      "Démonomanie II.3_corrected_stemmed.txt\n",
      "Démonomanie II.4_corrected_stemmed.txt\n",
      "Démonomanie II.5_corrected_stemmed.txt\n",
      "Démonomanie II.6_corrected_stemmed.txt\n",
      "Démonomanie II.7_corrected_stemmed.txt\n",
      "Démonomanie II.8_corrected_stemmed.txt\n",
      "Démonomanie III.1_corrected_stemmed.txt\n",
      "Démonomanie III.2_corrected_stemmed.txt\n",
      "Démonomanie III.3_corrected_stemmed.txt\n",
      "Démonomanie III.4_corrected_stemmed.txt\n",
      "Démonomanie III.5_corrected_stemmed.txt\n",
      "Démonomanie III.6_corrected_stemmed.txt\n",
      "Démonomanie IV.1_corrected_stemmed.txt\n",
      "Démonomanie IV.2_corrected_stemmed.txt\n",
      "Démonomanie IV.3_corrected_stemmed.txt\n",
      "Démonomanie IV.4_corrected_stemmed.txt\n",
      "Démonomanie IV.5_corrected_stemmed.txt\n",
      "République I.1_corrected_stemmed.txt\n",
      "République I.2_corrected_stemmed.txt\n",
      "République I.3_corrected_stemmed.txt\n",
      "République I.4_corrected_stemmed.txt\n",
      "République I.5_corrected_stemmed.txt\n",
      "République I.6_corrected_stemmed.txt\n",
      "République I.7_corrected_stemmed.txt\n",
      "République I.8_corrected_stemmed.txt\n",
      "République I.910_corrected_stemmed.txt\n",
      "République I.911_corrected_stemmed.txt\n",
      "République I.9_corrected_stemmed.txt\n",
      "République II.1_corrected_stemmed.txt\n",
      "République II.2_corrected_stemmed.txt\n",
      "République II.3_corrected_stemmed.txt\n",
      "République II.4_corrected_stemmed.txt\n",
      "République II.5_corrected_stemmed.txt\n",
      "République II.6_corrected_stemmed.txt\n",
      "République II.7_corrected_stemmed.txt\n",
      "République III.1_corrected_stemmed.txt\n",
      "République III.2_corrected_stemmed.txt\n",
      "République III.3_corrected_stemmed.txt\n",
      "République III.4_corrected_stemmed.txt\n",
      "République III.5_corrected_stemmed.txt\n",
      "République III.6_corrected_stemmed.txt\n",
      "République III.7_corrected_stemmed.txt\n",
      "République IV.1_corrected_stemmed.txt\n",
      "République IV.2_corrected_stemmed.txt\n",
      "République IV.3_corrected_stemmed.txt\n",
      "République IV.4_corrected_stemmed.txt\n",
      "République IV.5_corrected_stemmed.txt\n",
      "République IV.6_corrected_stemmed.txt\n",
      "République IV.7_corrected_stemmed.txt\n",
      "République V.1_corrected_stemmed.txt\n",
      "République V.2_corrected_stemmed.txt\n",
      "République V.3_corrected_stemmed.txt\n",
      "République V.4_corrected_stemmed.txt\n",
      "République V.5_corrected_stemmed.txt\n",
      "République VI.1_corrected_stemmed.txt\n",
      "République VI.2_corrected_stemmed.txt\n",
      "République VI.3_corrected_stemmed.txt\n",
      "République VI.4_corrected_stemmed.txt\n",
      "République VI.5_corrected_stemmed.txt\n",
      "République VI.6_corrected_stemmed.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 444\u001b[0m\n\u001b[1;32m    442\u001b[0m rate_dictionary_files, rate_dictionary_path \u001b[38;5;241m=\u001b[39m select_rate_dictionary_files()\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rate_dictionary_files:\n\u001b[0;32m--> 444\u001b[0m     \u001b[43msearch_concordance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrate_dictionary_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredefined_word_lists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo rate dictionary files selected.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 331\u001b[0m, in \u001b[0;36msearch_concordance\u001b[0;34m(text_data, predefined_word_lists, stops, alpha)\u001b[0m\n\u001b[1;32m    328\u001b[0m subset_files \u001b[38;5;241m=\u001b[39m prompt_files(find_text_files(os\u001b[38;5;241m.\u001b[39mgetcwd()), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKWIC and key word counts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# Allow users to choose an existing .xlsx file or create a new one\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m append_to_existing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDo you want to append results to an existing .xlsx file? (yes/no): \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m append_to_existing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    334\u001b[0m     existing_file \u001b[38;5;241m=\u001b[39m select_existing_xlsx_file()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import nltk\n",
    "from scipy.stats import fisher_exact\n",
    "from openpyxl import Workbook, load_workbook\n",
    "\n",
    "# Function to prompt the user to select text files based on patterns\n",
    "def prompt_pattern_files(text_files, pattern):\n",
    "    selected_files = [file for file in text_files if file.startswith(pattern)]\n",
    "    return selected_files\n",
    "\n",
    "def prompt_files(text_files, purpose):\n",
    "    text_files = sorted(text_files, key=custom_file_sort_key)  # Custom sort for files\n",
    "    print(f\"Select the files for {purpose}:\")\n",
    "    for i, file in enumerate(text_files, start=1):\n",
    "        print(f\"{i}. {file}\")\n",
    "    \n",
    "    selection = input(\"Enter the number of the file, a range (e.g., 1-3), multiple ranges (e.g., 1-3,5-7), a text pattern to select files, or type 'all' to select all files: \").strip()\n",
    "    selected_files = []\n",
    "    \n",
    "    if selection.lower() == 'all':\n",
    "        selected_files = text_files\n",
    "    else:\n",
    "        # Split the input by commas to handle multiple ranges or numbers\n",
    "        parts = selection.split(',')\n",
    "        for part in parts:\n",
    "            part = part.strip()\n",
    "            if '-' in part:  # If the part is a range\n",
    "                try:\n",
    "                    start, end = map(int, part.split('-'))\n",
    "                    selected_files.extend(text_files[start-1:end])\n",
    "                except ValueError:\n",
    "                    print(f\"Invalid range: {part}. Please provide ranges like '1-3'.\")\n",
    "            elif part.isdigit():  # If the part is a single number\n",
    "                try:\n",
    "                    selected_files.append(text_files[int(part) - 1])\n",
    "                except IndexError:\n",
    "                    print(f\"Invalid number: {part}. Please select numbers from the list.\")\n",
    "            else:  # If the part is treated as a pattern\n",
    "                selected_files.extend(prompt_pattern_files(text_files, part))\n",
    "    \n",
    "    # Remove duplicates and sort the selected files\n",
    "    selected_files = sorted(set(selected_files), key=custom_file_sort_key)\n",
    "    \n",
    "    print(\"Selected files:\")\n",
    "    for file in selected_files:\n",
    "        print(file)\n",
    "    \n",
    "    return selected_files\n",
    "\n",
    "# Custom sort key for file names\n",
    "def custom_file_sort_key(filename):\n",
    "    # Prioritize 'preface' higher than patterns like 'I.1'\n",
    "    if 'preface' in filename.lower():\n",
    "        return ('', filename.lower())  # Sort 'preface' first\n",
    "    return (filename.lower(),)\n",
    "\n",
    "# Function to process text files\n",
    "def process_text_files(file_paths):\n",
    "    combined_text = \"\"\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            combined_text += file.read().lower() + \" \"\n",
    "    tokens = nltk.wordpunct_tokenize(combined_text)\n",
    "    return nltk.Text(tokens)\n",
    "\n",
    "# Function to find .txt files in a directory\n",
    "def find_text_files(directory):\n",
    "    return sorted([f for f in os.listdir(directory) if f.endswith('.txt')], key=custom_file_sort_key)  # Custom sort\n",
    "\n",
    "# Function to list subfolders in the current directory\n",
    "def list_subfolders():\n",
    "    return sorted([f.name for f in os.scandir() if f.is_dir()])  # Sort folders alphabetically\n",
    "\n",
    "# Function to prompt the user to select a subfolder or the current directory\n",
    "def prompt_subfolder(subfolders):\n",
    "    print(\"Select a subfolder or the current working directory:\")\n",
    "    print(\"0. Current Working Directory\")\n",
    "    for i, subfolder in enumerate(subfolders, start=1):\n",
    "        print(f\"{i}. {subfolder}\")\n",
    "    selected_index = int(input(\"Enter the number of the subfolder: \"))\n",
    "    return None if selected_index == 0 else subfolders[selected_index - 1]\n",
    "\n",
    "# Function to get predefined target words\n",
    "def get_predefined_target_words():\n",
    "    return [\n",
    "        ['citoyen', 'cour', 'domain', 'ressort'],  # List 1\n",
    "        ['guerre', 'paix', 'police' 'religion'],  # List 2\n",
    "        ['confess', 'demon', 'demoniaqu', 'diabl',\n",
    "         'diabol', 'dieu', 'divin', \n",
    "        'hebrieu', 'impiet', 'preuv', 'question',   'sathan', \n",
    "        'sorceller', 'sorci',  'statut', 'sujet'],  # List 3\n",
    "        ['arrest',  'conseil', 'conseiller', 'consul', \n",
    "         'couron', 'édict', 'iurisdict', 'jug', 'magistrat',\n",
    "         'offic', 'offici', 'ordon', 'parlement',\n",
    "        'seigneur', 'seigneurial', 'statut'],  # List 4\n",
    "        ['absolu', 'bien', 'chos', 'civil', 'droit', 'estat', 'just', 'justic',\n",
    "         'loi', 'maiest', 'princ', 'puissanc',\n",
    "        'republ', 'roy', 'royal', 'royaum', 'souverain', 'souverainet', 'sujet']  # List 5\n",
    "    ]\n",
    "\n",
    "# Function to choose subdirectory for stopwords csv file\n",
    "def choose_subdirectory(subdirectories):\n",
    "    print(\"Select a subdirectory:\")\n",
    "    print(\"0. Current Working Directory\")\n",
    "    for i, subdir in enumerate(subdirectories, start=1):\n",
    "        print(f\"{i}. {subdir}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter your choice: \"))\n",
    "            if 0 <= choice <= len(subdirectories):\n",
    "                return None if choice == 0 else subdirectories[choice - 1]\n",
    "            else:\n",
    "                print(\"Invalid selection. Please try again.\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a number.\")\n",
    "\n",
    "# Function to read stopwords from a csv file\n",
    "def read_stopwords(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        stopwords = []\n",
    "        for row in reader:\n",
    "            for word in row:\n",
    "                stopwords.extend(word.split(','))\n",
    "        return [word.strip() for word in stopwords]\n",
    "\n",
    "# Function to find .csv files in a directory\n",
    "def find_csv_files(directory):\n",
    "    return sorted([f for f in os.listdir(directory) if f.endswith('.csv')])  # Sort files alphabetically\n",
    "\n",
    "# Function to select files for the stopwords\n",
    "def select_stopwords_file():\n",
    "    print('Stopwords file selection')\n",
    "    stopwords_subfolders = list_subfolders()\n",
    "    selected_stopwords_subfolder = choose_subdirectory(stopwords_subfolders)\n",
    "    \n",
    "    # Check if the user selected a subfolder or the current directory\n",
    "    stopwords_subfolder_path = os.getcwd() if selected_stopwords_subfolder is None else os.path.join(os.getcwd(), selected_stopwords_subfolder)\n",
    "    \n",
    "    # Find .csv files in the selected directory\n",
    "    stopwords_files = find_csv_files(stopwords_subfolder_path)\n",
    "    if stopwords_files:\n",
    "        print('Select a stopwords file from the following list:')\n",
    "        # Prompt the user to select a single .csv file\n",
    "        selected_file = prompt_files(stopwords_files, \"stopwords file\")\n",
    "        if selected_file:\n",
    "            return selected_file[0], stopwords_subfolder_path  # Return the first selected file and its path\n",
    "        else:\n",
    "            print(\"No stopwords file selected.\")\n",
    "            return None, None\n",
    "    else:\n",
    "        print(f\"No .csv stopwords files found in '{selected_stopwords_subfolder}'.\")\n",
    "        return None, None\n",
    "\n",
    "# Function to select files for the rate dictionary\n",
    "def select_rate_dictionary_files():\n",
    "    print('Rate dictionary file selection')\n",
    "    rate_dictionary_subfolders = list_subfolders()\n",
    "    selected_rate_dictionary_subfolder = choose_subdirectory(rate_dictionary_subfolders)\n",
    "    \n",
    "    # Check if the user selected a subfolder or the current directory\n",
    "    rate_dictionary_subfolder_path = os.getcwd() if selected_rate_dictionary_subfolder is None else os.path.join(os.getcwd(), selected_rate_dictionary_subfolder)\n",
    "    \n",
    "    # Find .txt files in the selected directory\n",
    "    rate_dictionary_files = find_text_files(rate_dictionary_subfolder_path)\n",
    "    if rate_dictionary_files:\n",
    "        print('Select one or more rate dictionary files from the following list:')\n",
    "        selected_files = prompt_files(rate_dictionary_files, \"rate dictionary\")\n",
    "        if selected_files:\n",
    "            return selected_files, rate_dictionary_subfolder_path  # Return the selected files and their path\n",
    "        else:\n",
    "            print(\"No rate dictionary files selected.\")\n",
    "            return [], None\n",
    "    else:\n",
    "        print(f\"No .txt rate dictionary files found in '{selected_rate_dictionary_subfolder}'.\")\n",
    "        return [], None\n",
    "\n",
    "def select_existing_xlsx_file():\n",
    "    print(\"Select a directory to search for .xlsx files:\")\n",
    "    subfolders = list_subfolders()\n",
    "    selected_subfolder = choose_subdirectory(subfolders)\n",
    "\n",
    "    # Check if the user selected a subfolder or the current directory\n",
    "    folder_path = os.getcwd() if selected_subfolder is None else os.path.join(os.getcwd(), selected_subfolder)\n",
    "\n",
    "    # Find .xlsx files in the selected directory\n",
    "    xlsx_files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]\n",
    "    if xlsx_files:\n",
    "        print(\"Select an existing .xlsx file from the following list:\")\n",
    "        for i, file in enumerate(xlsx_files, start=1):\n",
    "            print(f\"{i}. {file}\")\n",
    "        while True:\n",
    "            try:\n",
    "                choice = int(input(\"Enter the number of the file you want to select or 0 to cancel: \"))\n",
    "                if 0 <= choice <= len(xlsx_files):\n",
    "                    return None if choice == 0 else os.path.join(folder_path, xlsx_files[choice - 1])\n",
    "                else:\n",
    "                    print(\"Invalid selection. Please try again.\")\n",
    "            except ValueError:\n",
    "                print(\"Please enter a number.\")\n",
    "    else:\n",
    "        print(f\"No .xlsx files found in '{folder_path}'.\")\n",
    "        return None\n",
    "\n",
    "# Utility function to clean file names\n",
    "def clean_file_name(file_name):\n",
    "    \"\"\"\n",
    "    Clean the file name for display, including replacing specific patterns.\n",
    "    \"\"\"\n",
    "    file_name = file_name.replace('_', '').replace('corrected', '').replace('stemmed', '')\n",
    "    if 'Démonomanie' in file_name:\n",
    "        file_name = file_name.replace('Démonomanie', 'Dém')\n",
    "    if 'République' in file_name:\n",
    "        file_name = file_name.replace('République', 'Rép')\n",
    "   \n",
    "    # Replace '911' with '11' and '910' with '10' (NEW CHANGE)\n",
    "    file_name = file_name.replace('911', '11').replace('910', '10')  # <--- CHANGE HERE\n",
    "   \n",
    "    return os.path.splitext(file_name)[0]\n",
    "\n",
    "# Function to process the subset of text files for KWIC and counts\n",
    "def process_subset_files(file_paths):\n",
    "    combined_text = \"\"\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as f:\n",
    "            file_contents = f.read().lower()\n",
    "            combined_text += file_contents + \" \"\n",
    "    tokens = nltk.wordpunct_tokenize(combined_text)\n",
    "    return tokens\n",
    "\n",
    "def get_kwic(sometargetterm, somelistofwords, window=10, excl_target=True, source_file=None):\n",
    "    kwics = []\n",
    "    for n, w in enumerate(somelistofwords):\n",
    "        if w == sometargetterm:\n",
    "            start = max(0, n - window)\n",
    "            end = min(n + window + 1, len(somelistofwords))\n",
    "            if excl_target:\n",
    "                k = somelistofwords[start:n] + somelistofwords[n + 1:end]\n",
    "            else:\n",
    "                k = somelistofwords[start:end]\n",
    "            kwics.append((k, source_file))\n",
    "    return kwics\n",
    "\n",
    "def add_to_count_dict(word, count_dict):\n",
    "    if word in count_dict:\n",
    "        count_dict[word] += 1\n",
    "    else:\n",
    "        count_dict[word] = 1\n",
    "\n",
    "def get_fishers(someword, somecountdict, someratedict, alternative='greater'):\n",
    "    r = someratedict[someword]\n",
    "    wc = sum(somecountdict.values())\n",
    "    a = somecountdict[someword]\n",
    "    b = wc - a\n",
    "    c = round(r * wc)\n",
    "    d = wc - c\n",
    "    p = fisher_exact([[a, b], [c, d]], alternative=alternative)[1]\n",
    "    return p\n",
    "\n",
    "# Modified filter_collocates function\n",
    "def filter_collocates(collocates, collocate_counts):\n",
    "    \"\"\"\n",
    "    Filter the list of significant collocates based on user selection.\n",
    "\n",
    "    Parameters:\n",
    "        collocates (list): A sorted list of significant collocates.\n",
    "        collocate_counts (dict): A dictionary of collocates and their counts.\n",
    "\n",
    "    Returns:\n",
    "        list: A filtered list of collocates selected by the user.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            min_count = int(input(\"Enter the minimum count threshold for collocates to include: \").strip())\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid number.\")\n",
    "\n",
    "    filtered_collocates = [collocate for collocate in collocates if collocate_counts[collocate] >= min_count]\n",
    "    print(f\"\\nCollocates with counts >= {min_count}:\")\n",
    "    for i, collocate in enumerate(filtered_collocates, start=1):\n",
    "        print(f\"{i}. {collocate} (Count: {collocate_counts[collocate]})\")\n",
    "\n",
    "    print(\"\\nYou can select collocates by entering:\")\n",
    "    print(\"- A single number (e.g., 3) to select one collocate.\")\n",
    "    print(\"- A range of numbers (e.g., 3-6) to select multiple collocates.\")\n",
    "    print(\"- Multiple selections separated by commas (e.g., 3,5-7,9).\")\n",
    "    print(\"- Type 'all' to select all collocates.\")\n",
    "    print(\"- Type 'done' to finalize your selection.\")\n",
    "\n",
    "    selected_collocates = []\n",
    "\n",
    "    while True:\n",
    "        selection = input(\"Enter your selection: \").strip()\n",
    "        if selection.lower() == 'done':\n",
    "            break\n",
    "        elif selection.lower() == 'all':\n",
    "            selected_collocates = filtered_collocates\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            parts = selection.split(',')\n",
    "            for part in parts:\n",
    "                part = part.strip()\n",
    "                if '-' in part:  # Handle ranges\n",
    "                    start, end = map(int, part.split('-'))\n",
    "                    selected_collocates.extend(filtered_collocates[start-1:end])\n",
    "                elif part.isdigit():  # Handle single numbers\n",
    "                    selected_collocates.append(filtered_collocates[int(part) - 1])\n",
    "                else:\n",
    "                    print(f\"Invalid selection: {part}. Please try again.\")\n",
    "        except (ValueError, IndexError):\n",
    "            print(f\"Invalid input: {selection}. Please try again.\")\n",
    "\n",
    "        # Remove duplicates and sort the selected collocates\n",
    "        selected_collocates = sorted(set(selected_collocates), key=filtered_collocates.index)\n",
    "\n",
    "        print(\"Currently selected collocates:\")\n",
    "        for collocate in selected_collocates:\n",
    "            print(collocate)\n",
    "\n",
    "    return selected_collocates, min_count\n",
    "\n",
    "def search_concordance(text_data, predefined_word_lists, stops, alpha):\n",
    "    window = int(input(f\"Enter the window size for concordance: \").strip())\n",
    "\n",
    "    subset_files = prompt_files(find_text_files(os.getcwd()), \"KWIC and key word counts\")\n",
    "\n",
    "    # Allow users to choose an existing .xlsx file or create a new one\n",
    "    append_to_existing = input(\"Do you want to append results to an existing .xlsx file? (yes/no): \").strip().lower()\n",
    "\n",
    "    if append_to_existing == 'yes':\n",
    "        existing_file = select_existing_xlsx_file()\n",
    "        if existing_file:\n",
    "            wb = load_workbook(existing_file)\n",
    "            print(f\"Appending to existing file: {existing_file}\")\n",
    "        else:\n",
    "            print(\"No existing workbook selected. Creating a new workbook instead.\")\n",
    "            wb = Workbook()\n",
    "    else:\n",
    "        wb = Workbook()\n",
    "        print(\"Creating a new workbook.\")\n",
    "\n",
    "    for index, predefined_words in enumerate(predefined_word_lists):\n",
    "        # Allow users to skip processing a predefined word list\n",
    "        skip = input(f\"Do you want to skip processing Hypothesis {index + 1}? (yes/no): \").strip().lower()\n",
    "        if skip == 'yes':\n",
    "            print(f\"Skipping Hypothesis {index + 1}.\")\n",
    "            continue\n",
    "\n",
    "        ws = wb.create_sheet(title=f\"Hypothesis {index + 1}\")\n",
    "\n",
    "        # Write headers\n",
    "        headers = ['Word'] + [clean_file_name(file) for file in subset_files] + ['Total']\n",
    "        ws.append(headers)\n",
    "\n",
    "        # Sort rows (words) alphabetically\n",
    "        predefined_words = sorted(predefined_words)\n",
    "\n",
    "        all_significant_collocates = set()\n",
    "        collocate_counts = {}\n",
    "        for word in predefined_words:\n",
    "            for file in subset_files:\n",
    "                file_path = os.path.join(os.getcwd(), file)\n",
    "                tokens = process_subset_files([file_path])\n",
    "                kwics = get_kwic(word, tokens, window)\n",
    "                for k in kwics:\n",
    "                    for w in k[0]:  # Access the first element of the tuple\n",
    "                        if w not in stops:\n",
    "                            all_significant_collocates.add(w)\n",
    "                            add_to_count_dict(w, collocate_counts)\n",
    "\n",
    "        all_significant_collocates = sorted(all_significant_collocates)\n",
    "        selected_collocates, min_count = filter_collocates(all_significant_collocates, collocate_counts)\n",
    "\n",
    "        for word in predefined_words:\n",
    "            row = [word]\n",
    "            word_total = 0\n",
    "            for file in subset_files:\n",
    "                file_path = os.path.join(os.getcwd(), file)\n",
    "                tokens = process_subset_files([file_path])\n",
    "                kwics = get_kwic(word, tokens, window)\n",
    "                count = sum(1 for k in kwics if any(w in selected_collocates for w in k[0]))\n",
    "                row.append(count)\n",
    "                word_total += count\n",
    "            row.append(word_total)\n",
    "            ws.append(row)\n",
    "\n",
    "        # Add total row\n",
    "        total_row = ['Total'] + [sum(ws.cell(row=i + 2, column=j + 2).value for i in range(len(predefined_words))) for j in range(len(subset_files))] + [sum(ws.cell(row=i + 2, column=len(subset_files) + 2).value for i in range(len(predefined_words)))]\n",
    "        ws.append(total_row)\n",
    "\n",
    "        # Add blank line and selected collocates\n",
    "        ws.append([])\n",
    "        ws.append(['Selected Significant Collocates:'])\n",
    "        for i in range(0, len(selected_collocates), 10):\n",
    "            ws.append(selected_collocates[i:i + 10])\n",
    "       \n",
    "        # Add a blank line and display alpha (p-value threshold), window size, and minimum count threshold\n",
    "        ws.append([])\n",
    "        ws.append(['p-value threshold:', alpha])\n",
    "        ws.append(['window size:', window])\n",
    "        ws.append(['minimum count threshold:', min_count])\n",
    "\n",
    "        # Option to output results after processing each list\n",
    "        output_now = input(f\"Do you want to save the results for Hypothesis {index + 1} now? (yes/no): \").strip().lower()\n",
    "        if output_now == 'yes':\n",
    "            if 'concordances' not in os.listdir():\n",
    "                os.mkdir('concordances')\n",
    "            wb.save(os.path.join('concordances', 'distinct_collocates.xlsx'))\n",
    "            print(f\"Results up to Hypothesis {index + 1} saved to concordances/distinct_collocates.xlsx.\")\n",
    "\n",
    "        # Option to exit after processing each hypothesis\n",
    "        exit_now = input(\"Do you want to exit after this hypothesis? (yes/no): \").strip().lower()\n",
    "        if exit_now == 'yes':\n",
    "            print(\"Exiting the program.\")\n",
    "            return\n",
    "\n",
    "    # Remove the default sheet if it exists\n",
    "    if 'Sheet' in wb.sheetnames:\n",
    "        del wb['Sheet']\n",
    "\n",
    "    # Save the workbook\n",
    "    if 'concordances' not in os.listdir():\n",
    "        os.mkdir('concordances')\n",
    "    wb.save(os.path.join('concordances', 'distinct_collocates.xlsx'))\n",
    "    print(f'Concordance has been saved to concordances/distinct_collocates.xlsx.')\n",
    "    \n",
    "# Example usage\n",
    "use_predefined = input(\"Do you want to use predefined target word lists (yes/no)? \").strip().lower() == 'yes'\n",
    "if use_predefined:\n",
    "    predefined_word_lists = get_predefined_target_words()\n",
    "else:\n",
    "    predefined_word_lists = [input(\"Enter words for a group separated by spaces: \").strip().split() for _ in range(5)]\n",
    "\n",
    "alpha = float(input(\"Enter the value for alpha: \").strip())\n",
    "\n",
    "stopwords_file, stopwords_path = select_stopwords_file()\n",
    "if stopwords_file:\n",
    "    stops = read_stopwords(os.path.join(stopwords_path, stopwords_file))\n",
    "    rate_dictionary_files, rate_dictionary_path = select_rate_dictionary_files()\n",
    "    if rate_dictionary_files:\n",
    "        search_concordance(rate_dictionary_files, predefined_word_lists, stops, alpha)\n",
    "    else:\n",
    "        print(\"No rate dictionary files selected.\")\n",
    "else:\n",
    "    print(\"No stopwords file selected.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03297597-a09d-4d18-b1d6-8644a7f1681c",
   "metadata": {},
   "outputs": [],
   "source": [
    " modify this code so that it allows users to input a unique name to save the .xlsx file under in the concordances folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d27311-df52-4b0b-9cbd-37e2d84ba7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_concordance(text_data, predefined_word_lists, stops, alpha):\n",
    "    window = int(input(f\"Enter the window size for concordance: \").strip())\n",
    "    subset_files = prompt_files(find_text_files(os.getcwd()), \"KWIC and key word counts\")\n",
    "\n",
    "    append_to_existing = input(\"Do you want to append results to an existing .xlsx file? (yes/no): \").strip().lower()\n",
    "    if append_to_existing == 'yes':\n",
    "        existing_file = select_existing_xlsx_file()\n",
    "        if existing_file:\n",
    "            wb = load_workbook(existing_file)\n",
    "            print(f\"Appending to existing file: {existing_file}\")\n",
    "        else:\n",
    "            print(\"No existing workbook selected. Creating a new workbook instead.\")\n",
    "            wb = Workbook()\n",
    "            if 'Sheet' in wb.sheetnames:\n",
    "                del wb['Sheet']\n",
    "    else:\n",
    "        wb = Workbook()\n",
    "        print(\"Creating a new workbook.\")\n",
    "        if 'Sheet' in wb.sheetnames:\n",
    "            del wb['Sheet']\n",
    "\n",
    "    if append_to_existing == 'yes' and existing_file:\n",
    "        output_filepath = existing_file\n",
    "    else:\n",
    "        output_filename = input(\"Enter a unique name for the .xlsx file (without extension): \").strip()\n",
    "        if not output_filename:\n",
    "            output_filename = \"distinct_collocates\"\n",
    "        output_filepath = os.path.join(\"concordances\", f\"{output_filename}.xlsx\")\n",
    "\n",
    "    for index, predefined_words in enumerate(predefined_word_lists):\n",
    "        skip = input(f\"Do you want to skip processing Hypothesis {index + 1}? (yes/no): \").strip().lower()\n",
    "        if skip == 'yes':\n",
    "            print(f\"Skipping Hypothesis {index + 1}.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing Hypothesis {index + 1}.\")\n",
    "\n",
    "        ws = wb.create_sheet(title=f\"Hypothesis {index + 1}\")\n",
    "        headers = ['Word'] + [clean_file_name(file) for file in subset_files] + ['Total']\n",
    "        ws.append(headers)\n",
    "\n",
    "        predefined_words = sorted(predefined_words)\n",
    "        keyword_pairs = generate_keyword_pairs(predefined_words)\n",
    "\n",
    "        # --- 1. Gather KWIC collocates for all files ---\n",
    "        counts_by_file       = {}   # will map filename → {token → count}\n",
    "        pair_counts_by_file  = {}   # will map filename → {(kw1,kw2) → count}\n",
    "        \n",
    "        for file in subset_files:\n",
    "            file_path = os.path.join(os.getcwd(), file)\n",
    "            subset_tokens = process_subset_files([file_path])\n",
    "        \n",
    "            counts     = {}   # single‐token collocate counts for THIS file\n",
    "            pair_counts = {}  # keyword–keyword pair counts for THIS file\n",
    "        \n",
    "            for word in predefined_words:\n",
    "                kwics = get_kwic(word, subset_tokens, window, source_file=file)\n",
    "                for window_tokens, _ in kwics:\n",
    "                    unique = set(window_tokens)   # dedupe within each window\n",
    "                    for collocate in unique:\n",
    "                        if collocate not in stops and collocate != word:\n",
    "                            # 1) count every single‐word collocate\n",
    "                            add_to_count_dict(collocate, counts)\n",
    "        \n",
    "                            # 2) if that collocate is another hypothesis‐keyword,\n",
    "                            #    record the pair (word, collocate) separately\n",
    "                            if collocate in predefined_words:\n",
    "                                add_to_count_dict((word, collocate), pair_counts)\n",
    "\n",
    "    # store this file’s two dicts\n",
    "    counts_by_file[file]      = counts\n",
    "    pair_counts_by_file[file] = pair_counts\n",
    "\n",
    "        # --- 2. Per-file Fisher tests against the external rate-dictionary ---\n",
    "        # build expected rates once\n",
    "        ref_tokens = process_subset_files([\n",
    "            os.path.join(rate_dictionary_path, f) for f in text_data\n",
    "        ])\n",
    "        ref_counts = {}\n",
    "        for tok in ref_tokens:\n",
    "            if tok not in stops and tok not in predefined_words:\n",
    "                add_to_count_dict(tok, ref_counts)\n",
    "        ref_total = sum(ref_counts.values())\n",
    "        if ref_total == 0:\n",
    "            raise ValueError(\"Rate dictionary is empty after stopword/keyword filtering!\")\n",
    "        expected_rates = {w: ref_counts.get(w, 0) / ref_total for w in ref_counts}\n",
    "        \n",
    "        # test each file separately, collect all significant collocates\n",
    "        all_significant_collocates = set()\n",
    "        for file, counts in counts_by_file.items():\n",
    "            file_total = sum(counts.values())\n",
    "            if file_total == 0:\n",
    "                continue\n",
    "            for collocate, obs in counts.items():\n",
    "                exp_rate = expected_rates.get(collocate, 0.0)\n",
    "                exp_count = round(exp_rate * file_total)\n",
    "                a, b = obs, file_total - obs\n",
    "                c, d = exp_count, file_total - exp_count\n",
    "                p_value = fisher_exact([[a, b], [c, d]], alternative='greater')[1]\n",
    "                if p_value < alpha:\n",
    "                    all_significant_collocates.add(collocate)\n",
    "                    collocate_counts[collocate] = collocate_counts.get(collocate, 0) + obs\n",
    "                \n",
    "        # --- 3. Let user filter significant collocates ---\n",
    "        all_significant_collocates = sorted(all_significant_collocates)\n",
    "            print(f\"\\n=== Hypothesis {index+1} target words ===\")\n",
    "            print(\", \".join(predefined_words))\n",
    "            print(\"=======================================\\n\")\n",
    "        selected_collocates, min_count = filter_collocates_with_removal(all_significant_collocates, collocate_counts)\n",
    "\n",
    "        # --- 4. Write results per keyword to worksheet ---\n",
    "        for word in predefined_words:\n",
    "            row = [word]\n",
    "            word_total = 0\n",
    "            for file in subset_files:\n",
    "                file_collocates = set()\n",
    "                file_counts = counts_by_file[file]\n",
    "                for collocate in selected_collocates:\n",
    "                    if collocate in file_counts:\n",
    "                        file_collocates.add(collocate)\n",
    "                count = len(file_collocates)\n",
    "                row.append(count)\n",
    "                word_total += count\n",
    "            row.append(word_total)\n",
    "            ws.append(row)\n",
    "\n",
    "        total_row = ['Total'] + [\n",
    "            sum(ws.cell(row=i + 2, column=j + 2).value or 0 for i in range(len(predefined_words)))\n",
    "            for j in range(len(subset_files))\n",
    "        ] + [\n",
    "            sum(ws.cell(row=i + 2, column=len(subset_files) + 2).value or 0 for i in range(len(predefined_words)))\n",
    "        ]\n",
    "        ws.append(total_row)\n",
    "\n",
    "        # --- 5. Write selected collocates and pairs ---\n",
    "        ws.append([])\n",
    "        ws.append(['Selected Significant Collocates:'])\n",
    "        for i in range(0, len(selected_collocates), 10):\n",
    "            ws.append(selected_collocates[i:i + 10])\n",
    "\n",
    "        # Optional: Write keyword pairs for reference\n",
    "        pair_collocates = [\n",
    "            f\"{pair[0]} + {pair[1]}\" for pair in keyword_pairs\n",
    "            if pair[0] in selected_collocates and pair[1] in selected_collocates\n",
    "        ]\n",
    "        if pair_collocates:\n",
    "            ws.append([])\n",
    "            ws.append(['Keyword Pairs (Target + Significant Collocate):'])\n",
    "            for i in range(0, len(pair_collocates), 5):\n",
    "                ws.append(pair_collocates[i:i + 5])\n",
    "\n",
    "        ws.append([])\n",
    "        ws.append(['p-value threshold:', alpha])\n",
    "        ws.append(['window size:', window])\n",
    "        ws.append(['minimum count threshold:', min_count])\n",
    "\n",
    "        output_now = input(f\"Do you want to save the results for Hypothesis {index + 1} now? (yes/no): \").strip().lower()\n",
    "        if output_now == 'yes':\n",
    "            if 'concordances' not in os.listdir():\n",
    "                os.mkdir('concordances')\n",
    "            wb.save(output_filepath)\n",
    "            print(f\"Results up to Hypothesis {index + 1} saved to {output_filepath}.\")\n",
    "\n",
    "        exit_now = input(\"Do you want to exit after this hypothesis? (yes/no): \").strip().lower()\n",
    "        if exit_now == 'yes':\n",
    "            print(\"Exiting the program.\")\n",
    "            return\n",
    "\n",
    "    # Remove default 'Sheet' if present\n",
    "    if 'Sheet' in wb.sheetnames:\n",
    "        del wb['Sheet']\n",
    "\n",
    "    if 'concordances' not in os.listdir():\n",
    "        os.mkdir('concordances')\n",
    "    wb.save(output_filepath)\n",
    "    print(f'Concordance has been saved to {output_filepath}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f91ecd-e99c-4114-9772-f1cb84301ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import nltk\n",
    "from scipy.stats import fisher_exact\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from itertools import combinations\n",
    "\n",
    "# Function to prompt the user to select text files based on patterns\n",
    "def prompt_pattern_files(text_files, pattern):\n",
    "    selected_files = [file for file in text_files if file.startswith(pattern)]\n",
    "    return selected_files\n",
    "\n",
    "def generate_keyword_pairs(predefined_words):\n",
    "    \"\"\"\n",
    "    Generate all possible combinations of keyword pairs from the predefined word list.\n",
    "    \"\"\"\n",
    "    return list(combinations(predefined_words, 2))\n",
    "\n",
    "def prompt_files(text_files, purpose):\n",
    "    text_files = sorted(text_files, key=custom_file_sort_key)  # Custom sort for files\n",
    "    print(f\"Select the files for {purpose}:\")\n",
    "    for i, file in enumerate(text_files, start=1):\n",
    "        print(f\"{i}. {file}\")\n",
    "    \n",
    "    selection = input(\"Enter the number of the file, a range (e.g., 1-3), multiple ranges (e.g., 1-3,5-7), a text pattern to select files, or type 'all' to select all files: \").strip()\n",
    "    selected_files = []\n",
    "    \n",
    "    if selection.lower() == 'all':\n",
    "        selected_files = text_files\n",
    "    else:\n",
    "        # Split the input by commas to handle multiple ranges or numbers\n",
    "        parts = selection.split(',')\n",
    "        for part in parts:\n",
    "            part = part.strip()\n",
    "            if '-' in part:  # If the part is a range\n",
    "                try:\n",
    "                    start, end = map(int, part.split('-'))\n",
    "                    selected_files.extend(text_files[start-1:end])\n",
    "                except ValueError:\n",
    "                    print(f\"Invalid range: {part}. Please provide ranges like '1-3'.\")\n",
    "            elif part.isdigit():  # If the part is a single number\n",
    "                try:\n",
    "                    selected_files.append(text_files[int(part) - 1])\n",
    "                except IndexError:\n",
    "                    print(f\"Invalid number: {part}. Please select numbers from the list.\")\n",
    "            else:  # If the part is treated as a pattern\n",
    "                selected_files.extend(prompt_pattern_files(text_files, part))\n",
    "    \n",
    "    # Remove duplicates and sort the selected files\n",
    "    selected_files = sorted(set(selected_files), key=custom_file_sort_key)\n",
    "    \n",
    "    print(\"Selected files:\")\n",
    "    for file in selected_files:\n",
    "        print(file)\n",
    "    \n",
    "    return selected_files\n",
    "\n",
    "# Custom sort key for file names\n",
    "def custom_file_sort_key(filename):\n",
    "    # Prioritize 'preface' higher than patterns like 'I.1'\n",
    "    if 'preface' in filename.lower():\n",
    "        return ('', filename.lower())  # Sort 'preface' first\n",
    "    return (filename.lower(),)\n",
    "\n",
    "# Function to process text files\n",
    "def process_text_files(file_paths):\n",
    "    combined_text = \"\"\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            combined_text += file.read().lower() + \" \"\n",
    "    tokens = nltk.wordpunct_tokenize(combined_text)\n",
    "    return nltk.Text(tokens)\n",
    "\n",
    "# Function to find .txt files in a directory\n",
    "def find_text_files(directory):\n",
    "    return sorted([f for f in os.listdir(directory) if f.endswith('.txt')], key=custom_file_sort_key)  # Custom sort\n",
    "\n",
    "# Function to list subfolders in the current directory\n",
    "def list_subfolders():\n",
    "    return sorted([f.name for f in os.scandir() if f.is_dir()])  # Sort folders alphabetically\n",
    "\n",
    "# Function to prompt the user to select a subfolder or the current directory\n",
    "def prompt_subfolder(subfolders):\n",
    "    print(\"Select a subfolder or the current working directory:\")\n",
    "    print(\"0. Current Working Directory\")\n",
    "    for i, subfolder in enumerate(subfolders, start=1):\n",
    "        print(f\"{i}. {subfolder}\")\n",
    "    selected_index = int(input(\"Enter the number of the subfolder: \"))\n",
    "    return None if selected_index == 0 else subfolders[selected_index - 1]\n",
    "\n",
    "# Function to get predefined target words\n",
    "def get_predefined_target_words():\n",
    "    return [\n",
    "        ['citoyen', 'cour', 'domain', 'ressort'],  # List 1\n",
    "        ['guerr', 'paix', 'police', 'religion'],  # List 2\n",
    "        ['confess', 'demon', 'demoniaqu', 'diabl',\n",
    "         'diabol', 'dieu', 'divin', \n",
    "        'hebrieu', 'impiet', 'preuv', 'question',   'sathan', \n",
    "        'sorceller', 'sorci',  'statut', 'sujet'],  # List 3\n",
    "        ['arrest',  'conseil', 'conseiller', 'consul', \n",
    "         'couron', 'édict', 'iurisdict', 'jug', 'magistrat',\n",
    "         'offic', 'offici', 'ordon', 'parlement',\n",
    "        'seigneur', 'seigneurial', 'statut'],  # List 4\n",
    "        ['absolu', 'bien', 'chos', 'civil', 'droit', 'estat', 'just', 'justic',\n",
    "         'loi', 'maiest', 'princ', 'puissanc',\n",
    "        'republ', 'roy', 'royal', 'royaum', 'souverain', 'souverainet', 'sujet']  # List 5\n",
    "    ]\n",
    "\n",
    "# Function to choose subdirectory for stopwords csv file\n",
    "def choose_subdirectory(subdirectories):\n",
    "    print(\"Select a subdirectory:\")\n",
    "    print(\"0. Current Working Directory\")\n",
    "    for i, subdir in enumerate(subdirectories, start=1):\n",
    "        print(f\"{i}. {subdir}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter your choice: \"))\n",
    "            if 0 <= choice <= len(subdirectories):\n",
    "                return None if choice == 0 else subdirectories[choice - 1]\n",
    "            else:\n",
    "                print(\"Invalid selection. Please try again.\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a number.\")\n",
    "\n",
    "# Function to read stopwords from a csv file\n",
    "def read_stopwords(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        stopwords = []\n",
    "        for row in reader:\n",
    "            for word in row:\n",
    "                stopwords.extend(word.split(','))\n",
    "        return [word.strip() for word in stopwords]\n",
    "\n",
    "# Function to find .csv files in a directory\n",
    "def find_csv_files(directory):\n",
    "    return sorted([f for f in os.listdir(directory) if f.endswith('.csv')])  # Sort files alphabetically\n",
    "\n",
    "# Function to select files for the stopwords\n",
    "def select_stopwords_file():\n",
    "    print('Stopwords file selection')\n",
    "    stopwords_subfolders = list_subfolders()\n",
    "    selected_stopwords_subfolder = choose_subdirectory(stopwords_subfolders)\n",
    "    \n",
    "    # Check if the user selected a subfolder or the current directory\n",
    "    stopwords_subfolder_path = os.getcwd() if selected_stopwords_subfolder is None else os.path.join(os.getcwd(), selected_stopwords_subfolder)\n",
    "    \n",
    "    # Find .csv files in the selected directory\n",
    "    stopwords_files = find_csv_files(stopwords_subfolder_path)\n",
    "    if stopwords_files:\n",
    "        print('Select a stopwords file from the following list:')\n",
    "        # Prompt the user to select a single .csv file\n",
    "        selected_file = prompt_files(stopwords_files, \"stopwords file\")\n",
    "        if selected_file:\n",
    "            return selected_file[0], stopwords_subfolder_path  # Return the first selected file and its path\n",
    "        else:\n",
    "            print(\"No stopwords file selected.\")\n",
    "            return None, None\n",
    "    else:\n",
    "        print(f\"No .csv stopwords files found in '{selected_stopwords_subfolder}'.\")\n",
    "        return None, None\n",
    "\n",
    "# Function to select files for the rate dictionary\n",
    "def select_rate_dictionary_files():\n",
    "    print('Rate dictionary file selection')\n",
    "    rate_dictionary_subfolders = list_subfolders()\n",
    "    selected_rate_dictionary_subfolder = choose_subdirectory(rate_dictionary_subfolders)\n",
    "    \n",
    "    # Check if the user selected a subfolder or the current directory\n",
    "    rate_dictionary_subfolder_path = os.getcwd() if selected_rate_dictionary_subfolder is None else os.path.join(os.getcwd(), selected_rate_dictionary_subfolder)\n",
    "    \n",
    "    # Find .txt files in the selected directory\n",
    "    rate_dictionary_files = find_text_files(rate_dictionary_subfolder_path)\n",
    "    if rate_dictionary_files:\n",
    "        print('Select one or more rate dictionary files from the following list:')\n",
    "        selected_files = prompt_files(rate_dictionary_files, \"rate dictionary\")\n",
    "        if selected_files:\n",
    "            return selected_files, rate_dictionary_subfolder_path  # Return the selected files and their path\n",
    "        else:\n",
    "            print(\"No rate dictionary files selected.\")\n",
    "            return [], None\n",
    "    else:\n",
    "        print(f\"No .txt rate dictionary files found in '{selected_rate_dictionary_subfolder}'.\")\n",
    "        return [], None\n",
    "\n",
    "def select_existing_xlsx_file():\n",
    "    print(\"Select a directory to search for .xlsx files:\")\n",
    "    subfolders = list_subfolders()\n",
    "    selected_subfolder = choose_subdirectory(subfolders)\n",
    "\n",
    "    # Check if the user selected a subfolder or the current directory\n",
    "    folder_path = os.getcwd() if selected_subfolder is None else os.path.join(os.getcwd(), selected_subfolder)\n",
    "\n",
    "    # Find .xlsx files in the selected directory\n",
    "    xlsx_files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]\n",
    "    if xlsx_files:\n",
    "        print(\"Select an existing .xlsx file from the following list:\")\n",
    "        for i, file in enumerate(xlsx_files, start=1):\n",
    "            print(f\"{i}. {file}\")\n",
    "        while True:\n",
    "            try:\n",
    "                choice = int(input(\"Enter the number of the file you want to select or 0 to cancel: \"))\n",
    "                if 0 <= choice <= len(xlsx_files):\n",
    "                    return None if choice == 0 else os.path.join(folder_path, xlsx_files[choice - 1])\n",
    "                else:\n",
    "                    print(\"Invalid selection. Please try again.\")\n",
    "            except ValueError:\n",
    "                print(\"Please enter a number.\")\n",
    "    else:\n",
    "        print(f\"No .xlsx files found in '{folder_path}'.\")\n",
    "        return None\n",
    "\n",
    "# Utility function to clean file names\n",
    "def clean_file_name(file_name):\n",
    "    \"\"\"\n",
    "    Clean the file name for display, including replacing specific patterns.\n",
    "    \"\"\"\n",
    "    file_name = file_name.replace('_', '').replace('corrected', '').replace('stemmed', '')\n",
    "    if 'Démonomanie' in file_name:\n",
    "        file_name = file_name.replace('Démonomanie', 'Dém')\n",
    "    if 'République' in file_name:\n",
    "        file_name = file_name.replace('République', 'Rép')\n",
    "   \n",
    "    # Replace '911' with '11' and '910' with '10' (NEW CHANGE)\n",
    "    file_name = file_name.replace('911', '11').replace('910', '10')  # <--- CHANGE HERE\n",
    "   \n",
    "    return os.path.splitext(file_name)[0]\n",
    "\n",
    "# Function to process the subset of text files for KWIC and counts\n",
    "def process_subset_files(file_paths):\n",
    "    combined_text = \"\"\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as f:\n",
    "            file_contents = f.read().lower()\n",
    "            combined_text += file_contents + \" \"\n",
    "    tokens = nltk.wordpunct_tokenize(combined_text)\n",
    "    return tokens\n",
    "\n",
    "def get_kwic(sometargetterm, somelistofwords, window=10, excl_target=True, source_file=None):\n",
    "    kwics = []\n",
    "    for n, w in enumerate(somelistofwords):\n",
    "        if w == sometargetterm:\n",
    "            start = max(0, n - window)\n",
    "            end = min(n + window + 1, len(somelistofwords))\n",
    "            if excl_target:\n",
    "                # Updated: Exclude keyword itself from the window\n",
    "                k = [word for word in (somelistofwords[start:n] + somelistofwords[n + 1:end]) if word != sometargetterm]\n",
    "            else:\n",
    "                k = somelistofwords[start:end]\n",
    "            kwics.append((k, source_file))\n",
    "    return kwics\n",
    "   \n",
    "\n",
    "def add_to_count_dict(word, count_dict):\n",
    "    if word in count_dict:\n",
    "        count_dict[word] += 1\n",
    "    else:\n",
    "        count_dict[word] = 1\n",
    "\n",
    "def get_fishers(someword, somecountdict, someratedict, alternative='greater'):\n",
    "    r = someratedict[someword]\n",
    "    wc = sum(somecountdict.values())\n",
    "    a = somecountdict[someword]\n",
    "    b = wc - a\n",
    "    c = round(r * wc)\n",
    "    d = wc - c\n",
    "    p = fisher_exact([[a, b], [c, d]], alternative=alternative)[1]\n",
    "    return p\n",
    "\n",
    "def filter_collocates_with_removal(collocates, collocate_counts):\n",
    "    \"\"\"\n",
    "    Allow the user to filter the list of significant collocates and remove any selected collocates in error.\n",
    "\n",
    "    Parameters:\n",
    "        collocates (list): A sorted list of significant collocates.\n",
    "        collocate_counts (dict): A dictionary of collocates and their counts.\n",
    "\n",
    "    Returns:\n",
    "        list: A filtered list of collocates selected by the user.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            min_count = int(input(\"Enter the minimum count threshold for collocates to include: \").strip())\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid number.\")\n",
    "\n",
    "    # Filter collocates by minimum count\n",
    "    filtered_collocates = [collocate for collocate in collocates if collocate_counts[collocate] >= min_count]\n",
    "    print(f\"\\nCollocates with counts >= {min_count}:\")\n",
    "    for i, collocate in enumerate(filtered_collocates, start=1):\n",
    "        print(f\"{i}. {collocate} (Count: {collocate_counts[collocate]})\")\n",
    "\n",
    "    print(\"\\nYou can select collocates by entering:\")\n",
    "    print(\"- A single number (e.g., 3) to select one collocate.\")\n",
    "    print(\"- A range of numbers (e.g., 3-6) to select multiple collocates.\")\n",
    "    print(\"- Multiple selections separated by commas (e.g., 3,5-7,9).\")\n",
    "    print(\"- Type 'all' to select all collocates.\")\n",
    "    print(\"- Type 'done' to finalize your selection.\")\n",
    "\n",
    "    selected_collocates = []\n",
    "\n",
    "    while True:\n",
    "        selection = input(\"Enter your selection: \").strip()\n",
    "        if selection.lower() == 'done':\n",
    "            break\n",
    "        elif selection.lower() == 'all':\n",
    "            selected_collocates = filtered_collocates\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            parts = selection.split(',')\n",
    "            for part in parts:\n",
    "                part = part.strip()\n",
    "                if '-' in part:  # Handle ranges\n",
    "                    start, end = map(int, part.split('-'))\n",
    "                    selected_collocates.extend(filtered_collocates[start-1:end])\n",
    "                elif part.isdigit():  # Handle single numbers\n",
    "                    selected_collocates.append(filtered_collocates[int(part) - 1])\n",
    "                else:\n",
    "                    print(f\"Invalid selection: {part}. Please try again.\")\n",
    "        except (ValueError, IndexError):\n",
    "            print(f\"Invalid input: {selection}. Please try again.\")\n",
    "\n",
    "        # Remove duplicates and sort the selected collocates\n",
    "        selected_collocates = sorted(set(selected_collocates), key=filtered_collocates.index)\n",
    "\n",
    "        print(\"Currently selected collocates:\")\n",
    "        for collocate in selected_collocates:\n",
    "            print(collocate)\n",
    "\n",
    "    # Allow users to review and remove collocates selected in error\n",
    "    while True:\n",
    "        print(\"\\nFinalized collocates:\")\n",
    "        for i, collocate in enumerate(selected_collocates, start=1):\n",
    "            print(f\"{i}. {collocate}\")\n",
    "\n",
    "        remove_error = input(\n",
    "            \"Would you like to remove any collocates selected in error? (yes/no): \"\n",
    "        ).strip().lower()\n",
    "        if remove_error == 'yes':\n",
    "            remove_selection = input(\n",
    "                \"Enter the numbers of the collocates to remove (e.g., 2,4-5): \"\n",
    "            ).strip()\n",
    "            try:\n",
    "                parts = remove_selection.split(',')\n",
    "                to_remove = []\n",
    "                for part in parts:\n",
    "                    part = part.strip()\n",
    "                    if '-' in part:  # Handle ranges\n",
    "                        start, end = map(int, part.split('-'))\n",
    "                        to_remove.extend(selected_collocates[start-1:end])\n",
    "                    elif part.isdigit():  # Handle single numbers\n",
    "                        to_remove.append(selected_collocates[int(part) - 1])\n",
    "                    else:\n",
    "                        print(f\"Invalid selection: {part}. Please try again.\")\n",
    "                selected_collocates = [\n",
    "                    collocate for collocate in selected_collocates\n",
    "                    if collocate not in to_remove\n",
    "                ]\n",
    "            except (ValueError, IndexError):\n",
    "                print(f\"Invalid input: {remove_selection}. Please try again.\")\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return selected_collocates, min_count\n",
    "\n",
    "def search_concordance(text_data, predefined_word_lists, stops, alpha):\n",
    "    window = int(input(f\"Enter the window size for concordance: \").strip())\n",
    "\n",
    "    subset_files = prompt_files(find_text_files(os.getcwd()), \"KWIC and key word counts\")\n",
    "\n",
    "    append_to_existing = input(\"Do you want to append results to an existing .xlsx file? (yes/no): \").strip().lower()\n",
    "\n",
    "    if append_to_existing == 'yes':\n",
    "        existing_file = select_existing_xlsx_file()\n",
    "        if existing_file:\n",
    "            wb = load_workbook(existing_file)\n",
    "            print(f\"Appending to existing file: {existing_file}\")\n",
    "        else:\n",
    "            print(\"No existing workbook selected. Creating a new workbook instead.\")\n",
    "            wb = Workbook()\n",
    "            if 'Sheet' in wb.sheetnames:\n",
    "                del wb['Sheet']\n",
    "    else:\n",
    "        wb = Workbook()\n",
    "        print(\"Creating a new workbook.\")\n",
    "        if 'Sheet' in wb.sheetnames:\n",
    "            del wb['Sheet']\n",
    "\n",
    "    if append_to_existing == 'yes' and existing_file:\n",
    "        output_filepath = existing_file\n",
    "    else:\n",
    "        output_filename = input(\"Enter a unique name for the .xlsx file (without extension): \").strip()\n",
    "        if not output_filename:\n",
    "            output_filename = \"distinct_collocates\"\n",
    "        output_filepath = os.path.join(\"concordances\", f\"{output_filename}.xlsx\")\n",
    "\n",
    "    # Initialize the dictionary here\n",
    "    unique_keyword_collocate_pairs_by_file = {}\n",
    "\n",
    "    for index, predefined_words in enumerate(predefined_word_lists):\n",
    "        skip = input(f\"Do you want to skip processing Hypothesis {index + 1}? (yes/no): \").strip().lower()\n",
    "        if skip == 'yes':\n",
    "            print(f\"Skipping Hypothesis {index + 1}.\")\n",
    "            continue\n",
    "\n",
    "        ws = wb.create_sheet(title=f\"Hypothesis {index + 1}\")\n",
    "\n",
    "        headers = ['Word'] + [clean_file_name(file) for file in subset_files] + ['Total']\n",
    "        ws.append(headers)\n",
    "\n",
    "        predefined_words = sorted(predefined_words)\n",
    "\n",
    "        # Generate keyword pairs from predefined words\n",
    "        keyword_pairs = generate_keyword_pairs(predefined_words)\n",
    "\n",
    "        all_significant_collocates = set()\n",
    "        collocate_counts = {}\n",
    "        counts_by_file = {}\n",
    "\n",
    "        for file in subset_files:\n",
    "            file_path = os.path.join(os.getcwd(), file)\n",
    "            subset_tokens = process_subset_files([file_path])\n",
    "            counts = {}\n",
    "\n",
    "            unique_keyword_collocate_pairs_per_file = {}\n",
    "\n",
    "            for word in predefined_words:\n",
    "                kwics = get_kwic(word, subset_tokens, window, source_file=file)\n",
    "            \n",
    "                if word not in unique_keyword_collocate_pairs_per_file:\n",
    "                    unique_keyword_collocate_pairs_per_file[word] = set()\n",
    "            \n",
    "                for k, source_file in kwics:\n",
    "                    unique_collocates = set(k)  # Ensure uniqueness\n",
    "                    for collocate in unique_collocates:\n",
    "                        if collocate not in stops and collocate != word:  # Exclude stopwords and the keyword itself\n",
    "                            add_to_count_dict(collocate, counts)\n",
    "                            unique_keyword_collocate_pairs_per_file[word].add(collocate)\n",
    "\n",
    "                            # Check if the collocate is a keyword and form pairs\n",
    "                            if collocate in predefined_words and collocate != word:\n",
    "                                pair = (word, collocate)\n",
    "                                if pair in keyword_pairs:\n",
    "                                    add_to_count_dict(pair, counts)\n",
    "\n",
    "            counts_by_file[file] = counts\n",
    "            unique_keyword_collocate_pairs_by_file[file] = unique_keyword_collocate_pairs_per_file\n",
    "\n",
    "        total_wc = sum(count for counts in counts_by_file.values() for count in counts.values())\n",
    "        rates = {word: count / total_wc for counts in counts_by_file.values() for word, count in counts.items()}\n",
    "\n",
    "        for file, counts in counts_by_file.items():\n",
    "            for word, count in sorted(counts.items(), key=lambda item: item[1], reverse=True):\n",
    "                if word not in stops:\n",
    "                    p_value = get_fishers(word, counts, rates, alternative='greater')\n",
    "                    if p_value < alpha:\n",
    "                        all_significant_collocates.add(word)\n",
    "                        collocate_counts[word] = collocate_counts.get(word, 0) + count\n",
    "\n",
    "        print(f\"\\nPredefined words for Hypothesis {index + 1}: {', '.join(predefined_words)}\")\n",
    "        all_significant_collocates = sorted(all_significant_collocates)\n",
    "        selected_collocates, min_count = filter_collocates_with_removal(all_significant_collocates, collocate_counts)\n",
    "\n",
    "        for word in predefined_words:\n",
    "            row = [word]\n",
    "            word_total = 0\n",
    "            for file in subset_files:\n",
    "                unique_collocates_for_word = unique_keyword_collocate_pairs_by_file[file].get(word, set())\n",
    "                # Filter the unique collocates to only include the selected collocates\n",
    "                filtered_collocates_for_word = [collocate for collocate in unique_collocates_for_word if collocate in selected_collocates]\n",
    "        \n",
    "                #print(f\"Keyword: {word}, File: {file}, Filtered Unique Collocates: {filtered_collocates_for_word}\")\n",
    "        \n",
    "                # Count the filtered collocates\n",
    "                count = len(filtered_collocates_for_word)\n",
    "                row.append(count)\n",
    "                word_total += count\n",
    "            row.append(word_total)\n",
    "            ws.append(row)\n",
    "\n",
    "\n",
    "        total_row = ['Total'] + [\n",
    "            sum(ws.cell(row=i + 2, column=j + 2).value or 0 for i in range(len(predefined_words)))\n",
    "            for j in range(len(subset_files))\n",
    "        ] + [\n",
    "            sum(ws.cell(row=i + 2, column=len(subset_files) + 2).value or 0 for i in range(len(predefined_words)))\n",
    "        ]\n",
    "        ws.append(total_row)\n",
    "        \n",
    "        \n",
    "        # Include generated pairs in the list of selected collocates\n",
    "        pair_collocates = [\n",
    "            f\"{pair[0]} + {pair[1]}\" for pair in keyword_pairs\n",
    "            if pair[1] in selected_collocates\n",
    "        ]\n",
    "\n",
    "        # Write selected significant collocates, including pairs, to the sheet\n",
    "        ws.append([])\n",
    "        ws.append(['Selected Significant Collocates (Including Keyword Pairs):'])\n",
    "        for i in range(0, len(selected_collocates), 10):\n",
    "            ws.append(selected_collocates[i:i + 10])\n",
    "        \n",
    "        # Write keyword pairs separately for reference\n",
    "        if pair_collocates:\n",
    "            ws.append([])\n",
    "            ws.append(['Keyword Pairs (Target + Significant Collocate):'])\n",
    "            for i in range(0, len(pair_collocates), 5):  # Group pairs for better readability\n",
    "                ws.append(pair_collocates[i:i + 5])\n",
    "\n",
    "        ws.append([])\n",
    "        ws.append(['p-value threshold:', alpha])\n",
    "        ws.append(['window size:', window])\n",
    "        ws.append(['minimum count threshold:', min_count])\n",
    "\n",
    "        output_now = input(f\"Do you want to save the results for Hypothesis {index + 1} now? (yes/no): \").strip().lower()\n",
    "        if output_now == 'yes':\n",
    "            if 'concordances' not in os.listdir():\n",
    "                os.mkdir('concordances')\n",
    "            wb.save(output_filepath)\n",
    "            print(f\"Results up to Hypothesis {index + 1} saved to {output_filepath}.\")\n",
    "\n",
    "        exit_now = input(\"Do you want to exit after this hypothesis? (yes/no): \").strip().lower()\n",
    "        if exit_now == 'yes':\n",
    "            print(\"Exiting the program.\")\n",
    "            return\n",
    "\n",
    "    if 'Sheet' in wb.sheetnames:\n",
    "        del wb['Sheet']\n",
    "\n",
    "    if 'concordances' not in os.listdir():\n",
    "        os.mkdir('concordances')\n",
    "    wb.save(output_filepath)\n",
    "    print(f'Concordance has been saved to {output_filepath}.')\n",
    "    \n",
    "# Example usage\n",
    "use_predefined = input(\"Do you want to use predefined target word lists (yes/no)? \").strip().lower() == 'yes'\n",
    "if use_predefined:\n",
    "    predefined_word_lists = get_predefined_target_words()\n",
    "else:\n",
    "    predefined_word_lists = [input(\"Enter words for a group separated by spaces: \").strip().split() for _ in range(5)]\n",
    "\n",
    "alpha = float(input(\"Enter the value for alpha: \").strip())\n",
    "\n",
    "stopwords_file, stopwords_path = select_stopwords_file()\n",
    "if stopwords_file:\n",
    "    stops = read_stopwords(os.path.join(stopwords_path, stopwords_file))\n",
    "    rate_dictionary_files, rate_dictionary_path = select_rate_dictionary_files()\n",
    "    if rate_dictionary_files:\n",
    "        search_concordance(rate_dictionary_files, predefined_word_lists, stops, alpha)\n",
    "    else:\n",
    "        print(\"No rate dictionary files selected.\")\n",
    "else:\n",
    "    print(\"No stopwords file selected.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256f3d9e-56c3-49f2-8c2b-afa12c39f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "his code seems to be creating the pair_collocates list only if the second item in each pair is in the selected collocates list. But this approach does not work because the keywords are excluded from the list of collocates users can select. The desired outcome is that pair_collocates is generated if the second item matches an item in all_significant_collocates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0267738c-f380-41d8-874a-1288fe8c8dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to use predefined target word lists (yes/no)?  yes\n",
      "Enter the value for alpha:  0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords file selection\n",
      "Select a subdirectory:\n",
      "0. Current Working Directory\n",
      "1. .ipynb_checkpoints\n",
      "2. concordances\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a stopwords file from the following list:\n",
      "Select the files for stopwords file:\n",
      "1. stop_words.csv\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of the file, a range (e.g., 1-3), multiple ranges (e.g., 1-3,5-7), a text pattern to select files, or type 'all' to select all files:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected files:\n",
      "stop_words.csv\n",
      "Rate dictionary file selection\n",
      "Select a subdirectory:\n",
      "0. Current Working Directory\n",
      "1. .ipynb_checkpoints\n",
      "2. concordances\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select one or more rate dictionary files from the following list:\n",
      "Select the files for rate dictionary:\n",
      "1. Démonomanie preface Repair_corrected_stemmed.txt\n",
      "2. République preface_corrected_stemmed.txt\n",
      "3. Discours des raisons_corrected_stemmed.txt\n",
      "4. Démonomanie I.1_corrected_stemmed.txt\n",
      "5. Démonomanie I.2_corrected_stemmed.txt\n",
      "6. Démonomanie I.3_corrected_stemmed.txt\n",
      "7. Démonomanie I.4_corrected_stemmed.txt\n",
      "8. Démonomanie I.5_corrected_stemmed.txt\n",
      "9. Démonomanie I.6_corrected_stemmed.txt\n",
      "10. Démonomanie I.7_corrected_stemmed.txt\n",
      "11. Démonomanie II.1_corrected_stemmed.txt\n",
      "12. Démonomanie II.2_corrected_stemmed.txt\n",
      "13. Démonomanie II.3_corrected_stemmed.txt\n",
      "14. Démonomanie II.4_corrected_stemmed.txt\n",
      "15. Démonomanie II.5_corrected_stemmed.txt\n",
      "16. Démonomanie II.6_corrected_stemmed.txt\n",
      "17. Démonomanie II.7_corrected_stemmed.txt\n",
      "18. Démonomanie II.8_corrected_stemmed.txt\n",
      "19. Démonomanie III.1_corrected_stemmed.txt\n",
      "20. Démonomanie III.2_corrected_stemmed.txt\n",
      "21. Démonomanie III.3_corrected_stemmed.txt\n",
      "22. Démonomanie III.4_corrected_stemmed.txt\n",
      "23. Démonomanie III.5_corrected_stemmed.txt\n",
      "24. Démonomanie III.6_corrected_stemmed.txt\n",
      "25. Démonomanie IV.1_corrected_stemmed.txt\n",
      "26. Démonomanie IV.2_corrected_stemmed.txt\n",
      "27. Démonomanie IV.3_corrected_stemmed.txt\n",
      "28. Démonomanie IV.4_corrected_stemmed.txt\n",
      "29. Démonomanie IV.5_corrected_stemmed.txt\n",
      "30. Harangue - Fontainebleau_corrected_stemmed.txt\n",
      "31. Harangue - lit de justice_corrected_stemmed.txt\n",
      "32. Harangue - Orléans 2_corrected_stemmed.txt\n",
      "33. Harangue - Orléans_corrected_stemmed.txt\n",
      "34. Harangue - ouverture de parlement_corrected_stemmed.txt\n",
      "35. Harangue - parlement 2_corrected_stemmed.txt\n",
      "36. Harangue - parlement 3_corrected_stemmed.txt\n",
      "37. Harangue - parlement_corrected_stemmed.txt\n",
      "38. Harangue - Poissy_corrected_stemmed.txt\n",
      "39. Harangue - religion_corrected_stemmed.txt\n",
      "40. Harangue - Rouen_corrected_stemmed.txt\n",
      "41. Harangue - Saint Germain_corrected_stemmed.txt\n",
      "42. Harangue - septembre_corrected_stemmed.txt\n",
      "43. La réponse_corrected_stemmed.txt\n",
      "44. Le paradoxe_corrected_stemmed.txt\n",
      "45. Lettre_corrected_stemmed.txt\n",
      "46. Lit de justice_corrected_stemmed.txt\n",
      "47. Memoire - le but_corrected_stemmed.txt\n",
      "48. Memoire - Namur_corrected_stemmed.txt\n",
      "49. Memoire au roi_corrected_stemmed.txt\n",
      "50. Memoires d'État Refuge_corrected_stemmed.txt\n",
      "51. Memoires d'état_corrected_stemmed.txt\n",
      "52. Recueil_corrected_stemmed.txt\n",
      "53. Remonstrances - parlement_corrected_stemmed.txt\n",
      "54. Remonstrances - Royaume_corrected_stemmed.txt\n",
      "55. République I.1_corrected_stemmed.txt\n",
      "56. République I.2_corrected_stemmed.txt\n",
      "57. République I.3_corrected_stemmed.txt\n",
      "58. République I.4_corrected_stemmed.txt\n",
      "59. République I.5_corrected_stemmed.txt\n",
      "60. République I.6_corrected_stemmed.txt\n",
      "61. République I.7_corrected_stemmed.txt\n",
      "62. République I.8_corrected_stemmed.txt\n",
      "63. République I.910_corrected_stemmed.txt\n",
      "64. République I.911_corrected_stemmed.txt\n",
      "65. République I.9_corrected_stemmed.txt\n",
      "66. République II.1_corrected_stemmed.txt\n",
      "67. République II.2_corrected_stemmed.txt\n",
      "68. République II.3_corrected_stemmed.txt\n",
      "69. République II.4_corrected_stemmed.txt\n",
      "70. République II.5_corrected_stemmed.txt\n",
      "71. République II.6_corrected_stemmed.txt\n",
      "72. République II.7_corrected_stemmed.txt\n",
      "73. République III.1_corrected_stemmed.txt\n",
      "74. République III.2_corrected_stemmed.txt\n",
      "75. République III.3_corrected_stemmed.txt\n",
      "76. République III.4_corrected_stemmed.txt\n",
      "77. République III.5_corrected_stemmed.txt\n",
      "78. République III.6_corrected_stemmed.txt\n",
      "79. République III.7_corrected_stemmed.txt\n",
      "80. République IV.1_corrected_stemmed.txt\n",
      "81. République IV.2_corrected_stemmed.txt\n",
      "82. République IV.3_corrected_stemmed.txt\n",
      "83. République IV.4_corrected_stemmed.txt\n",
      "84. République IV.5_corrected_stemmed.txt\n",
      "85. République IV.6_corrected_stemmed.txt\n",
      "86. République IV.7_corrected_stemmed.txt\n",
      "87. République V.1_corrected_stemmed.txt\n",
      "88. République V.2_corrected_stemmed.txt\n",
      "89. République V.3_corrected_stemmed.txt\n",
      "90. République V.4_corrected_stemmed.txt\n",
      "91. République V.5_corrected_stemmed.txt\n",
      "92. République VI.1_corrected_stemmed.txt\n",
      "93. République VI.2_corrected_stemmed.txt\n",
      "94. République VI.3_corrected_stemmed.txt\n",
      "95. République VI.4_corrected_stemmed.txt\n",
      "96. République VI.5_corrected_stemmed.txt\n",
      "97. République VI.6_corrected_stemmed.txt\n",
      "98. Théatre I_corrected_stemmed.txt\n",
      "99. Théatre II_corrected_stemmed.txt\n",
      "100. Théatre III_corrected_stemmed.txt\n",
      "101. Théatre IV_corrected_stemmed.txt\n",
      "102. Théatre summary_corrected_stemmed.txt\n",
      "103. Théatre V_corrected_stemmed.txt\n",
      "104. Traite Justice V_corrected_stemmed.txt\n",
      "105. Traite Justice VI_corrected_stemmed.txt\n",
      "106. Traite Justice VII_corrected_stemmed.txt\n",
      "107. Traité Justice I_corrected_stemmed.txt\n",
      "108. Traité Justice II_corrected_stemmed.txt\n",
      "109. Traité Justice III_corrected_stemmed.txt\n",
      "110. Traité Justice IV_corrected_stemmed.txt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of the file, a range (e.g., 1-3), multiple ranges (e.g., 1-3,5-7), a text pattern to select files, or type 'all' to select all files:  all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected files:\n",
      "Démonomanie preface Repair_corrected_stemmed.txt\n",
      "République preface_corrected_stemmed.txt\n",
      "Discours des raisons_corrected_stemmed.txt\n",
      "Démonomanie I.1_corrected_stemmed.txt\n",
      "Démonomanie I.2_corrected_stemmed.txt\n",
      "Démonomanie I.3_corrected_stemmed.txt\n",
      "Démonomanie I.4_corrected_stemmed.txt\n",
      "Démonomanie I.5_corrected_stemmed.txt\n",
      "Démonomanie I.6_corrected_stemmed.txt\n",
      "Démonomanie I.7_corrected_stemmed.txt\n",
      "Démonomanie II.1_corrected_stemmed.txt\n",
      "Démonomanie II.2_corrected_stemmed.txt\n",
      "Démonomanie II.3_corrected_stemmed.txt\n",
      "Démonomanie II.4_corrected_stemmed.txt\n",
      "Démonomanie II.5_corrected_stemmed.txt\n",
      "Démonomanie II.6_corrected_stemmed.txt\n",
      "Démonomanie II.7_corrected_stemmed.txt\n",
      "Démonomanie II.8_corrected_stemmed.txt\n",
      "Démonomanie III.1_corrected_stemmed.txt\n",
      "Démonomanie III.2_corrected_stemmed.txt\n",
      "Démonomanie III.3_corrected_stemmed.txt\n",
      "Démonomanie III.4_corrected_stemmed.txt\n",
      "Démonomanie III.5_corrected_stemmed.txt\n",
      "Démonomanie III.6_corrected_stemmed.txt\n",
      "Démonomanie IV.1_corrected_stemmed.txt\n",
      "Démonomanie IV.2_corrected_stemmed.txt\n",
      "Démonomanie IV.3_corrected_stemmed.txt\n",
      "Démonomanie IV.4_corrected_stemmed.txt\n",
      "Démonomanie IV.5_corrected_stemmed.txt\n",
      "Harangue - Fontainebleau_corrected_stemmed.txt\n",
      "Harangue - lit de justice_corrected_stemmed.txt\n",
      "Harangue - Orléans 2_corrected_stemmed.txt\n",
      "Harangue - Orléans_corrected_stemmed.txt\n",
      "Harangue - ouverture de parlement_corrected_stemmed.txt\n",
      "Harangue - parlement 2_corrected_stemmed.txt\n",
      "Harangue - parlement 3_corrected_stemmed.txt\n",
      "Harangue - parlement_corrected_stemmed.txt\n",
      "Harangue - Poissy_corrected_stemmed.txt\n",
      "Harangue - religion_corrected_stemmed.txt\n",
      "Harangue - Rouen_corrected_stemmed.txt\n",
      "Harangue - Saint Germain_corrected_stemmed.txt\n",
      "Harangue - septembre_corrected_stemmed.txt\n",
      "La réponse_corrected_stemmed.txt\n",
      "Le paradoxe_corrected_stemmed.txt\n",
      "Lettre_corrected_stemmed.txt\n",
      "Lit de justice_corrected_stemmed.txt\n",
      "Memoire - le but_corrected_stemmed.txt\n",
      "Memoire - Namur_corrected_stemmed.txt\n",
      "Memoire au roi_corrected_stemmed.txt\n",
      "Memoires d'État Refuge_corrected_stemmed.txt\n",
      "Memoires d'état_corrected_stemmed.txt\n",
      "Recueil_corrected_stemmed.txt\n",
      "Remonstrances - parlement_corrected_stemmed.txt\n",
      "Remonstrances - Royaume_corrected_stemmed.txt\n",
      "République I.1_corrected_stemmed.txt\n",
      "République I.2_corrected_stemmed.txt\n",
      "République I.3_corrected_stemmed.txt\n",
      "République I.4_corrected_stemmed.txt\n",
      "République I.5_corrected_stemmed.txt\n",
      "République I.6_corrected_stemmed.txt\n",
      "République I.7_corrected_stemmed.txt\n",
      "République I.8_corrected_stemmed.txt\n",
      "République I.910_corrected_stemmed.txt\n",
      "République I.911_corrected_stemmed.txt\n",
      "République I.9_corrected_stemmed.txt\n",
      "République II.1_corrected_stemmed.txt\n",
      "République II.2_corrected_stemmed.txt\n",
      "République II.3_corrected_stemmed.txt\n",
      "République II.4_corrected_stemmed.txt\n",
      "République II.5_corrected_stemmed.txt\n",
      "République II.6_corrected_stemmed.txt\n",
      "République II.7_corrected_stemmed.txt\n",
      "République III.1_corrected_stemmed.txt\n",
      "République III.2_corrected_stemmed.txt\n",
      "République III.3_corrected_stemmed.txt\n",
      "République III.4_corrected_stemmed.txt\n",
      "République III.5_corrected_stemmed.txt\n",
      "République III.6_corrected_stemmed.txt\n",
      "République III.7_corrected_stemmed.txt\n",
      "République IV.1_corrected_stemmed.txt\n",
      "République IV.2_corrected_stemmed.txt\n",
      "République IV.3_corrected_stemmed.txt\n",
      "République IV.4_corrected_stemmed.txt\n",
      "République IV.5_corrected_stemmed.txt\n",
      "République IV.6_corrected_stemmed.txt\n",
      "République IV.7_corrected_stemmed.txt\n",
      "République V.1_corrected_stemmed.txt\n",
      "République V.2_corrected_stemmed.txt\n",
      "République V.3_corrected_stemmed.txt\n",
      "République V.4_corrected_stemmed.txt\n",
      "République V.5_corrected_stemmed.txt\n",
      "République VI.1_corrected_stemmed.txt\n",
      "République VI.2_corrected_stemmed.txt\n",
      "République VI.3_corrected_stemmed.txt\n",
      "République VI.4_corrected_stemmed.txt\n",
      "République VI.5_corrected_stemmed.txt\n",
      "République VI.6_corrected_stemmed.txt\n",
      "Théatre I_corrected_stemmed.txt\n",
      "Théatre II_corrected_stemmed.txt\n",
      "Théatre III_corrected_stemmed.txt\n",
      "Théatre IV_corrected_stemmed.txt\n",
      "Théatre summary_corrected_stemmed.txt\n",
      "Théatre V_corrected_stemmed.txt\n",
      "Traite Justice V_corrected_stemmed.txt\n",
      "Traite Justice VI_corrected_stemmed.txt\n",
      "Traite Justice VII_corrected_stemmed.txt\n",
      "Traité Justice I_corrected_stemmed.txt\n",
      "Traité Justice II_corrected_stemmed.txt\n",
      "Traité Justice III_corrected_stemmed.txt\n",
      "Traité Justice IV_corrected_stemmed.txt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the window size for concordance:  15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the files for KWIC and key word counts:\n",
      "1. Démonomanie preface Repair_corrected_stemmed.txt\n",
      "2. République preface_corrected_stemmed.txt\n",
      "3. Discours des raisons_corrected_stemmed.txt\n",
      "4. Démonomanie I.1_corrected_stemmed.txt\n",
      "5. Démonomanie I.2_corrected_stemmed.txt\n",
      "6. Démonomanie I.3_corrected_stemmed.txt\n",
      "7. Démonomanie I.4_corrected_stemmed.txt\n",
      "8. Démonomanie I.5_corrected_stemmed.txt\n",
      "9. Démonomanie I.6_corrected_stemmed.txt\n",
      "10. Démonomanie I.7_corrected_stemmed.txt\n",
      "11. Démonomanie II.1_corrected_stemmed.txt\n",
      "12. Démonomanie II.2_corrected_stemmed.txt\n",
      "13. Démonomanie II.3_corrected_stemmed.txt\n",
      "14. Démonomanie II.4_corrected_stemmed.txt\n",
      "15. Démonomanie II.5_corrected_stemmed.txt\n",
      "16. Démonomanie II.6_corrected_stemmed.txt\n",
      "17. Démonomanie II.7_corrected_stemmed.txt\n",
      "18. Démonomanie II.8_corrected_stemmed.txt\n",
      "19. Démonomanie III.1_corrected_stemmed.txt\n",
      "20. Démonomanie III.2_corrected_stemmed.txt\n",
      "21. Démonomanie III.3_corrected_stemmed.txt\n",
      "22. Démonomanie III.4_corrected_stemmed.txt\n",
      "23. Démonomanie III.5_corrected_stemmed.txt\n",
      "24. Démonomanie III.6_corrected_stemmed.txt\n",
      "25. Démonomanie IV.1_corrected_stemmed.txt\n",
      "26. Démonomanie IV.2_corrected_stemmed.txt\n",
      "27. Démonomanie IV.3_corrected_stemmed.txt\n",
      "28. Démonomanie IV.4_corrected_stemmed.txt\n",
      "29. Démonomanie IV.5_corrected_stemmed.txt\n",
      "30. Harangue - Fontainebleau_corrected_stemmed.txt\n",
      "31. Harangue - lit de justice_corrected_stemmed.txt\n",
      "32. Harangue - Orléans 2_corrected_stemmed.txt\n",
      "33. Harangue - Orléans_corrected_stemmed.txt\n",
      "34. Harangue - ouverture de parlement_corrected_stemmed.txt\n",
      "35. Harangue - parlement 2_corrected_stemmed.txt\n",
      "36. Harangue - parlement 3_corrected_stemmed.txt\n",
      "37. Harangue - parlement_corrected_stemmed.txt\n",
      "38. Harangue - Poissy_corrected_stemmed.txt\n",
      "39. Harangue - religion_corrected_stemmed.txt\n",
      "40. Harangue - Rouen_corrected_stemmed.txt\n",
      "41. Harangue - Saint Germain_corrected_stemmed.txt\n",
      "42. Harangue - septembre_corrected_stemmed.txt\n",
      "43. La réponse_corrected_stemmed.txt\n",
      "44. Le paradoxe_corrected_stemmed.txt\n",
      "45. Lettre_corrected_stemmed.txt\n",
      "46. Lit de justice_corrected_stemmed.txt\n",
      "47. Memoire - le but_corrected_stemmed.txt\n",
      "48. Memoire - Namur_corrected_stemmed.txt\n",
      "49. Memoire au roi_corrected_stemmed.txt\n",
      "50. Memoires d'État Refuge_corrected_stemmed.txt\n",
      "51. Memoires d'état_corrected_stemmed.txt\n",
      "52. Recueil_corrected_stemmed.txt\n",
      "53. Remonstrances - parlement_corrected_stemmed.txt\n",
      "54. Remonstrances - Royaume_corrected_stemmed.txt\n",
      "55. République I.1_corrected_stemmed.txt\n",
      "56. République I.2_corrected_stemmed.txt\n",
      "57. République I.3_corrected_stemmed.txt\n",
      "58. République I.4_corrected_stemmed.txt\n",
      "59. République I.5_corrected_stemmed.txt\n",
      "60. République I.6_corrected_stemmed.txt\n",
      "61. République I.7_corrected_stemmed.txt\n",
      "62. République I.8_corrected_stemmed.txt\n",
      "63. République I.910_corrected_stemmed.txt\n",
      "64. République I.911_corrected_stemmed.txt\n",
      "65. République I.9_corrected_stemmed.txt\n",
      "66. République II.1_corrected_stemmed.txt\n",
      "67. République II.2_corrected_stemmed.txt\n",
      "68. République II.3_corrected_stemmed.txt\n",
      "69. République II.4_corrected_stemmed.txt\n",
      "70. République II.5_corrected_stemmed.txt\n",
      "71. République II.6_corrected_stemmed.txt\n",
      "72. République II.7_corrected_stemmed.txt\n",
      "73. République III.1_corrected_stemmed.txt\n",
      "74. République III.2_corrected_stemmed.txt\n",
      "75. République III.3_corrected_stemmed.txt\n",
      "76. République III.4_corrected_stemmed.txt\n",
      "77. République III.5_corrected_stemmed.txt\n",
      "78. République III.6_corrected_stemmed.txt\n",
      "79. République III.7_corrected_stemmed.txt\n",
      "80. République IV.1_corrected_stemmed.txt\n",
      "81. République IV.2_corrected_stemmed.txt\n",
      "82. République IV.3_corrected_stemmed.txt\n",
      "83. République IV.4_corrected_stemmed.txt\n",
      "84. République IV.5_corrected_stemmed.txt\n",
      "85. République IV.6_corrected_stemmed.txt\n",
      "86. République IV.7_corrected_stemmed.txt\n",
      "87. République V.1_corrected_stemmed.txt\n",
      "88. République V.2_corrected_stemmed.txt\n",
      "89. République V.3_corrected_stemmed.txt\n",
      "90. République V.4_corrected_stemmed.txt\n",
      "91. République V.5_corrected_stemmed.txt\n",
      "92. République VI.1_corrected_stemmed.txt\n",
      "93. République VI.2_corrected_stemmed.txt\n",
      "94. République VI.3_corrected_stemmed.txt\n",
      "95. République VI.4_corrected_stemmed.txt\n",
      "96. République VI.5_corrected_stemmed.txt\n",
      "97. République VI.6_corrected_stemmed.txt\n",
      "98. Théatre I_corrected_stemmed.txt\n",
      "99. Théatre II_corrected_stemmed.txt\n",
      "100. Théatre III_corrected_stemmed.txt\n",
      "101. Théatre IV_corrected_stemmed.txt\n",
      "102. Théatre summary_corrected_stemmed.txt\n",
      "103. Théatre V_corrected_stemmed.txt\n",
      "104. Traite Justice V_corrected_stemmed.txt\n",
      "105. Traite Justice VI_corrected_stemmed.txt\n",
      "106. Traite Justice VII_corrected_stemmed.txt\n",
      "107. Traité Justice I_corrected_stemmed.txt\n",
      "108. Traité Justice II_corrected_stemmed.txt\n",
      "109. Traité Justice III_corrected_stemmed.txt\n",
      "110. Traité Justice IV_corrected_stemmed.txt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of the file, a range (e.g., 1-3), multiple ranges (e.g., 1-3,5-7), a text pattern to select files, or type 'all' to select all files:  Dém,Rép\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected files:\n",
      "Démonomanie preface Repair_corrected_stemmed.txt\n",
      "République preface_corrected_stemmed.txt\n",
      "Démonomanie I.1_corrected_stemmed.txt\n",
      "Démonomanie I.2_corrected_stemmed.txt\n",
      "Démonomanie I.3_corrected_stemmed.txt\n",
      "Démonomanie I.4_corrected_stemmed.txt\n",
      "Démonomanie I.5_corrected_stemmed.txt\n",
      "Démonomanie I.6_corrected_stemmed.txt\n",
      "Démonomanie I.7_corrected_stemmed.txt\n",
      "Démonomanie II.1_corrected_stemmed.txt\n",
      "Démonomanie II.2_corrected_stemmed.txt\n",
      "Démonomanie II.3_corrected_stemmed.txt\n",
      "Démonomanie II.4_corrected_stemmed.txt\n",
      "Démonomanie II.5_corrected_stemmed.txt\n",
      "Démonomanie II.6_corrected_stemmed.txt\n",
      "Démonomanie II.7_corrected_stemmed.txt\n",
      "Démonomanie II.8_corrected_stemmed.txt\n",
      "Démonomanie III.1_corrected_stemmed.txt\n",
      "Démonomanie III.2_corrected_stemmed.txt\n",
      "Démonomanie III.3_corrected_stemmed.txt\n",
      "Démonomanie III.4_corrected_stemmed.txt\n",
      "Démonomanie III.5_corrected_stemmed.txt\n",
      "Démonomanie III.6_corrected_stemmed.txt\n",
      "Démonomanie IV.1_corrected_stemmed.txt\n",
      "Démonomanie IV.2_corrected_stemmed.txt\n",
      "Démonomanie IV.3_corrected_stemmed.txt\n",
      "Démonomanie IV.4_corrected_stemmed.txt\n",
      "Démonomanie IV.5_corrected_stemmed.txt\n",
      "République I.1_corrected_stemmed.txt\n",
      "République I.2_corrected_stemmed.txt\n",
      "République I.3_corrected_stemmed.txt\n",
      "République I.4_corrected_stemmed.txt\n",
      "République I.5_corrected_stemmed.txt\n",
      "République I.6_corrected_stemmed.txt\n",
      "République I.7_corrected_stemmed.txt\n",
      "République I.8_corrected_stemmed.txt\n",
      "République I.910_corrected_stemmed.txt\n",
      "République I.911_corrected_stemmed.txt\n",
      "République I.9_corrected_stemmed.txt\n",
      "République II.1_corrected_stemmed.txt\n",
      "République II.2_corrected_stemmed.txt\n",
      "République II.3_corrected_stemmed.txt\n",
      "République II.4_corrected_stemmed.txt\n",
      "République II.5_corrected_stemmed.txt\n",
      "République II.6_corrected_stemmed.txt\n",
      "République II.7_corrected_stemmed.txt\n",
      "République III.1_corrected_stemmed.txt\n",
      "République III.2_corrected_stemmed.txt\n",
      "République III.3_corrected_stemmed.txt\n",
      "République III.4_corrected_stemmed.txt\n",
      "République III.5_corrected_stemmed.txt\n",
      "République III.6_corrected_stemmed.txt\n",
      "République III.7_corrected_stemmed.txt\n",
      "République IV.1_corrected_stemmed.txt\n",
      "République IV.2_corrected_stemmed.txt\n",
      "République IV.3_corrected_stemmed.txt\n",
      "République IV.4_corrected_stemmed.txt\n",
      "République IV.5_corrected_stemmed.txt\n",
      "République IV.6_corrected_stemmed.txt\n",
      "République IV.7_corrected_stemmed.txt\n",
      "République V.1_corrected_stemmed.txt\n",
      "République V.2_corrected_stemmed.txt\n",
      "République V.3_corrected_stemmed.txt\n",
      "République V.4_corrected_stemmed.txt\n",
      "République V.5_corrected_stemmed.txt\n",
      "République VI.1_corrected_stemmed.txt\n",
      "République VI.2_corrected_stemmed.txt\n",
      "République VI.3_corrected_stemmed.txt\n",
      "République VI.4_corrected_stemmed.txt\n",
      "République VI.5_corrected_stemmed.txt\n",
      "République VI.6_corrected_stemmed.txt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to append results to an existing .xlsx file? (yes/no):  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new workbook.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a unique name for the .xlsx file (without extension):  ss\n",
      "Do you want to skip processing Hypothesis 1? (yes/no):  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predefined words for Hypothesis 1: citoyen, cour, domain, ressort\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the minimum count threshold for collocates to include:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collocates with counts >= 2:\n",
      "1. alli (Count: 7)\n",
      "2. appel (Count: 5)\n",
      "3. approch (Count: 6)\n",
      "4. aristocrat (Count: 4)\n",
      "5. autruy (Count: 4)\n",
      "6. bien (Count: 24)\n",
      "7. bon (Count: 4)\n",
      "8. bourgeois (Count: 15)\n",
      "9. certain (Count: 7)\n",
      "10. charg (Count: 6)\n",
      "11. choif (Count: 5)\n",
      "12. cit (Count: 10)\n",
      "13. citoyen (Count: 44)\n",
      "14. command (Count: 8)\n",
      "15. corp (Count: 5)\n",
      "16. cour (Count: 11)\n",
      "17. coustum (Count: 5)\n",
      "18. definit (Count: 7)\n",
      "19. deni (Count: 11)\n",
      "20. derni (Count: 5)\n",
      "21. different (Count: 8)\n",
      "22. dir (Count: 10)\n",
      "23. domain (Count: 6)\n",
      "24. droit (Count: 13)\n",
      "25. enfant (Count: 8)\n",
      "26. entre (Count: 13)\n",
      "27. esclav (Count: 7)\n",
      "28. estat (Count: 28)\n",
      "29. estrang (Count: 11)\n",
      "30. estranger (Count: 12)\n",
      "31. fix (Count: 4)\n",
      "32. fort (Count: 20)\n",
      "33. foy (Count: 4)\n",
      "34. franc (Count: 4)\n",
      "35. honneur (Count: 4)\n",
      "36. ja (Count: 5)\n",
      "37. jug (Count: 14)\n",
      "38. latin (Count: 4)\n",
      "39. lieu (Count: 4)\n",
      "40. ligu (Count: 5)\n",
      "41. loi (Count: 10)\n",
      "42. magistrat (Count: 17)\n",
      "43. marqu (Count: 4)\n",
      "44. mer (Count: 4)\n",
      "45. moin (Count: 12)\n",
      "46. moindr (Count: 8)\n",
      "47. natur (Count: 4)\n",
      "48. naturaliz (Count: 6)\n",
      "49. naturel (Count: 9)\n",
      "50. nom (Count: 5)\n",
      "51. ordinair (Count: 4)\n",
      "52. ordon (Count: 5)\n",
      "53. ore (Count: 4)\n",
      "54. parlement (Count: 8)\n",
      "55. part (Count: 23)\n",
      "56. particuli (Count: 4)\n",
      "57. pay (Count: 9)\n",
      "58. peupl (Count: 11)\n",
      "59. piec (Count: 4)\n",
      "60. plusieur (Count: 9)\n",
      "61. populair (Count: 12)\n",
      "62. prendr (Count: 5)\n",
      "63. prerogativ (Count: 7)\n",
      "64. present (Count: 4)\n",
      "65. princ (Count: 15)\n",
      "66. privileg (Count: 10)\n",
      "67. prix (Count: 4)\n",
      "68. proc (Count: 4)\n",
      "69. propr (Count: 6)\n",
      "70. puissanc (Count: 12)\n",
      "71. republ (Count: 42)\n",
      "72. request (Count: 4)\n",
      "73. rom (Count: 6)\n",
      "74. romain (Count: 18)\n",
      "75. roy (Count: 37)\n",
      "76. royaum (Count: 5)\n",
      "77. seigneur (Count: 5)\n",
      "78. senat (Count: 9)\n",
      "79. souverain (Count: 18)\n",
      "80. souverainet (Count: 10)\n",
      "81. soyent (Count: 6)\n",
      "82. sujet (Count: 29)\n",
      "83. vill (Count: 19)\n",
      "84. vray (Count: 15)\n",
      "\n",
      "You can select collocates by entering:\n",
      "- A single number (e.g., 3) to select one collocate.\n",
      "- A range of numbers (e.g., 3-6) to select multiple collocates.\n",
      "- Multiple selections separated by commas (e.g., 3,5-7,9).\n",
      "- Type 'all' to select all collocates.\n",
      "- Type 'done' to finalize your selection.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 475\u001b[0m\n\u001b[1;32m    473\u001b[0m rate_dictionary_files, rate_dictionary_path \u001b[38;5;241m=\u001b[39m select_rate_dictionary_files()\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rate_dictionary_files:\n\u001b[0;32m--> 475\u001b[0m     \u001b[43msearch_concordance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrate_dictionary_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredefined_word_lists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo rate dictionary files selected.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 406\u001b[0m, in \u001b[0;36msearch_concordance\u001b[0;34m(text_data, predefined_word_lists, stops, alpha)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPredefined words for Hypothesis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(predefined_words)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    405\u001b[0m all_significant_collocates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(all_significant_collocates)\n\u001b[0;32m--> 406\u001b[0m selected_collocates, min_count \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_collocates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_significant_collocates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollocate_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m predefined_words:\n\u001b[1;32m    409\u001b[0m     row \u001b[38;5;241m=\u001b[39m [word]\n",
      "Cell \u001b[0;32mIn[2], line 295\u001b[0m, in \u001b[0;36mfilter_collocates\u001b[0;34m(collocates, collocate_counts)\u001b[0m\n\u001b[1;32m    292\u001b[0m selected_collocates \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     selection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter your selection: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selection\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import nltk\n",
    "from scipy.stats import fisher_exact\n",
    "from openpyxl import Workbook, load_workbook\n",
    "\n",
    "# Function to prompt the user to select text files based on patterns\n",
    "def prompt_pattern_files(text_files, pattern):\n",
    "    selected_files = [file for file in text_files if file.startswith(pattern)]\n",
    "    return selected_files\n",
    "\n",
    "def prompt_files(text_files, purpose):\n",
    "    text_files = sorted(text_files, key=custom_file_sort_key)  # Custom sort for files\n",
    "    print(f\"Select the files for {purpose}:\")\n",
    "    for i, file in enumerate(text_files, start=1):\n",
    "        print(f\"{i}. {file}\")\n",
    "    \n",
    "    selection = input(\"Enter the number of the file, a range (e.g., 1-3), multiple ranges (e.g., 1-3,5-7), a text pattern to select files, or type 'all' to select all files: \").strip()\n",
    "    selected_files = []\n",
    "    \n",
    "    if selection.lower() == 'all':\n",
    "        selected_files = text_files\n",
    "    else:\n",
    "        # Split the input by commas to handle multiple ranges or numbers\n",
    "        parts = selection.split(',')\n",
    "        for part in parts:\n",
    "            part = part.strip()\n",
    "            if '-' in part:  # If the part is a range\n",
    "                try:\n",
    "                    start, end = map(int, part.split('-'))\n",
    "                    selected_files.extend(text_files[start-1:end])\n",
    "                except ValueError:\n",
    "                    print(f\"Invalid range: {part}. Please provide ranges like '1-3'.\")\n",
    "            elif part.isdigit():  # If the part is a single number\n",
    "                try:\n",
    "                    selected_files.append(text_files[int(part) - 1])\n",
    "                except IndexError:\n",
    "                    print(f\"Invalid number: {part}. Please select numbers from the list.\")\n",
    "            else:  # If the part is treated as a pattern\n",
    "                selected_files.extend(prompt_pattern_files(text_files, part))\n",
    "    \n",
    "    # Remove duplicates and sort the selected files\n",
    "    selected_files = sorted(set(selected_files), key=custom_file_sort_key)\n",
    "    \n",
    "    print(\"Selected files:\")\n",
    "    for file in selected_files:\n",
    "        print(file)\n",
    "    \n",
    "    return selected_files\n",
    "\n",
    "# Custom sort key for file names\n",
    "def custom_file_sort_key(filename):\n",
    "    # Prioritize 'preface' higher than patterns like 'I.1'\n",
    "    if 'preface' in filename.lower():\n",
    "        return ('', filename.lower())  # Sort 'preface' first\n",
    "    return (filename.lower(),)\n",
    "\n",
    "# Function to process text files\n",
    "def process_text_files(file_paths):\n",
    "    combined_text = \"\"\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            combined_text += file.read().lower() + \" \"\n",
    "    tokens = nltk.wordpunct_tokenize(combined_text)\n",
    "    return nltk.Text(tokens)\n",
    "\n",
    "# Function to find .txt files in a directory\n",
    "def find_text_files(directory):\n",
    "    return sorted([f for f in os.listdir(directory) if f.endswith('.txt')], key=custom_file_sort_key)  # Custom sort\n",
    "\n",
    "# Function to list subfolders in the current directory\n",
    "def list_subfolders():\n",
    "    return sorted([f.name for f in os.scandir() if f.is_dir()])  # Sort folders alphabetically\n",
    "\n",
    "# Function to prompt the user to select a subfolder or the current directory\n",
    "def prompt_subfolder(subfolders):\n",
    "    print(\"Select a subfolder or the current working directory:\")\n",
    "    print(\"0. Current Working Directory\")\n",
    "    for i, subfolder in enumerate(subfolders, start=1):\n",
    "        print(f\"{i}. {subfolder}\")\n",
    "    selected_index = int(input(\"Enter the number of the subfolder: \"))\n",
    "    return None if selected_index == 0 else subfolders[selected_index - 1]\n",
    "\n",
    "# Function to get predefined target words\n",
    "def get_predefined_target_words():\n",
    "    return [\n",
    "        ['citoyen', 'cour', 'domain', 'ressort'],  # List 1\n",
    "        ['guerre', 'paix', 'police' 'religion'],  # List 2\n",
    "        ['confess', 'demon', 'demoniaqu', 'diabl',\n",
    "         'diabol', 'dieu', 'divin', \n",
    "        'hebrieu', 'impiet', 'preuv', 'question',   'sathan', \n",
    "        'sorceller', 'sorci',  'statut', 'sujet'],  # List 3\n",
    "        ['arrest',  'conseil', 'conseiller', 'consul', \n",
    "         'couron', 'édict', 'iurisdict', 'jug', 'magistrat',\n",
    "         'offic', 'offici', 'ordon', 'parlement',\n",
    "        'seigneur', 'seigneurial', 'statut'],  # List 4\n",
    "        ['absolu', 'bien', 'chos', 'civil', 'droit', 'estat', 'just', 'justic',\n",
    "         'loi', 'maiest', 'princ', 'puissanc',\n",
    "        'republ', 'roy', 'royal', 'royaum', 'souverain', 'souverainet', 'sujet']  # List 5\n",
    "    ]\n",
    "\n",
    "# Function to choose subdirectory for stopwords csv file\n",
    "def choose_subdirectory(subdirectories):\n",
    "    print(\"Select a subdirectory:\")\n",
    "    print(\"0. Current Working Directory\")\n",
    "    for i, subdir in enumerate(subdirectories, start=1):\n",
    "        print(f\"{i}. {subdir}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter your choice: \"))\n",
    "            if 0 <= choice <= len(subdirectories):\n",
    "                return None if choice == 0 else subdirectories[choice - 1]\n",
    "            else:\n",
    "                print(\"Invalid selection. Please try again.\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a number.\")\n",
    "\n",
    "# Function to read stopwords from a csv file\n",
    "def read_stopwords(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        stopwords = []\n",
    "        for row in reader:\n",
    "            for word in row:\n",
    "                stopwords.extend(word.split(','))\n",
    "        return [word.strip() for word in stopwords]\n",
    "\n",
    "# Function to find .csv files in a directory\n",
    "def find_csv_files(directory):\n",
    "    return sorted([f for f in os.listdir(directory) if f.endswith('.csv')])  # Sort files alphabetically\n",
    "\n",
    "# Function to select files for the stopwords\n",
    "def select_stopwords_file():\n",
    "    print('Stopwords file selection')\n",
    "    stopwords_subfolders = list_subfolders()\n",
    "    selected_stopwords_subfolder = choose_subdirectory(stopwords_subfolders)\n",
    "    \n",
    "    # Check if the user selected a subfolder or the current directory\n",
    "    stopwords_subfolder_path = os.getcwd() if selected_stopwords_subfolder is None else os.path.join(os.getcwd(), selected_stopwords_subfolder)\n",
    "    \n",
    "    # Find .csv files in the selected directory\n",
    "    stopwords_files = find_csv_files(stopwords_subfolder_path)\n",
    "    if stopwords_files:\n",
    "        print('Select a stopwords file from the following list:')\n",
    "        # Prompt the user to select a single .csv file\n",
    "        selected_file = prompt_files(stopwords_files, \"stopwords file\")\n",
    "        if selected_file:\n",
    "            return selected_file[0], stopwords_subfolder_path  # Return the first selected file and its path\n",
    "        else:\n",
    "            print(\"No stopwords file selected.\")\n",
    "            return None, None\n",
    "    else:\n",
    "        print(f\"No .csv stopwords files found in '{selected_stopwords_subfolder}'.\")\n",
    "        return None, None\n",
    "\n",
    "# Function to select files for the rate dictionary\n",
    "def select_rate_dictionary_files():\n",
    "    print('Rate dictionary file selection')\n",
    "    rate_dictionary_subfolders = list_subfolders()\n",
    "    selected_rate_dictionary_subfolder = choose_subdirectory(rate_dictionary_subfolders)\n",
    "    \n",
    "    # Check if the user selected a subfolder or the current directory\n",
    "    rate_dictionary_subfolder_path = os.getcwd() if selected_rate_dictionary_subfolder is None else os.path.join(os.getcwd(), selected_rate_dictionary_subfolder)\n",
    "    \n",
    "    # Find .txt files in the selected directory\n",
    "    rate_dictionary_files = find_text_files(rate_dictionary_subfolder_path)\n",
    "    if rate_dictionary_files:\n",
    "        print('Select one or more rate dictionary files from the following list:')\n",
    "        selected_files = prompt_files(rate_dictionary_files, \"rate dictionary\")\n",
    "        if selected_files:\n",
    "            return selected_files, rate_dictionary_subfolder_path  # Return the selected files and their path\n",
    "        else:\n",
    "            print(\"No rate dictionary files selected.\")\n",
    "            return [], None\n",
    "    else:\n",
    "        print(f\"No .txt rate dictionary files found in '{selected_rate_dictionary_subfolder}'.\")\n",
    "        return [], None\n",
    "\n",
    "def select_existing_xlsx_file():\n",
    "    print(\"Select a directory to search for .xlsx files:\")\n",
    "    subfolders = list_subfolders()\n",
    "    selected_subfolder = choose_subdirectory(subfolders)\n",
    "\n",
    "    # Check if the user selected a subfolder or the current directory\n",
    "    folder_path = os.getcwd() if selected_subfolder is None else os.path.join(os.getcwd(), selected_subfolder)\n",
    "\n",
    "    # Find .xlsx files in the selected directory\n",
    "    xlsx_files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]\n",
    "    if xlsx_files:\n",
    "        print(\"Select an existing .xlsx file from the following list:\")\n",
    "        for i, file in enumerate(xlsx_files, start=1):\n",
    "            print(f\"{i}. {file}\")\n",
    "        while True:\n",
    "            try:\n",
    "                choice = int(input(\"Enter the number of the file you want to select or 0 to cancel: \"))\n",
    "                if 0 <= choice <= len(xlsx_files):\n",
    "                    return None if choice == 0 else os.path.join(folder_path, xlsx_files[choice - 1])\n",
    "                else:\n",
    "                    print(\"Invalid selection. Please try again.\")\n",
    "            except ValueError:\n",
    "                print(\"Please enter a number.\")\n",
    "    else:\n",
    "        print(f\"No .xlsx files found in '{folder_path}'.\")\n",
    "        return None\n",
    "\n",
    "# Utility function to clean file names\n",
    "def clean_file_name(file_name):\n",
    "    \"\"\"\n",
    "    Clean the file name for display, including replacing specific patterns.\n",
    "    \"\"\"\n",
    "    file_name = file_name.replace('_', '').replace('corrected', '').replace('stemmed', '')\n",
    "    if 'Démonomanie' in file_name:\n",
    "        file_name = file_name.replace('Démonomanie', 'Dém')\n",
    "    if 'République' in file_name:\n",
    "        file_name = file_name.replace('République', 'Rép')\n",
    "   \n",
    "    # Replace '911' with '11' and '910' with '10' (NEW CHANGE)\n",
    "    file_name = file_name.replace('911', '11').replace('910', '10')  # <--- CHANGE HERE\n",
    "   \n",
    "    return os.path.splitext(file_name)[0]\n",
    "\n",
    "# Function to process the subset of text files for KWIC and counts\n",
    "def process_subset_files(file_paths):\n",
    "    combined_text = \"\"\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as f:\n",
    "            file_contents = f.read().lower()\n",
    "            combined_text += file_contents + \" \"\n",
    "    tokens = nltk.wordpunct_tokenize(combined_text)\n",
    "    return tokens\n",
    "\n",
    "def get_kwic(sometargetterm, somelistofwords, window=10, excl_target=True, source_file=None):\n",
    "    kwics = []\n",
    "    for n, w in enumerate(somelistofwords):\n",
    "        if w == sometargetterm:\n",
    "            start = max(0, n - window)\n",
    "            end = min(n + window + 1, len(somelistofwords))\n",
    "            if excl_target:\n",
    "                k = somelistofwords[start:n] + somelistofwords[n + 1:end]\n",
    "            else:\n",
    "                k = somelistofwords[start:end]\n",
    "            kwics.append((k, source_file))\n",
    "    return kwics\n",
    "\n",
    "def add_to_count_dict(word, count_dict):\n",
    "    if word in count_dict:\n",
    "        count_dict[word] += 1\n",
    "    else:\n",
    "        count_dict[word] = 1\n",
    "\n",
    "def get_fishers(someword, somecountdict, someratedict, alternative='greater'):\n",
    "    r = someratedict[someword]\n",
    "    wc = sum(somecountdict.values())\n",
    "    a = somecountdict[someword]\n",
    "    b = wc - a\n",
    "    c = round(r * wc)\n",
    "    d = wc - c\n",
    "    p = fisher_exact([[a, b], [c, d]], alternative=alternative)[1]\n",
    "    return p\n",
    "\n",
    "# Modified filter_collocates function\n",
    "def filter_collocates(collocates, collocate_counts):\n",
    "    \"\"\"\n",
    "    Filter the list of significant collocates based on user selection.\n",
    "\n",
    "    Parameters:\n",
    "        collocates (list): A sorted list of significant collocates.\n",
    "        collocate_counts (dict): A dictionary of collocates and their counts.\n",
    "\n",
    "    Returns:\n",
    "        list: A filtered list of collocates selected by the user.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            min_count = int(input(\"Enter the minimum count threshold for collocates to include: \").strip())\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid number.\")\n",
    "\n",
    "    filtered_collocates = [collocate for collocate in collocates if collocate_counts[collocate] >= min_count]\n",
    "    print(f\"\\nCollocates with counts >= {min_count}:\")\n",
    "    for i, collocate in enumerate(filtered_collocates, start=1):\n",
    "        print(f\"{i}. {collocate} (Count: {collocate_counts[collocate]})\")\n",
    "\n",
    "    print(\"\\nYou can select collocates by entering:\")\n",
    "    print(\"- A single number (e.g., 3) to select one collocate.\")\n",
    "    print(\"- A range of numbers (e.g., 3-6) to select multiple collocates.\")\n",
    "    print(\"- Multiple selections separated by commas (e.g., 3,5-7,9).\")\n",
    "    print(\"- Type 'all' to select all collocates.\")\n",
    "    print(\"- Type 'done' to finalize your selection.\")\n",
    "\n",
    "    selected_collocates = []\n",
    "\n",
    "    while True:\n",
    "        selection = input(\"Enter your selection: \").strip()\n",
    "        if selection.lower() == 'done':\n",
    "            break\n",
    "        elif selection.lower() == 'all':\n",
    "            selected_collocates = filtered_collocates\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            parts = selection.split(',')\n",
    "            for part in parts:\n",
    "                part = part.strip()\n",
    "                if '-' in part:  # Handle ranges\n",
    "                    start, end = map(int, part.split('-'))\n",
    "                    selected_collocates.extend(filtered_collocates[start-1:end])\n",
    "                elif part.isdigit():  # Handle single numbers\n",
    "                    selected_collocates.append(filtered_collocates[int(part) - 1])\n",
    "                else:\n",
    "                    print(f\"Invalid selection: {part}. Please try again.\")\n",
    "        except (ValueError, IndexError):\n",
    "            print(f\"Invalid input: {selection}. Please try again.\")\n",
    "\n",
    "        # Remove duplicates and sort the selected collocates\n",
    "        selected_collocates = sorted(set(selected_collocates), key=filtered_collocates.index)\n",
    "\n",
    "        print(\"Currently selected collocates:\")\n",
    "        for collocate in selected_collocates:\n",
    "            print(collocate)\n",
    "\n",
    "    return selected_collocates, min_count\n",
    "\n",
    "def search_concordance(text_data, predefined_word_lists, stops, alpha):\n",
    "    window = int(input(f\"Enter the window size for concordance: \").strip())\n",
    "\n",
    "    subset_files = prompt_files(find_text_files(os.getcwd()), \"KWIC and key word counts\")\n",
    "\n",
    "    # Allow users to choose an existing .xlsx file or create a new one\n",
    "    append_to_existing = input(\"Do you want to append results to an existing .xlsx file? (yes/no): \").strip().lower()\n",
    "\n",
    "    if append_to_existing == 'yes':\n",
    "        existing_file = select_existing_xlsx_file()\n",
    "        if existing_file:\n",
    "            wb = load_workbook(existing_file)\n",
    "            print(f\"Appending to existing file: {existing_file}\")\n",
    "        else:\n",
    "            print(\"No existing workbook selected. Creating a new workbook instead.\")\n",
    "            wb = Workbook()\n",
    "    else:\n",
    "        wb = Workbook()\n",
    "        print(\"Creating a new workbook.\")\n",
    "\n",
    "    # Prompt the user for a unique name to save the .xlsx file\n",
    "    output_filename = input(\"Enter a unique name for the .xlsx file (without extension): \").strip()\n",
    "    if not output_filename:\n",
    "        output_filename = \"distinct_collocates\"  # Default name\n",
    "    output_filepath = os.path.join(\"concordances\", f\"{output_filename}.xlsx\")\n",
    "\n",
    "    for index, predefined_words in enumerate(predefined_word_lists):\n",
    "        # Allow users to skip processing a predefined word list\n",
    "        skip = input(f\"Do you want to skip processing Hypothesis {index + 1}? (yes/no): \").strip().lower()\n",
    "        if skip == 'yes':\n",
    "            print(f\"Skipping Hypothesis {index + 1}.\")\n",
    "            continue\n",
    "\n",
    "        ws = wb.create_sheet(title=f\"Hypothesis {index + 1}\")\n",
    "\n",
    "        # Write headers\n",
    "        headers = ['Word'] + [clean_file_name(file) for file in subset_files] + ['Total']\n",
    "        ws.append(headers)\n",
    "\n",
    "        # Sort rows (words) alphabetically\n",
    "        predefined_words = sorted(predefined_words)\n",
    "\n",
    "        all_significant_collocates = set()\n",
    "        collocate_counts = {}\n",
    "        counts_by_file = {}\n",
    "        \n",
    "        # Process each file and each predefined word\n",
    "        for file in subset_files:\n",
    "            file_path = os.path.join(os.getcwd(), file)\n",
    "            subset_tokens = process_subset_files([file_path])\n",
    "            counts = {}\n",
    "            \n",
    "            for word in predefined_words:  # Iterate over each word\n",
    "                kwics = get_kwic(word, subset_tokens, window, source_file=file)\n",
    "                \n",
    "                # Count occurrences of each word in the KWIC context\n",
    "                for k, source_file in kwics:\n",
    "                    for w in k:\n",
    "                        if w not in stops:\n",
    "                            add_to_count_dict(w, counts)\n",
    "            \n",
    "            counts_by_file[file] = counts\n",
    "        \n",
    "        # Calculate total word count across all files\n",
    "        total_wc = sum(count for counts in counts_by_file.values() for count in counts.values())\n",
    "        \n",
    "        # Calculate rates for all words\n",
    "        rates = {word: count / total_wc for counts in counts_by_file.values() for word, count in counts.items()}\n",
    "        \n",
    "        # Filter significant tokens using Fisher's exact test\n",
    "        for file, counts in counts_by_file.items():\n",
    "            for word, count in sorted(counts.items(), key=lambda item: item[1], reverse=True):\n",
    "                if word not in stops:\n",
    "                    p_value = get_fishers(word, counts, rates, alternative='greater')\n",
    "                    if p_value < alpha:\n",
    "                        all_significant_collocates.add(word)\n",
    "                        collocate_counts[word] = collocate_counts.get(word, 0) + count\n",
    "\n",
    "        # Notify the user again before selecting collocates\n",
    "        print(f\"\\nPredefined words for Hypothesis {index + 1}: {', '.join(predefined_words)}\")\n",
    "        all_significant_collocates = sorted(all_significant_collocates)\n",
    "        selected_collocates, min_count = filter_collocates(all_significant_collocates, collocate_counts)\n",
    "\n",
    "        for word in predefined_words:\n",
    "            row = [word]\n",
    "            word_total = 0\n",
    "            for file in subset_files:\n",
    "                file_path = os.path.join(os.getcwd(), file)\n",
    "                tokens = process_subset_files([file_path])\n",
    "                kwics = get_kwic(word, tokens, window)\n",
    "                count = sum(1 for k in kwics if any(w in selected_collocates for w in k[0]))\n",
    "                row.append(count)\n",
    "                word_total += count\n",
    "            row.append(word_total)\n",
    "            ws.append(row)\n",
    "\n",
    "        # Add total row\n",
    "        total_row = ['Total'] + [sum(ws.cell(row=i + 2, column=j + 2).value for i in range(len(predefined_words))) for j in range(len(subset_files))] + [sum(ws.cell(row=i + 2, column=len(subset_files) + 2).value for i in range(len(predefined_words)))]\n",
    "        ws.append(total_row)\n",
    "\n",
    "        # Add blank line and selected collocates\n",
    "        ws.append([])\n",
    "        ws.append(['Selected Significant Collocates:'])\n",
    "        for i in range(0, len(selected_collocates), 10):\n",
    "            ws.append(selected_collocates[i:i + 10])\n",
    "       \n",
    "        # Add a blank line and display alpha (p-value threshold), window size, and minimum count threshold\n",
    "        ws.append([])\n",
    "        ws.append(['p-value threshold:', alpha])\n",
    "        ws.append(['window size:', window])\n",
    "        ws.append(['minimum count threshold:', min_count])\n",
    "\n",
    "        # Option to output results after processing each list\n",
    "        output_now = input(f\"Do you want to save the results for Hypothesis {index + 1} now? (yes/no): \").strip().lower()\n",
    "        if output_now == 'yes':\n",
    "            if 'concordances' not in os.listdir():\n",
    "                os.mkdir('concordances')\n",
    "            wb.save(output_filepath)\n",
    "            print(f\"Results up to Hypothesis {index + 1} saved to {output_filepath}.\")\n",
    "\n",
    "        # Option to exit after processing each hypothesis\n",
    "        exit_now = input(\"Do you want to exit after this hypothesis? (yes/no): \").strip().lower()\n",
    "        if exit_now == 'yes':\n",
    "            print(\"Exiting the program.\")\n",
    "            return\n",
    "\n",
    "    # Remove the default sheet if it exists\n",
    "    if 'Sheet' in wb.sheetnames:\n",
    "        del wb['Sheet']\n",
    "\n",
    "    # Save the workbook\n",
    "    if 'concordances' not in os.listdir():\n",
    "        os.mkdir('concordances')\n",
    "    wb.save(output_filepath)\n",
    "    print(f'Concordance has been saved to {output_filepath}.')\n",
    "    \n",
    "# Example usage\n",
    "use_predefined = input(\"Do you want to use predefined target word lists (yes/no)? \").strip().lower() == 'yes'\n",
    "if use_predefined:\n",
    "    predefined_word_lists = get_predefined_target_words()\n",
    "else:\n",
    "    predefined_word_lists = [input(\"Enter words for a group separated by spaces: \").strip().split() for _ in range(5)]\n",
    "\n",
    "alpha = float(input(\"Enter the value for alpha: \").strip())\n",
    "\n",
    "stopwords_file, stopwords_path = select_stopwords_file()\n",
    "if stopwords_file:\n",
    "    stops = read_stopwords(os.path.join(stopwords_path, stopwords_file))\n",
    "    rate_dictionary_files, rate_dictionary_path = select_rate_dictionary_files()\n",
    "    if rate_dictionary_files:\n",
    "        search_concordance(rate_dictionary_files, predefined_word_lists, stops, alpha)\n",
    "    else:\n",
    "        print(\"No rate dictionary files selected.\")\n",
    "else:\n",
    "    print(\"No stopwords file selected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb302138-c417-4d0c-b5d1-3bc2b347a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "modify this code so that it gives users the option to remove words from the selected significant collocates words list after finalizing the selection to allow the user to remove collocates selected in error. Also, please delete the blank sheet at the beginning of the .xlsx workbook. Finally, please ensure that the summed counts displayed in the .xlsx workbook are the counts of unique keyword-collocate pairs in each file, not the total number of occurences of any keyword-collocate pair. Thanks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
