{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5a937f-9be9-4d50-acbf-c182984331f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "from pathlib import Path  \n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Global variable to store the selected stopwords\n",
    "selected_stopwords = None\n",
    "\n",
    "def get_directory_path():\n",
    "    # Get the current working directory\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    print(f\"Current working directory: {cwd}\")\n",
    "    print(\"1. Use the current working directory\")\n",
    "    print(\"2. Select a subdirectory\")\n",
    "\n",
    "    choice = input(\"Enter your choice (default is 1): \") or '1'\n",
    "\n",
    "    if choice == '1':\n",
    "        return cwd\n",
    "    elif choice == '2':\n",
    "        subdirs = [d for d in os.listdir(cwd) if os.path.isdir(os.path.join(cwd, d))]\n",
    "        if not subdirs:\n",
    "            print(\"No subdirectories found.\")\n",
    "            return cwd\n",
    "\n",
    "        print(\"Available subdirectories:\")\n",
    "        for i, subdir in enumerate(subdirs):\n",
    "            print(f\"{i + 1}. {subdir}\")\n",
    "\n",
    "        subdir_choice = int(input(\"Select a subdirectory number: \")) - 1\n",
    "        if subdir_choice < 0 or subdir_choice >= len(subdirs):\n",
    "            print(\"Invalid choice. Using current working directory.\")\n",
    "            return cwd\n",
    "\n",
    "        return os.path.join(cwd, subdirs[subdir_choice])\n",
    "    else:\n",
    "        print(\"Invalid choice. Using current working directory.\")\n",
    "        return cwd\n",
    "\n",
    "def exclude_files(text_files):\n",
    "    print(\"Do you want to exclude any files? (yes/no, default is yes)\")\n",
    "    choice = input().strip().lower() or 'yes'\n",
    "\n",
    "    if choice == 'yes':\n",
    "        print(\"Available text files:\")\n",
    "        for i, file in enumerate(text_files):\n",
    "            file_stem = f\"{Path(file).stem}{Path(file).suffix}\"\n",
    "            print(f\"{i + 1}. {file_stem}\")\n",
    "\n",
    "        user_input = input(\"Enter the numbers of the files you want to exclude, separated by commas (press Enter to include all files):\").strip()\n",
    "        if user_input:\n",
    "            exclude_indices = [int(x.strip()) - 1 for x in user_input.split(',')]\n",
    "            text_files = [file for i, file in enumerate(text_files) if i not in exclude_indices]\n",
    "\n",
    "    return text_files\n",
    "\n",
    "def get_stopwords():\n",
    "    global selected_stopwords\n",
    "    \n",
    "    # Check if stopwords have already been selected\n",
    "    if selected_stopwords is not None:\n",
    "        print(\"Using previously selected stopwords file.\")\n",
    "        return selected_stopwords\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    csv_files = sorted([f for f in os.listdir(cwd) if f.endswith('.csv')])\n",
    "\n",
    "    if not csv_files:\n",
    "        print(\"No CSV files found in the current working directory.\")\n",
    "        return []\n",
    "\n",
    "    print(\"Available CSV files:\")\n",
    "    for i, file in enumerate(csv_files):\n",
    "        print(f\"{i + 1}. {file}\")\n",
    "\n",
    "    while True:\n",
    "        choice = input(\"Select a CSV file number for the stopword list: \").strip()\n",
    "        if choice.isdigit():\n",
    "            choice = int(choice) - 1\n",
    "            if 0 <= choice < len(csv_files):\n",
    "                stopword_file = csv_files[choice]\n",
    "                stopwords = []\n",
    "                with open(stopword_file, 'r', encoding='utf-8') as file:\n",
    "                    reader = csv.reader(file)\n",
    "                    for row in reader:\n",
    "                        stopwords.extend(row)\n",
    "                stopwords = [word.strip() for word in stopwords]\n",
    "                # Save the selected stopwords in the global variable\n",
    "                selected_stopwords = stopwords\n",
    "                return stopwords\n",
    "        print(\"Invalid choice. Please enter a valid number from the list.\")\n",
    "\n",
    "def get_top_n_value():\n",
    "    while True:\n",
    "        try:\n",
    "            top_n_input = input(\"Enter the number of top terms to display (default is 30): \").strip()\n",
    "            if not top_n_input:\n",
    "                return 30\n",
    "            top_n = int(top_n_input)\n",
    "            return top_n\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b8de1b9-f207-4356-aad7-21232af46b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/lucas-jerusalimiec/Documents/OCR Text/Text/Collected/lemmatized\n",
      "1. Use the current working directory\n",
      "2. Select a subdirectory\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (default is 1):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to exclude any files? (yes/no, default is yes)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final list of text files:\n",
      "Discours des raisons_corrected_stemmed\n",
      "Démonomanie Repair_corrected_stemmed\n",
      "Harangue - Fontainebleau_corrected_stemmed\n",
      "Harangue - Orléans 2_corrected_stemmed\n",
      "Harangue - Orléans_corrected_stemmed\n",
      "Harangue - Poissy_corrected_stemmed\n",
      "Harangue - Rouen_corrected_stemmed\n",
      "Harangue - Saint Germain_corrected_stemmed\n",
      "Harangue - lit de justice_corrected_stemmed\n",
      "Harangue - ouverture de parlement_corrected_stemmed\n",
      "Harangue - parlement 2_corrected_stemmed\n",
      "Harangue - parlement 3_corrected_stemmed\n",
      "Harangue - parlement_corrected_stemmed\n",
      "Harangue - religion_corrected_stemmed\n",
      "Harangue - septembre_corrected_stemmed\n",
      "La réponse_corrected_stemmed\n",
      "Le paradoxe_corrected_stemmed\n",
      "Lettre_corrected_stemmed\n",
      "Lit de justice_corrected_stemmed\n",
      "Memoire - Namur_corrected_stemmed\n",
      "Memoire - le but_corrected_stemmed\n",
      "Memoire au roi_corrected_stemmed\n",
      "Memoires d'État Refuge_corrected_stemmed\n",
      "Memoires d'état_corrected_stemmed\n",
      "Recueil_corrected_stemmed\n",
      "Remonstrances - Royaume_corrected_stemmed\n",
      "Remonstrances - parlement_corrected_stemmed\n",
      "République_corrected_stemmed\n",
      "Théatre_corrected_stemmed\n",
      "Traite Justice VII_corrected_stemmed\n",
      "Traite Justice VI_corrected_stemmed\n",
      "Traite Justice V_corrected_stemmed\n",
      "Traité Justice III_corrected_stemmed\n",
      "Traité Justice II_corrected_stemmed\n",
      "Traité Justice IV_corrected_stemmed\n",
      "Traité Justice I_corrected_stemmed\n"
     ]
    }
   ],
   "source": [
    "# Get the directory path from the user\n",
    "directory_path = get_directory_path()\n",
    "text_files = sorted(glob.glob(f\"{directory_path}/*.txt\"))\n",
    "\n",
    "# Prompt the user to exclude any files\n",
    "text_files = exclude_files(text_files)\n",
    "\n",
    "text_titles = [Path(text).stem for text in text_files]\n",
    "\n",
    "# Print the final list of text files\n",
    "print(\"Final list of text files:\")\n",
    "for text_title in text_titles:\n",
    "    print(text_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf2735e2-56ca-4746-b230-63f575544fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CSV files:\n",
      "1. stop_words.csv\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select a CSV file number for the stopword list:  1\n",
      "Enter the number of top terms to display (default is 30):  50\n",
      "Enter a filename (without extension) to save the top TF-IDF terms:  top50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top TF-IDF terms saved to top50_tfidf.xlsx in the current directory.\n"
     ]
    }
   ],
   "source": [
    "# Global variable to store the selected stopwords\n",
    "if 'selected_stopwords' not in globals():\n",
    "    selected_stopwords = None\n",
    "\n",
    "# Get the custom stopword list from the user\n",
    "stop_words = get_stopwords()\n",
    "\n",
    "# Get the number of top terms to display\n",
    "top_n = get_top_n_value()\n",
    "\n",
    "text_contents = []\n",
    "for file_path in text_files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text_contents.append(file.read())\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "tfidf_vector = tfidf_vectorizer.fit_transform(text_contents)\n",
    "tfidf_df = pd.DataFrame(tfidf_vector.toarray(), index=text_titles, columns=tfidf_vectorizer.get_feature_names_out())\n",
    "tfidf_df = tfidf_df.stack().reset_index()\n",
    "tfidf_df = tfidf_df.rename(columns={0: 'tfidf', 'level_0': 'document', 'level_1': 'term'})\n",
    "\n",
    "# Get the top N terms for each document\n",
    "top_tfidf = tfidf_df.sort_values(by=['document', 'tfidf'], ascending=[True, False])\\\n",
    "    .groupby(['document']).head(top_n)\n",
    "\n",
    "# Prompt the user for a filename, reprompt if return is hit accidentally\n",
    "while True:\n",
    "    filename = input(\"Enter a filename (without extension) to save the top TF-IDF terms: \").strip()\n",
    "    if filename:\n",
    "        break\n",
    "    print(\"Filename cannot be empty. Please enter a valid filename.\")\n",
    "\n",
    "# Save the top TF-IDF terms to an Excel workbook\n",
    "output_file = f\"{filename}_tfidf.xlsx\"\n",
    "top_tfidf.to_excel(output_file, index=False, engine='openpyxl')\n",
    "print(f\"Top TF-IDF terms saved to {output_file} in the current directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823e85d9-bdd0-48f2-af40-73f89985b424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using previously selected stopwords file.\n",
      "Available XLSX files:\n",
      "1. top50_tfidf.xlsx\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select an XLSX file number to read as top_tfidf (default is 1):  1\n",
      "Do you want to truncate the plot by only including certain groups? (yes/no, default is no):  \n",
      "Do you want to limit the number of words displayed in each group? (yes/no, default is yes):  \n",
      "Enter the maximum number of words to display per group:  15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Use preset list of terms\n",
      "2. Specify custom terms\n",
      "3. Enter a blank list\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1, 2, or 3), default is 1:  \n"
     ]
    }
   ],
   "source": [
    "import altair as alt\n",
    "import numpy as np\n",
    "\n",
    "# Get the custom stopword list from the user\n",
    "stop_words = get_stopwords()\n",
    "\n",
    "# Function to select an .xlsx file\n",
    "def select_xlsx_file():\n",
    "    cwd = os.getcwd()\n",
    "    xlsx_files = sorted([f for f in os.listdir(cwd) if f.endswith('.xlsx')])\n",
    "    \n",
    "    if not xlsx_files:\n",
    "        print(\"No XLSX files found in the current working directory.\")\n",
    "        return None\n",
    "\n",
    "    print(\"Available XLSX files:\")\n",
    "    for i, file in enumerate(xlsx_files):\n",
    "        print(f\"{i + 1}. {file}\")\n",
    "\n",
    "    choice_input = input(\"Select an XLSX file number to read as top_tfidf (default is 1): \").strip()\n",
    "    choice = int(choice_input) - 1 if choice_input.isdigit() else 0\n",
    "    if choice < 0 or choice >= len(xlsx_files):\n",
    "        print(\"Invalid choice.\")\n",
    "        return None\n",
    "\n",
    "    return xlsx_files[choice]\n",
    "\n",
    "# Prompt user to select an .xlsx file\n",
    "xlsx_file = select_xlsx_file()\n",
    "if xlsx_file:\n",
    "    top_tfidf = pd.read_excel(xlsx_file)\n",
    "    \n",
    "    # Extract the stem of the selected XLSX file\n",
    "    xlsx_stem = Path(xlsx_file).stem\n",
    "\n",
    "    # Prompt user to truncate groups with default value as 'no'\n",
    "    truncate_groups = input(\"Do you want to truncate the plot by only including certain groups? (yes/no, default is no): \").strip().lower() or 'no'\n",
    "    if truncate_groups == 'yes':\n",
    "        available_groups = top_tfidf['document'].unique()\n",
    "        print(\"Available groups (documents) with index numbers:\")\n",
    "        for i, group in enumerate(available_groups):\n",
    "            print(f\"{i + 1}. {group}\")\n",
    "\n",
    "        selected_groups = input(\"Enter the index numbers of the groups to include (e.g., 1,2,3 or 1-3): \").strip()\n",
    "        selected_indexes = []\n",
    "\n",
    "        # Split the input by commas to handle both individual values and ranges\n",
    "        for part in selected_groups.split(','):\n",
    "            if '-' in part:\n",
    "                start_index, end_index = map(int, part.split('-'))\n",
    "                selected_indexes.extend(range(start_index, end_index + 1))\n",
    "            else:\n",
    "                selected_indexes.append(int(part))\n",
    "\n",
    "        # Convert selected indexes to groups\n",
    "        selected_groups = [available_groups[i - 1] for i in selected_indexes]\n",
    "\n",
    "        # Filter the DataFrame\n",
    "        top_tfidf = top_tfidf[top_tfidf['document'].isin(selected_groups)]\n",
    "\n",
    "    # Remove '_corrected' from the 'document' labels\n",
    "    top_tfidf['document'] = top_tfidf['document'].str.replace('_corrected', '')\n",
    "    top_tfidf['document'] = top_tfidf['document'].str.replace('Repair', '')\n",
    "    top_tfidf['document'] = top_tfidf['document'].str.replace('_lemmatized', '')\n",
    "    top_tfidf['document'] = top_tfidf['document'].str.replace('_stemmed', '')\n",
    "\n",
    "    # Prompt user to limit the number of words displayed in each group\n",
    "    limit_words = input(\"Do you want to limit the number of words displayed in each group? (yes/no, default is yes): \").strip().lower() or 'yes'\n",
    "    if limit_words == 'yes':\n",
    "        max_words = int(input(\"Enter the maximum number of words to display per group: \").strip())\n",
    "        top_tfidf['rank'] = top_tfidf.groupby('document')['tfidf'].rank(\"first\", ascending=False)\n",
    "        top_tfidf = top_tfidf[top_tfidf['rank'] <= max_words]\n",
    "\n",
    "    # Prompt user to choose whether to use a preset list of terms, specify custom terms, or enter a blank list\n",
    "    print(\"1. Use preset list of terms\")\n",
    "    print(\"2. Specify custom terms\")\n",
    "    print(\"3. Enter a blank list\")\n",
    "    term_choice_input = input(\"Enter your choice (1, 2, or 3), default is 1: \").strip()\n",
    "    term_choice = int(term_choice_input) if term_choice_input.isdigit() else 1\n",
    "\n",
    "\n",
    "    preset_terms = ['bien', 'cayer', 'céan', 'chambr', 'chos', 'conseil', 'conseiller', 'court',\n",
    "                    'déni', 'dieu', 'divin', 'droit', 'édict', 'estat', 'héres',\n",
    "                    'judg', 'jug', 'justic', 'loi', 'majest', 'magistrat', 'offic', 'ordon',\n",
    "                    'parlement', 'paix', 'princ', 'puissanc',\n",
    "                    'réform', 'religion', 'republ', 'ressort', 'roy', 'royaum',\n",
    "                    'sathan', 'sorc', 'sorci', 'souverain', 'sujet']\n",
    "    if term_choice == 1:\n",
    "        term_list = preset_terms\n",
    "    elif term_choice == 2:\n",
    "        user_terms = input(\"Enter a list of words separated by commas for highlighting (e.g., war, peace): \")\n",
    "        term_list = [term.strip() for term in user_terms.split(\",\")]\n",
    "    else:\n",
    "        term_list = []\n",
    "\n",
    "    # Prompt user for a filename to save the PNG file\n",
    "    file_name = input(\"Enter a filename (without extension) to save the visualization: \")\n",
    "    output_file = f\"{file_name}.png\"\n",
    "\n",
    "    # Prompt user to specify the width of the chart\n",
    "    chart_width_input = input(\"Enter the chart width (default is 600): \").strip()\n",
    "    chart_width = int(chart_width_input) if chart_width_input.isdigit() else 600\n",
    "\n",
    "    # Adding a little randomness to break ties in term ranking\n",
    "    top_tfidf_plusRand = top_tfidf.copy()\n",
    "    top_tfidf_plusRand['tfidf'] = top_tfidf_plusRand['tfidf'] + np.random.rand(top_tfidf.shape[0]) * 0.0001\n",
    "\n",
    "    # Base chart for all visualizations, with rank calculation\n",
    "    base = alt.Chart(top_tfidf_plusRand).encode(\n",
    "        x=alt.X('rank:O', axis=alt.Axis(labelAngle=0)),  # Set labelAngle to horizontal (0 degrees)\n",
    "        y='document:N'\n",
    "    ).transform_window(\n",
    "        rank=\"rank()\",\n",
    "        sort=[alt.SortField(\"tfidf\", order=\"descending\")],\n",
    "        groupby=[\"document\"]\n",
    "    )\n",
    "\n",
    "    # Heatmap specification\n",
    "    heatmap = base.mark_rect().encode(\n",
    "        color='tfidf:Q'\n",
    "    )\n",
    "\n",
    "    # Red circle over terms in the entered list\n",
    "    circle = base.mark_circle(size=100).encode(\n",
    "        color=alt.condition(\n",
    "            alt.FieldOneOfPredicate(field='term', oneOf=term_list),\n",
    "            alt.value('red'),\n",
    "            alt.value('#FFFFFF00')\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Text labels, white for darker heatmap colors\n",
    "    text = base.mark_text(baseline='middle', fontSize=12).encode(\n",
    "        text='term:N',\n",
    "        color=alt.condition(alt.datum.tfidf >= 0.23, alt.value('white'), alt.value('black'))\n",
    "    )\n",
    "\n",
    "    # Combine the heatmap, circle, and text\n",
    "    final_chart = alt.layer(heatmap, circle, text).properties(width=chart_width)\n",
    "\n",
    "    # Display the chart in Jupyter Lab\n",
    "    final_chart.display()\n",
    "\n",
    "    # Save the chart as a PNG file using the base Altair package\n",
    "    try:\n",
    "        final_chart.save(output_file)\n",
    "        print(f\"Visualization saved as {output_file} in the current directory.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving visualization: {e}\")\n",
    "else:\n",
    "    print(\"No valid XLSX file selected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
